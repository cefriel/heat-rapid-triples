{"version":3,"file":"js/699.a532e63a.js","mappings":"4JAEIA,EAA8B,uDAC9BC,EAAkB,qCAClBC,EAAkB,iBAClBC,EAAkB,oBAClBC,EAAoB,QACpBC,EAAuB,WAOvBC,EAAgB,iCAEhBC,EAAQ,CACVC,KAAM,EACNC,IAAK,EACLC,KAAM,GAGR,SAASC,EAAMC,GACb,OAAOA,EAAMC,QAASZ,EAAiB,GACzC,CAEA,SAASa,EAAeF,GACtB,OAAOV,EAAgBa,KAAMH,EAC/B,CAEA,SAASI,EAAgBJ,EAAOK,GAC9B,MAAOH,EAAeF,EAAMK,IAC1BA,IAEF,OAAOA,CACT,CAEA,SAASC,EAAaN,GACpB,OAAOP,EAAqBU,KAAMH,KAC/BN,EAAcS,KAAMH,EACzB,CAQA,SAASO,EAAuBC,EAASC,GACvC,OACEC,OAAOC,KAAMH,GAAUI,SAAWF,OAAOC,KAAMF,GAAUG,QACzDF,OAAOC,KAAMH,GAAUK,MACnBC,GAASA,KAAOL,GAAWD,EAASM,KAAUL,EAASK,GAG/D,CAEA,MAAMC,EAQJ,WAAAC,CAAahB,GAGXiB,KAAKC,KAAO,GAERlB,GACFiB,KAAKE,MAAOnB,EAGhB,CAOA,GAAAoB,CAAKpB,GAKH,IAHA,IAAIqB,EAAQ,GACRC,EAAOtB,EAAMuB,cAERC,EAAI,EAAGA,EAAIP,KAAKC,KAAKN,OAAQY,IACF,kBAAvBP,KAAKC,KAAMM,GAAIJ,KAAoBH,KAAKC,KAAMM,GAAIJ,IAAIG,gBAAkBD,GACjFD,EAAMI,KAAMR,KAAKC,KAAMM,IAI3B,OAAOH,CAET,CAQA,GAAAK,CAAKC,EAAM3B,GAET2B,EAAOA,EAAKJ,cACZvB,EAAQA,EAAMuB,cAId,IAFA,IAAIF,EAAQ,GAEHG,EAAI,EAAGA,EAAIP,KAAKC,KAAKN,OAAQY,IACE,kBAA3BP,KAAKC,KAAMM,GAAKG,IAAuBV,KAAKC,KAAMM,GAAKG,GAAOJ,gBAAkBvB,GACzFqB,EAAMI,KAAMR,KAAKC,KAAMM,IAI3B,OAAOH,CAET,CAGA,GAAAO,CAAKC,GAEH,OADAZ,KAAKC,KAAKO,KAAMI,GACTZ,IACT,CAKA,SAAAa,CAAWD,GAMT,OAJKZ,KAAKC,KAAKa,KAAOC,GAASzB,EAAuByB,EAAKH,KACzDZ,KAAKC,KAAKO,KAAMI,GAGXZ,IAET,CAEA,GAAAgB,CAAKN,EAAM3B,GAET2B,EAAOA,EAAKJ,cACZvB,EAAQA,EAAMuB,cAEd,IAAK,IAAIC,EAAI,EAAGA,EAAIP,KAAKC,KAAKN,OAAQY,IACpC,GAAsC,kBAA3BP,KAAKC,KAAMM,GAAKG,IAAuBV,KAAKC,KAAMM,GAAKG,GAAOJ,gBAAkBvB,EACzF,OAAO,EAIX,OAAO,CAET,CAEA,KAAAmB,CAAOnB,EAAOK,GAEZA,EAASA,GAAU,EACnBL,EAAQK,EAASL,EAAMkC,MAAO7B,GAAWL,EAGzCA,EAAQD,EAAMC,GAAQC,QAASV,EAAiB,IAEhD,IAAI4C,EAAQxC,EAAMC,KACdgB,EAASZ,EAAMY,OAEfoB,GADA3B,EAAS,EACH,MAEV,MAAOA,EAASO,EACd,GAAIuB,IAAUxC,EAAMC,KAAO,CACzB,GAAIM,EAAeF,EAAMK,IAAY,CACnCA,IACA,QACF,CAAO,GAAsB,MAAlBL,EAAMK,GAaf,MAAM,IAAI+B,MAAO,yBAA2BpC,EAAMK,GAAU,eAAiBA,GAZlE,MAAP2B,IACS,MAAXA,EAAIZ,IACFH,KAAKC,KAAKO,QAASV,EAAKsB,gBAAiBL,IACzCf,KAAKC,KAAKO,KAAMO,IAEpB,IAAIM,EAAMtC,EAAMuC,QAAS,IAAKlC,GAC9B,IAAa,IAATiC,EAAa,MAAM,IAAIF,MAAO,2CAA6C/B,GAC/E2B,EAAM,CAAEQ,IAAKxC,EAAMkC,MAAO7B,EAAS,EAAGiC,IAEtCjC,EAASiC,EACTH,EAAQxC,EAAME,IAIhBQ,GACF,MAAO,GAAI8B,IAAUxC,EAAME,IAAM,CAC/B,GAAIK,EAAeF,EAAMK,IAAY,CACnCA,IACA,QACF,CAAO,GAAsB,MAAlBL,EAAMK,GACf8B,EAAQxC,EAAMG,KACdO,QACK,IAAsB,MAAlBL,EAAMK,GAIf,MAAM,IAAI+B,MAAO,yBAA2BpC,EAAMK,GAAU,eAAiBA,GAH7E8B,EAAQxC,EAAMC,KACdS,GAGF,CACF,KAAO,IAAI8B,IAAUxC,EAAMG,KAuDzB,MAAM,IAAIsC,MAAO,yBAA2BD,EAAQ,KAtDpD,GAAqB,MAAjBnC,EAAMK,IAAkBH,EAAeF,EAAMK,IAAY,CAC3DA,IACA,QACF,CACIiC,EAAMtC,EAAMuC,QAAS,IAAKlC,IACjB,IAATiC,IAAaA,EAAMtC,EAAMuC,QAAS,IAAKlC,KAC9B,IAATiC,IAAaA,EAAMtC,EAAMY,QAC7B,IAAIe,EAAO5B,EAAMC,EAAMkC,MAAO7B,EAAQiC,IAAQf,cAC1CkB,EAAY,GAGhB,GAFApC,EAASiC,EAAM,EACfjC,EAASD,EAAgBJ,EAAOK,GACV,MAAlBL,EAAMK,GAAkB,CAC1BA,IACA,MAAOA,EAASO,EAAS,CACvB,GAAsB,MAAlBZ,EAAMK,GAAkB,CAC1BA,IAAU,KACZ,CACsB,OAAlBL,EAAMK,IACRA,IAEFoC,GAAazC,EAAMK,GACnBA,GACF,CACF,KAAO,CACDiC,EAAMjC,EAAS,EACnB,OAAQb,EAAkBW,KAAMH,EAAMsC,KAAUA,EAAM1B,EACpD0B,IAEFG,EAAYzC,EAAMkC,MAAO7B,EAAQiC,GACjCjC,EAASiC,CACX,CAkBA,OAjBIN,EAAKL,IAAUZ,EAAK2B,sBAAuBf,KAER,MAA5BA,EAAMA,EAAKf,OAAS,GAC7BoB,EAAKL,GAASZ,EAAK4B,mBAAoBF,IAEvCA,EAAqB,SAATd,EACVc,EAAUlB,cAAgBkB,EACT,MAAfT,EAAKL,GACHiB,MAAMC,QAASb,EAAKL,IACtBK,EAAKL,GAAOF,KAAMgB,GAElBT,EAAKL,GAAS,CAAEK,EAAKL,GAAQc,GAG/BT,EAAKL,GAASc,IAGVzC,EAAMK,IACZ,IAAK,IAAK8B,EAAQxC,EAAMC,KAAM,MAC9B,IAAK,IAAKuC,EAAQxC,EAAMG,KAAM,MAEhCO,GAGF,CAWF,OARW,MAAP2B,IACS,MAAXA,EAAIZ,IACFH,KAAKC,KAAKO,QAASV,EAAKsB,gBAAiBL,IACzCf,KAAKC,KAAKO,KAAMO,IAGpBA,EAAM,KAECf,IAET,CAEA,QAAA6B,GAME,IAJA,IAAI5B,EAAO,GACPW,EAAO,GACPG,EAAM,KAEDR,EAAI,EAAGA,EAAIP,KAAKC,KAAKN,OAAQY,IACpCQ,EAAMf,KAAKC,KAAKM,GAChBK,EAAOnB,OAAOC,KAAMM,KAAKC,KAAKM,IAAKuB,OAAQ,SAAUlB,EAAMF,GACzD,MAAa,QAATA,EAAwBE,EACrBA,EAAO,KAAOd,EAAKiC,gBAAiBrB,EAAMK,EAAKL,GACxD,EAAG,IAAMK,EAAIQ,IAAM,KACnBtB,EAAKO,KAAMI,GAGb,OAAOX,EAAK+B,KAAM,KAEpB,EAUFlC,EAAKmC,qBAAuB,SAAUlD,GACpC,OAAOZ,EAA4Be,KAAMH,EAC3C,EAEAe,EAAKI,MAAQ,SAAUnB,EAAOK,GAC5B,OAAO,IAAIU,GAAOI,MAAOnB,EAAOK,EAClC,EAEAU,EAAK2B,sBAAwB,SAAUf,GACrC,MAAgB,QAATA,GAA2B,SAATA,GAA4B,UAATA,GACjC,UAATA,GAA6B,WAATA,CACxB,EAEAZ,EAAKoC,YAAc,SAAUxB,GAC3B,MAAgB,QAATA,GAA2B,SAATA,GAA4B,WAATA,CAC9C,EAEAZ,EAAKqC,aAAe,SAAUpD,GAC5B,OAAOA,EAAMC,QAAS,KAAM,MAC9B,EAEAc,EAAKsB,gBAAkB,SAAUL,GAC/B,IAAIqB,EAAOrB,EAAIZ,IAAIkC,MAAO,KAC1B,OAAOD,EAAKE,IAAK,SAAUnC,GACzB,IAAIpB,EAAQU,OAAO8C,OAAQ,CAAC,EAAGxB,GAE/B,OADAhC,EAAMoB,IAAMA,EACLpB,CACT,EACF,EAQAe,EAAK4B,mBAAqB,SAAU3C,GAClC,IAAIyD,EAAQ,6BAA6BC,KAAM1D,GAC/C,MAAO,CACL2D,SAAUF,EAAM,GAAGlC,cACnBqC,SAAU7C,EAAKmC,qBAAsBO,EAAM,IACzC,KAAOA,EAAM,GAAGlC,cAClBvB,MAAOe,EAAKmC,qBAAsBO,EAAM,IACtCI,mBAAoBJ,EAAM,IAAOA,EAAM,GAE7C,EAQA1C,EAAK+C,wBAA0B,SAAUnC,EAAMoC,GAE7C,IAAIH,GAAaG,EAAKH,UAAY,SAAUI,cACxCL,EAAWI,EAAKJ,UAAY,KAE5BM,EAAe,GAWnB,OAREA,EADEC,EAAOC,SAAUJ,EAAK/D,QAAWe,EAAKmC,qBAAsBU,GAC/CG,EAAK/D,MAAM8C,SAAUc,GAC3BM,EAAOC,SAAUJ,EAAK/D,OAChB+D,EAAK/D,MAAM8C,SAAU,OACjC7C,QAAS,gBAAiB,OAEdmE,mBAAoBL,EAAK/D,OAGnC2B,EAAO,IAAMiC,EAAW,IAC7BD,EAAW,IAAOM,CAEtB,EAQAlD,EAAKiC,gBAAkB,SAAUrB,EAAM3B,GAErC,OAAI4C,MAAMC,QAAS7C,GACVA,EAAMuD,IAAMc,GACVtD,EAAKiC,gBAAiBrB,EAAM0C,IAClCpB,KAAM,MAGqB,MAA5BtB,EAAMA,EAAKf,OAAS,IAAgC,kBAAVZ,EACrCe,EAAK+C,wBAAyBnC,EAAM3B,IAGzCe,EAAKoC,YAAaxB,GACpB3B,EAAQM,EAAaN,GACnB,IAAMe,EAAKqC,aAAcpD,GAAU,IACnCe,EAAKqC,aAAcpD,GACZM,EAAaN,KACtBA,EAAQoE,mBAAoBpE,GAE5BA,EAAQA,EACLC,QAAS,OAAQ,KACjBA,QAAS,OAAQ,KACjBA,QAAS,OAAQ,KAEpBD,EAAQ,IAAMA,EAAQ,KAGjB2B,EAAO,IAAM3B,EAEtB,EAEAsE,EAAOC,QAAUxD,C,oCCxZjBL,OAAO8D,eAAeD,EAAS,aAAc,CAAEvE,OAAO,IACtDuE,EAAQE,4BAAyB,EACjC,MAAMC,EAAS,EAAQ,OACjBC,EAA0B,EAAQ,OAIxC,MAAMF,EACF,iBAAAG,GACI,OAAO,CACX,CACA,gBAAAC,GACI,OAAO,CACX,CACA,cAAMC,CAASC,EAAgBC,EAAMrE,EAAMsE,EAAOC,GAC9C,OAAOjE,KAAKd,KAAK4E,EAAgBC,EAAM,KAAMrE,EAAMsE,EACvD,CACA,UAAM9E,CAAK4E,EAAgBC,EAAMlE,EAAKH,EAAMsE,GACxC,MAA8B,kBAAhBtE,EAAKsE,EACvB,CACA,YAAME,CAAOJ,EAAgBC,EAAMlE,EAAKH,EAAMX,EAAOiF,GACjD,IAAIG,QAAkBJ,EAAKK,qBAAqB1E,EAAMsE,GAEtD,GAAkB,UAAdG,EAAuB,CAGvB,IAAIE,EAAc,KACdC,EAAgB,EACpB,IAAK,IAAI/D,EAAIyD,EAAQ,EAAGzD,EAAI,EAAGA,IAAK,CAChC,MAAMgE,EAAY7E,EAAKa,GACvB,GAAyB,kBAAdgE,GAA+C,kBAAdA,EAAwB,CAChED,EAAgB/D,EAChB8D,EAAcE,EACd,KACJ,CACJ,CACA,GAAoB,OAAhBF,EAAsB,CAEtB,MAAMG,QAAeT,EAAKU,kBAAkBX,EAAeY,WAAWhF,GAAO2E,EAAatF,EAAOiF,EAAOtE,GACxG,IAAK,MAAMiF,KAAUH,QACXxE,KAAK4E,kBAAkBd,EAAgBC,EAAMY,EAAQ5F,EAAOiF,EAAOtE,EAAKuB,MAAM,EAAGqD,GAAgBA,GAGrF,IAAlBE,EAAO7E,cACDK,KAAK4E,kBAAkBd,EAAgBC,EAAM,KAAMhF,EAAOiF,EAAOtE,EAAKuB,MAAM,EAAGqD,GAAgBA,EAE7G,CACJ,MACK,GAAkB,SAAdH,QAECL,EAAee,cAAcnF,EAAKuB,MAAM,GAAI,GAAIlC,EAAOiF,EAAQ,GAAG,QAEvE,QAAkBc,IAAdX,GAAyC,UAAdA,EAAuB,CAKvD,IAAK,IAAI5D,EAAIyD,EAAQ,EAAGzD,EAAI,EAAGA,IAC3B,GAAuB,kBAAZb,EAAKa,GAAiB,CAC7B4D,QAAkBJ,EAAKgB,eAAerF,EAAKa,GAAIb,EAAMa,GACrD,KACJ,CAGJ,MAAMyE,QAAsBlB,EAAeY,WAAWhF,EAAKuB,MAAM,GAAI,IACrE,GAAI,UAAWwC,EAAOwB,KAAKC,yBAAyBF,EAAeb,GAAY,CAG3EL,EAAeqB,aAAanB,EAAQ,IAAK,EACzC,MAAMQ,QAAeT,EAAKU,kBAAkBX,EAAeY,WAAWhF,GAAOyE,EAAWpF,EAAOiF,EAAOtE,GACtG,IAAK,MAAMiF,KAAUH,QACXxE,KAAK4E,kBAAkBd,EAAgBC,EAAMY,EAAQ5F,EAAOiF,EAAOtE,EAAKuB,MAAM,GAAI,GAAI+C,EAAQ,GAGlF,IAAlBQ,EAAO7E,cACDK,KAAK4E,kBAAkBd,EAAgBC,EAAM,KAAMhF,EAAOiF,EAAOtE,EAAKuB,MAAM,GAAI,GAAI+C,EAAQ,EAE1G,MAGIF,EAAesB,WAAWpB,EAAO,SAE3BF,EAAee,cAAcnF,EAAKuB,MAAM,GAAI,GAAIlC,EAAOiF,EAAQ,GAAG,GAExEF,EAAeuB,YAAYC,cAAc5F,EAAKuB,MAAM,GAAI,GAEhE,CACJ,CACA,uBAAM2D,CAAkBd,EAAgBC,EAAMhF,EAAOwG,EAAevB,EAAOwB,EAAclB,GAErF,IAAImB,EAAc3B,EAAe4B,iBAAiB1B,GAClD,GAAsB,OAAlBuB,GAAyG,cAAxExB,EAAK4B,gBAAgBJ,EAAeC,EAAcxB,IAAQ,UAAoB,CAC/G,GAAKyB,GAAgBA,EAAY1G,MAI5B,CAID,MAAM6G,EAAc7B,EAAK8B,YAAYC,YACrChC,EAAeiC,SAAS/B,EAAOD,EAAK8B,YAAYG,KAAKP,EAAY1G,MAAOgF,EAAKkC,QAASL,EAAa7B,EAAKmC,oBAExGT,EAAY1G,MAAQ6G,CACxB,KAZwC,CACpC,MAAMO,EAAWpC,EAAK8B,YAAYC,YAClCL,EAAc,CAAE1G,MAAOoH,EAAU7B,gBAAe8B,OAAQD,EAC5D,CAYIpH,GACA+E,EAAeiC,SAAS/B,EAAOD,EAAK8B,YAAYG,KAAKP,EAAY1G,MAAOgF,EAAKsC,SAAUtH,EAAOgF,EAAKmC,mBAE3G,MAIST,IACDA,EAAc,CAAEnB,gBAAe8B,OAAQrC,EAAKuC,SAGpDxC,EAAe4B,iBAAiB1B,GAASyB,EAErC3B,EAAeyC,SAAWzC,EAAe0C,kBAAkBxC,IAC3DF,EAAe2C,UAAU,IAAI/C,EAAwBgD,WAAW,4CAA6ChD,EAAwBiD,YAAYC,oBAEzJ,EAEJtD,EAAQE,uBAAyBA,C,kCC7HjC/D,OAAO8D,eAAeD,EAAS,aAAc,CAAEvE,OAAO,IACtDuE,EAAQuD,iBAAc,EAOtB,MAAMA,EACF,WAAA9G,GACIC,KAAK8G,SAAW,CAAC,CACrB,CACA,UAAApC,CAAWhF,GACP,GAAIA,EAAKC,OAAS,EAAG,CACjB,MAAOoH,KAASC,GAAQtH,EAClBuH,EAAUjH,KAAK8G,SAASC,GAC9B,GAAIE,EAAS,CACT,MAAMC,EAAaD,EAAQvC,WAAWsC,GACtC,GAAIE,EACA,OAAOA,EAAWC,KAAK,EAAGC,UAASpD,YAAY,CAAGoD,UAASpD,MAAOA,EAAQ,IAElF,CACJ,CACA,OAAOhE,KAAKoH,QAAUpH,KAAKoH,QAAQD,KAAMC,IAAY,CAAGA,UAASpD,MAAO,KAAQ,IACpF,CACA,UAAAqD,CAAW3H,EAAM0H,GACb,GAAoB,IAAhB1H,EAAKC,OACLK,KAAKoH,QAAUA,MAEd,CACD,MAAOL,KAASC,GAAQtH,EACxB,IAAIuH,EAAUjH,KAAK8G,SAASC,GACvBE,IACDA,EAAUjH,KAAK8G,SAASC,GAAQ,IAAIF,GAExCI,EAAQI,WAAWL,EAAMI,EAC7B,CACJ,CACA,aAAA9B,CAAcgC,GACVtH,KAAKqH,WAAWC,EAAM,KAC1B,EAEJhE,EAAQuD,YAAcA,C,oCC1CtBpH,OAAO8D,eAAeD,EAAS,aAAc,CAAEvE,OAAO,IACtDuE,EAAQiE,2BAAwB,EAChC,MAAM7D,EAA0B,EAAQ,OAClC8D,EAA0B,EAAQ,OAClC/D,EAAS,EAAQ,OAMvB,MAAM8D,EACF,mBAAAE,GACI,OAAO,CACX,CACA,YAAMvD,CAAOwD,EAAY5D,EAAgBC,EAAMrE,EAAMX,EAAOiF,GACxD,IAAKrC,MAAMC,QAAQ7C,GAAQ,CACvB,MAAM4I,EAAiB,WAAYD,EAE7BN,QAAgBtD,EAAeY,WAAWhF,GAC1CkI,EAAWlI,EAAKsE,EAAQ,GACxB6D,EAAmBpE,EAAOwB,KAAK6C,qBAAqBV,EAASQ,GACnE,GAAIC,EAAkB,CAElB,GAAInE,EAAwBuB,KAAK8C,mBAAmBF,GAChD,MAAM,IAAInE,EAAwBgD,WAAW,kDAAkDmB,IAAoBnE,EAAwBiD,YAAYqB,yBAE3J,GAAgC,kBAArBH,EACP,MAAM,IAAInE,EAAwBgD,WAAW,uCAAuCmB,IAAoBnE,EAAwBiD,YAAYqB,yBAGhJ,GAAqB,kBAAVjJ,EAAoB,CAE3B,GAA2D,QAAvD0E,EAAOwB,KAAKgD,oBAAoBb,EAASQ,GACzC,MAAM,IAAIlE,EAAwBgD,WAAW,gGAAgG3H,IAAS2E,EAAwBiD,YAAYuB,sBAG9L,MAAMC,EAAKpE,EAAKqE,eAAehB,EAASrI,GACpCoJ,IACArE,EAAeuE,QAAQrE,EAAQ,GAAK,CAACmE,GAE7C,CAEA,MAAMG,EAAgBvE,EAAKwE,sBAAsBnB,EAASS,GAC1D,GAAIS,EAAe,CACf,MAAME,QAAoBzE,EAAKU,YAAY2C,EAASS,QAAwB9D,EAAK0E,gBAAgB/I,EAAKsE,GAAQtE,EAAMsE,GAAQA,EAAOtE,GACnI,GAAIiI,EAAgB,CAEhB,MAAMe,QAAgB3E,EAAK4E,uBAAuBjJ,EAAMsE,EAAQ,GAChE,IAAK,MAAM4E,KAAcJ,EACrB1E,EAAeiC,SAAS/B,EAAOD,EAAK8B,YAAYG,KAAK0C,EAASJ,EAAeM,EAAY7E,EAAKmC,mBAEtG,MAGI,IAAK,MAAM0C,KAAcJ,QACfhB,EAAwBqB,sBAAsBC,sBAAsBhF,EAAgBC,EAAMrE,EAAMsE,EAAQ,EAAGsE,EAAeM,GAAY,GAAO,GAAO,EAGtK,CACJ,CACA,MAAMG,EAAcpB,EAAiB,EAAI,QACnC7D,EAAee,cAAcnF,EAAKuB,MAAM,EAAGvB,EAAKC,OAASoJ,GAAchK,EAAOiF,EAAQ+E,GAAa,SAEnGjF,EAAekF,oCACzB,CACAlF,EAAeqB,aAAanB,IAAS,CACzC,EAEJV,EAAQiE,sBAAwBA,C,oCCpEhC9H,OAAO8D,eAAeD,EAAS,aAAc,CAAEvE,OAAO,IACtDuE,EAAQ2F,6BAA0B,EAClC,MAAMvF,EAA0B,EAAQ,OAClCwF,EAAwB,EAAQ,OAItC,MAAMD,UAAgCC,EAAsBC,oBACxD,WAAApJ,GACIqJ,MAAM,QACV,CACA,YAAMlF,CAAOJ,EAAgBC,EAAMlE,EAAKH,EAAMX,EAAOiF,GAC5B,kBAAVjF,GACP+E,EAAe2C,UAAU,IAAI/C,EAAwBgD,WAAW,kCAAkC7G,QAAUd,KAAU2E,EAAwBiD,YAAY0C,qBAE1J,iBAAkBtF,EAAK4B,gBAAgB5G,EAAOW,EAAMsE,QAAaF,EAAeY,WAAWhF,KAC3FoE,EAAe2C,UAAU,IAAI/C,EAAwBgD,WAAW,qCAAqC7G,KAAQ6D,EAAwBiD,YAAY0C,qBAErJvF,EAAeqB,aAAanB,IAAS,CACzC,EAEJV,EAAQ2F,wBAA0BA,C,kCCrBlCxJ,OAAO8D,eAAeD,EAAS,aAAc,CAAEvE,OAAO,IACtDuE,EAAQgG,iCAA8B,EAKtC,MAAMA,EACF,iBAAA3F,GACI,OAAO,CACX,CACA,gBAAAC,GACI,OAAO,CACX,CACA,cAAMC,CAASC,EAAgBC,EAAMrE,EAAMsE,EAAOC,GAC9C,OAAO,CACX,CACA,UAAM/E,CAAK4E,EAAgBC,EAAMlE,EAAKH,EAAMsE,GACxC,OAAO,CACX,CACA,YAAME,CAAOJ,EAAgBC,EAAMlE,EAAKH,EAAMX,EAAOiF,GACjDF,EAAeqB,aAAanB,IAAS,CACzC,EAEJV,EAAQgG,4BAA8BA,C,qCCvBtC7J,OAAO8D,eAAeD,EAAS,aAAc,CAAEvE,OAAO,IACtDuE,EAAQiG,gCAA6B,EACrC,MAAM7F,EAA0B,EAAQ,OAClCwF,EAAwB,EAAQ,OAItC,MAAMK,UAAmCL,EAAsBC,oBAC3D,WAAApJ,GACIqJ,MAAM,WACV,CACA,gBAAAxF,GACI,OAAO,CACX,CACA,YAAMM,CAAOJ,EAAgBC,EAAMlE,EAAKH,EAAMX,EAAOiF,GAE7CF,EAAe0F,mBACX1F,EAAe2F,gBAAgBzF,IAC5BF,EAAe4F,eAAe1F,SACIc,IAAlChB,EAAeuE,QAAQrE,KAC9BF,EAAe2C,UAAU,IAAI/C,EAAwBgD,WAAW,yFAC5BhD,EAAwBiD,YAAYgD,8BAK5E,MAAM3E,EAAgBlB,EAAeY,WAAWhF,GAE1C0H,EAAUtD,EAAe8F,aAAa7K,SAAciG,GAAe6E,iBACzE/F,EAAeuB,YAAYgC,WAAW3H,EAAKuB,MAAM,GAAI,GAAImG,GACzDtD,EAAegG,YAAY/K,SACrB+E,EAAeiG,sBAAsB3C,EAC/C,EAEJ9D,EAAQiG,2BAA6BA,C,qCClCrC9J,OAAO8D,eAAeD,EAAS,aAAc,CAAEvE,OAAO,IACtDuE,EAAQ0G,2BAAwB,EAChC,MAAMC,EAA+B,EAAQ,OACvCC,EAA0B,EAAQ,MAClCC,EAA6B,EAAQ,OACrCC,EAAyB,EAAQ,OACjC3G,EAAS,EAAQ,OAKvB,MAAMuG,EAMF,6BAAOK,CAAuB3C,GAC1B,MAAO,WAAYA,IACV,SAAUA,GAAiD,IAAnCjI,OAAOC,KAAKgI,GAAY/H,QAAoD,IAAnCF,OAAOC,KAAKgI,GAAY/H,OACtG,CAMA,8BAAO2K,CAAwB5C,GAC3B,MAAO,WAAYA,IACV,SAAUA,GAAcjI,OAAOC,KAAKgI,GAAY/H,OAAS,KACpD,SAAU+H,IAAejI,OAAOC,KAAKgI,GAAY/H,OAAS,EAC5E,CAQA,6BAAO4K,CAAuB7C,EAAY1D,EAAOtE,GAC7C,IAAI2K,EAAyBL,EAAsBK,uBAAuB3C,GACtE8C,EAAQ,GACZ,IAAK,IAAIjK,EAAIyD,EAAOzD,EAAIb,EAAKC,OAAQY,IAC5B8J,GAA6C,kBAAZ3K,EAAKa,KACvCiK,GAAS,IAAM9K,EAAKa,IAGnB8J,GAA6C,kBAAZ3K,EAAKa,KACvC8J,GAAyB,GAGjC,OAAOG,CACX,CAeA,gCAAaC,CAAoB3G,EAAgBpE,EAAMsE,GACnD,MAAM0G,EAAW,CACbhD,WAAY,CAAE,QAAQ,GACtB1D,QACA0G,UAAU,GAGd,IAAIC,GAAsB,EAE1B,MAAMvD,QAAgBtD,EAAeY,WAAWhF,EAAM,GACtD,IAAK,IAAIa,EAAIyD,EAAQ,EAAGzD,GAAK,EAAGA,IAC5B,GAAuB,kBAAZb,EAAKa,GAAiB,CAE7B,MAAMqK,EAAiBnH,EAAOwB,KAAK4F,gBAAgBzD,EAAS,aAAc1H,EAAKa,IAAI,GACnF,GAAIqK,GAAkBZ,EAAsBK,uBAAuBO,GAC/D,MAAO,CACHlD,WAAYkD,EACZ5G,MAAOzD,EAAI,EACXmK,UAAU,GAGlB,MAAMI,EAAmBrH,EAAOwB,KAAK4F,gBAAgBzD,EAAS,aAAc1H,EAAKa,EAAI,IAAI,GACzF,GAAKuK,EAQA,CAED,MAAMnD,EAAiB,WAAYmD,EAEnC,IAAK,MAAMC,KAAuBf,EAAsBgB,mBACpD,GAAIF,EAAiBC,GACjB,OAAIpD,EAEIqC,EAAsBgB,mBAAmBD,GAAqBtD,sBACvD,CACHC,WAAYoD,EACZ9G,MAAOzD,EACPmK,UAAU,GAIPA,EAKPC,EACOD,EAGA,CACHhD,WAAYoD,EACZ9G,MAAOzD,EACPmK,UAAU,GAO9B,OAAOA,CACX,CA3CI,GAAIC,EAEA,OAAOD,EAGXC,GAAsB,CAuC9B,CAEJ,OAAOD,CACX,CAeA,yCAAaO,CAA6BnH,EAAgBpE,EAAMsE,GAC5D,MAAMkH,QAAgBlB,EAAsBS,oBAAoB3G,EAAgBpE,EAAMsE,GACtF,OAAQkH,EAAQR,YAAc,WAAYQ,EAAQxD,WACtD,CACA,iBAAA/D,GACI,OAAO,CACX,CACA,gBAAAC,GACI,OAAO,CACX,CACA,cAAMC,CAASC,EAAgBC,EAAMrE,EAAMsE,EAAOC,GAC9C,cAAejE,KAAKd,KAAK4E,EAAgBC,EAAM,KAAMrE,EAAMsE,EAC/D,CACA,UAAM9E,CAAK4E,EAAgBC,EAAMlE,EAAKH,EAAMsE,GACxC,MAAM0D,EAAajE,EAAOwB,KAAKC,+BAA+BpB,EAAeY,WAAWhF,EAAM,GAAIA,EAAKsE,EAAQ,IAC/G,IAAK,MAAMmH,KAAiBnB,EAAsBgB,mBAC9C,GAAItD,EAAWyD,GACX,MAAO,CACHzD,aACAwD,QAASlB,EAAsBgB,mBAAmBG,IAI9D,OAAO,IACX,CACA,YAAMjH,CAAOJ,EAAgBC,EAAMlE,EAAKH,EAAMX,EAAOiF,EAAOoH,GACxD,OAAOA,EAAWF,QAAQhH,OAAOkH,EAAW1D,WAAY5D,EAAgBC,EAAMrE,EAAMX,EAAOiF,EAC/F,EAEJV,EAAQ0G,sBAAwBA,EAChCA,EAAsBgB,mBAAqB,CACvC,MAAO,IAAIf,EAA6BoB,2BACxC,SAAU,IAAInB,EAAwB3C,sBACtC,YAAa,IAAI4C,EAA2BmB,yBAC5C,QAAS,IAAIlB,EAAuBmB,qB,qCCzLxC9L,OAAO8D,eAAeD,EAAS,aAAc,CAAEvE,OAAO,IACtDuE,EAAQkI,wCAAqC,EAC7C,MAAM9H,EAA0B,EAAQ,OAKxC,MAAM8H,EACF,iBAAA7H,GACI,OAAO,CACX,CACA,gBAAAC,GACI,OAAO,CACX,CACA,cAAMC,CAASC,EAAgBC,EAAMrE,EAAMsE,EAAOC,GAC9C,MAAMpE,QAAYkE,EAAKgB,eAAerF,EAAKsE,GAAQtE,EAAMsE,GACzD,QAAIN,EAAwBuB,KAAK8C,mBAAmBlI,OAE3CoE,GACW,UAARpE,EAOhB,CACA,UAAMX,CAAK4E,EAAgBC,EAAMlE,EAAKH,EAAMsE,GACxC,OAAON,EAAwBuB,KAAK8C,mBAAmBlI,EAC3D,CACA,YAAMqE,CAAOJ,EAAgBC,EAAMlE,EAAKH,EAAMX,EAAOiF,GACjD,MAAMyH,EAAcD,EAAmCE,qBAAqB7L,QACxDiF,IAAhB2G,EACIA,UAAsB1M,IAAU0M,EAAYpL,MAC5CyD,EAAe2C,UAAU,IAAI/C,EAAwBgD,WAAW,2BAA2B7G,kBAAoBd,KAAU0M,EAAYE,YAGpI7H,EAAe8H,cACpB9H,EAAe2C,UAAU,IAAItF,MAAM,oBAAoBtB,kBAAoBd,OAE/E+E,EAAeqB,aAAanB,IAAS,CACzC,EAEJV,EAAQkI,mCAAqCA,EAC7CA,EAAmCE,qBAAuB,CACtD,SAAU,CAAErL,KAAM,SAAUsL,UAAWjI,EAAwBiD,YAAYkF,qBAC3E,QAAS,KACT,WAAY,CAAExL,KAAM,SAAUsL,UAAWjI,EAAwBiD,YAAYmF,uBAC7E,OAAQ,KACR,SAAU,K,mCCjDdrM,OAAO8D,eAAeD,EAAS,aAAc,CAAEvE,OAAO,IACtDuE,EAAQ+H,gCAA6B,EAOrC,MAAMA,EACF,mBAAA5D,GACI,OAAO,CACX,CACA,YAAMvD,CAAOwD,EAAY5D,EAAgBC,EAAMrE,EAAMX,EAAOiF,GACxD,IAAImE,EAEJ,GAAIrE,EAAeqB,aAAanB,EAAQ,IAAMF,EAAeuE,QAAQrE,EAAQ,GAEzEmE,EAAKrE,EAAeuE,QAAQrE,EAAQ,GAAG,OAEtC,CAED,MAAM+H,QAAqBhI,EAAK0E,gBAAgB/I,EAAKsE,GAAQtE,EAAMsE,GAC7DgI,EAA2B,OAAjBD,QACJhI,EAAKqE,qBAAqBtE,EAAeY,WAAWhF,GAAOA,EAAKsE,IACtED,EAAK8B,YAAYC,YAEvB,IAAKkG,EAED,YADAlI,EAAeqB,aAAanB,IAAS,GAGzCmE,EAAK6D,EAELlI,EAAeuE,QAAQrE,EAAQ,GAAK,CAACmE,EACzC,CAGA,IAAI8D,EAAMnI,EAAeuE,QAAQrE,GAC5BiI,IACDA,EAAMnI,EAAeuE,QAAQrE,GAAS,IAGrCiI,EAAInL,KAAMoL,GAASA,EAAKC,OAAOhE,KAChC8D,EAAIzL,KAAK2H,SAGFrE,EAAekF,uCACtBlF,EAAeqB,aAAanB,IAAS,EAE7C,EAEJV,EAAQ+H,2BAA6BA,C,qCClDrC5L,OAAO8D,eAAeD,EAAS,aAAc,CAAEvE,OAAO,IACtDuE,EAAQ8I,6BAA0B,EAClC,MAAM1I,EAA0B,EAAQ,OAClCD,EAAS,EAAQ,OACjB+D,EAA0B,EAAQ,OAClC0B,EAAwB,EAAQ,OAItC,MAAMkD,UAAgClD,EAAsBC,oBACxD,WAAApJ,GACIqJ,MAAM,QACV,CACA,gBAAAxF,GACI,OAAO,CACX,CACA,YAAMM,CAAOJ,EAAgBC,EAAMlE,EAAKH,EAAMX,EAAOiF,GACjD,MAAMqI,EAAc3M,EAAKsE,GAInBoD,QAAgBtD,EAAeY,WAAWhF,GAC1C4M,EAAYvI,EAAKwI,QACjBpI,QAAkBJ,EAAKK,qBAAqB1E,EAAMsE,GAClDwI,EAAU/I,EAAOwB,KAAKwH,kBAAkBrF,EAASiF,EAAalI,GAC9DuI,EAAajJ,EAAOwB,KAAK0H,yBAAyBxI,GACxDJ,EAAK6I,8BAA8B/M,EAAK2M,EAASE,GACjD,MAAMG,EAAepJ,EAAOwB,KAAK6H,6BAA6B3I,GAExD4I,EAAWpL,MAAMC,QAAQ7C,GAASA,EAAQ,CAACA,GACjD,IAAK,MAAMiO,KAAWD,EAAU,CACL,kBAAZC,GACPlJ,EAAe2C,UAAU,IAAI/C,EAAwBgD,WAAW,wBAAwBsG,KAAYtJ,EAAwBiD,YAAYsG,qBAE5I,MAAM5M,EAAO0D,EAAKwE,sBAAsBnB,EAAS4F,GAC7C3M,SACMmH,EAAwBqB,sBAAsBC,sBAAsBhF,EAAgBC,EAAMrE,EAAMsE,EAAOsI,EAAWjM,EAAMmM,EAASE,EAAYG,EAE3J,CAEA,IAAIK,EAAgBC,QAAQC,QAAQhG,GAChCiG,GAAwB,EAC5B,IAAK,MAAML,KAAWD,EAASO,OAAQ,CACnC,MAAMC,EAAc9J,EAAOwB,KAAK4F,gBAAgBzD,EAAS,WAAY4F,EAAS,MAC1EO,IACAF,GAAwB,EACxBH,EAAgBA,EAAc/F,KAAMqG,GAAM1J,EAAe8F,aAAa2D,EAAaC,EAAE3D,kBAE7F,EAEI/F,EAAe0F,mBACX6D,GAA0BvJ,EAAe2J,2CACzC3J,EAAe2F,gBAAgBzF,KAAUF,EAAeuE,QAAQrE,IACpEF,EAAe2C,UAAU,IAAI/C,EAAwBgD,WAAW,qGAC5BhD,EAAwBiD,YAAYgD,8BAGxE0D,IAEAH,EAAgBA,EAAc/F,KAAMqG,IAIQ,IAApCA,EAAE3D,gBAAgB,cACX,IAAInG,EAAwBgK,wBAAwBjO,OAAO8C,OAAO9C,OAAO8C,OAAO,CAAC,EAAGiL,EAAE3D,iBAAkB,CAAE,cAAc,EAAO,uBAAwBzC,EAAQyC,mBAEnK2D,GAGX1J,EAAeuB,YAAYgC,WAAW3H,EAAKuB,MAAM,EAAGvB,EAAKC,OAAS,GAAIuN,IAG1EpJ,EAAe4F,eAAe1F,IAAS,CAC3C,EAEJV,EAAQ8I,wBAA0BA,C,qCC3ElC3M,OAAO8D,eAAeD,EAAS,aAAc,CAAEvE,OAAO,IACtDuE,EAAQqK,mBAAgB,EACxB,MAAMC,EAA6B,EAAQ,OACrCC,EAAe,EAAQ,OACvBC,EAAwB,EAAQ,OAChCC,EAA4B,EAAQ,OACpCtK,EAAS,EAAQ,OAIvB,MAAMkK,EACF,WAAA5N,CAAYiO,GACRA,EAAUA,GAAW,CAAC,EACtBhO,KAAKiO,eAAiBD,EAAQC,gBAAkB,IAAIH,EAAsBI,oBAC1ElO,KAAKmO,cAAgB,CAAC,EACtBnO,KAAK+J,iBAAmBiE,EAAQI,eAChCpO,KAAKqO,0BAA4BL,EAAQK,wBACzCrO,KAAKsO,yBAA2BN,EAAQM,0BAA4B,GACpEtO,KAAKuO,yBAAyB,2BAA4BP,MAAYA,EAAQO,sBAClF,CAUA,uBAAOC,CAAiBzP,EAAO0P,EAAa9C,GACxC,GAAqB,kBAAV5M,EACP,MAAM,IAAI8O,EAAanH,WAAW,sDAAsDgI,KAAKC,UAAU5P,MAAW4M,GAEtH,IAAKlI,EAAOwB,KAAK2J,mBAAmB1P,KAAKH,GAAQ,CAC7C,GAAI0P,EACA,MAAM,IAAIZ,EAAanH,WAAW,kEAAkEgI,KAAKC,UAAU5P,MAAW4M,GAG9H,OAAO,CAEf,CACA,OAAO,CACX,CASA,wBAAOkD,CAAkB9P,EAAO6M,GAC5B,GAAqB,kBAAV7M,EACP,MAAM,IAAI8O,EAAanH,WAAW,uDAAuDgI,KAAKC,UAAU5P,MAAW8O,EAAalH,YAAYmI,wBAEhJ,IAAKrL,EAAOwB,KAAK8J,oBAAoB7P,KAAKH,GAAQ,CAC9C,GAAI6M,EACA,MAAM,IAAIiC,EAAanH,WAAW,6DAA6DgI,KAAKC,UAAU5P,MAAW8O,EAAalH,YAAYmI,wBAGlJ,OAAO,CAEf,CACA,OAAO,CACX,CAMA,iBAAAE,CAAkB5H,GACd,IAAK,MAAMvH,KAAOJ,OAAOC,KAAK0H,GAAU,CACpC,IAAIrI,EAAQqI,EAAQvH,GACpB,GAAId,GAA0B,kBAAVA,GACZA,EAAM,cAAgBA,EAAM,OAAQ,CACpC,GAAiC,kBAAtBA,EAAM,aAA4B0E,EAAOwB,KAAKgK,eAAelQ,EAAM,aAC1E,MAAM,IAAI8O,EAAanH,WAAW,gEAAgE3H,EAAM,eAAgB8O,EAAalH,YAAYuI,qBAErJnQ,EAAQqI,EAAQvH,GAAOJ,OAAO8C,OAAO9C,OAAO8C,OAAO,CAAC,EAAGxD,GAAQ,CAAE,MAAOA,EAAM,cAC9EA,EAAM,OAASA,EAAM,YACjB0E,EAAOwB,KAAK8C,mBAAmBhJ,EAAM,oBAC9BA,EAAM,YAGbA,EAAM,aAAc,CAE5B,CAER,CACA,OAAOqI,CACX,CASA,mBAAA+H,CAAoB/H,EAASiH,EAAyB3O,GAClD,MAAM0P,EAAahI,EAAQyC,gBAC3B,IAAK,MAAMhK,KAAQH,GAAQD,OAAOC,KAAK0P,GAEnC,GAAI3L,EAAOwB,KAAKoK,sBAAsB/N,QAAQzB,GAAO,IAAM4D,EAAOwB,KAAKqK,0BAA0BzP,GAAM,CAEnG,MAAM0P,EAAWH,EAAWvP,GAC5B,GAAI4D,EAAOwB,KAAK8C,mBAAmBlI,IAAQ4D,EAAOwB,KAAKuK,uBAAuBlO,QAAQzB,IAAQ,IAC9E,UAARA,GAA8C,kBAApBuP,EAAWvP,KAChCuP,EAAWvP,GAAK,eAAmD,SAAlCuP,EAAWvP,GAAK,eACtD,MAAM,IAAIgO,EAAanH,WAAW,iEAC1C7G,QAAU6O,KAAKC,UAAUY,KAAa1B,EAAalH,YAAY8I,sBAI/D,GAAIhM,EAAOwB,KAAKyK,sBAAsBpO,QAAQmC,EAAOwB,KAAK0K,kBAAkBJ,KAAc,EACtF,MAAM,IAAI1B,EAAanH,WAAW,+DACtC7G,QAAU6O,KAAKC,UAAUY,KAAa1B,EAAalH,YAAYiJ,uBAG/D,GAAIL,GAAY9L,EAAOwB,KAAK8C,mBAAmBtE,EAAOwB,KAAK0K,kBAAkBJ,MAC9C,IAAxBA,EAAS,WACZ,MAAM,IAAI1B,EAAanH,WAAW,4CAA4C7G,QAAU6O,KAAKC,UAAUY,MAAc1B,EAAalH,YAAYqB,yBAGlJ,MAAOvE,EAAOwB,KAAK4K,cAAcT,EAAWvP,IAAO,CAC/C,MAAMd,EAAQqQ,EAAWvP,GACzB,IAAIiQ,GAAU,EACd,GAAqB,kBAAV/Q,EACPqQ,EAAWvP,GAAOuH,EAAQ2I,WAAWhR,GAAO,GAC5C+Q,EAAUA,GAAW/Q,IAAUqQ,EAAWvP,OAEzC,CACD,MAAMsI,EAAKpJ,EAAM,OACXsB,EAAOtB,EAAM,SAEbiR,IAAkB,YAAajR,IAAU0E,EAAOwB,KAAKgL,WAAWpQ,GACtE,GAAI,QAASd,OAEE+F,IAAPqD,GAA2B,OAAPA,GAA6B,kBAAPA,IAC1CiH,EAAWvP,GAAOJ,OAAO8C,OAAO9C,OAAO8C,OAAO,CAAC,EAAG6M,EAAWvP,IAAO,CAAE,MAAOuH,EAAQ2I,WAAW5H,GAAI,KACpG2H,EAAUA,GAAW3H,IAAOiH,EAAWvP,GAAK,aAG/C,IAAK4D,EAAOwB,KAAK8C,mBAAmBlI,IAAQmQ,EAAe,CAE5D,MAAME,EAAQ9I,EAAQ2I,WAAWlQ,GAAK,GAClCqQ,IAAUrQ,IAEVuP,EAAWvP,GAAOJ,OAAO8C,OAAO9C,OAAO8C,OAAO,CAAC,EAAG6M,EAAWvP,IAAO,CAAE,MAAOqQ,IAC7EJ,GAAU,EAElB,CACA,GAAIzP,GAAwB,kBAATA,GAA8B,WAATA,KAC/BtB,EAAM,gBAAkBA,EAAM,cAAc,WAC9CiR,EAAe,CAElB,IAAIG,EAAe/I,EAAQ2I,WAAW1P,GAAM,GACxCgO,GAA2BhO,IAAS8P,IACpCA,EAAe/I,EAAQ2I,WAAW1P,GAAM,IAExC8P,IAAiB9P,IACjByP,GAAU,EACVV,EAAWvP,GAAOJ,OAAO8C,OAAO9C,OAAO8C,OAAO,CAAC,EAAG6M,EAAWvP,IAAO,CAAE,QAASsQ,IAEvF,CACJ,CACA,IAAKL,EACD,KAER,CACJ,CAER,CAMA,SAAAM,CAAUhJ,GAAS,eAAEiJ,EAAc,sBAAEC,IAEjC,GAAIA,GAA4C,IAAnBD,EACzB,IAAK,MAAMxQ,KAAOJ,OAAOC,KAAK0H,GAC1B,GAAY,cAARvH,GAA+C,kBAAjBuH,EAAQvH,GACtCuH,EAAQvH,GAAOuH,EAAQvH,GAAKS,kBAE3B,CACD,MAAMvB,EAAQqI,EAAQvH,GACtB,GAAId,GAA0B,kBAAVA,GACkB,kBAAvBA,EAAM,aAA2B,CACxC,MAAMwR,EAAYxR,EAAM,aAAauB,cACjCiQ,IAAcxR,EAAM,eACpBqI,EAAQvH,GAAOJ,OAAO8C,OAAO9C,OAAO8C,OAAO,CAAC,EAAGxD,GAAQ,CAAE,YAAawR,IAE9E,CAER,CAGZ,CAKA,gBAAAC,CAAiBpJ,GACb,IAAK,MAAMvH,KAAOJ,OAAOC,KAAK0H,GAAU,CACpC,MAAMrI,EAAQqI,EAAQvH,GACtB,GAAId,GAA0B,kBAAVA,EAChB,GAAmC,kBAAxBA,EAAM,cACbqI,EAAQvH,GAAOJ,OAAO8C,OAAO9C,OAAO8C,OAAO,CAAC,EAAGxD,GAAQ,CAAE,aAAc,CAAE,CAACA,EAAM,gBAAgB,UAE/F,GAAI4C,MAAMC,QAAQ7C,EAAM,eAAgB,CACzC,MAAM0R,EAAW,CAAC,EAClB,IAAK,MAAMC,KAAkB3R,EAAM,cAC/B0R,EAASC,IAAkB,EAE/BtJ,EAAQvH,GAAOJ,OAAO8C,OAAO9C,OAAO8C,OAAO,CAAC,EAAGxD,GAAQ,CAAE,aAAc0R,GAC3E,CAER,CACJ,CAMA,oBAAAE,CAAqBvJ,GAAS,eAAEiJ,GAAkBO,GAC9C,GAAIP,GAAkBA,GAAkB,KAChCjJ,EAAQ,cAAe,CACvB,IAAK,MAAMvH,KAAOJ,OAAOC,KAAK0H,GAC1B,IAAI3D,EAAOwB,KAAKqK,0BAA0BzP,KAGrC4D,EAAOwB,KAAK8C,mBAAmBlI,KAAS4D,EAAOwB,KAAK4L,gBAAgBzJ,EAASvH,GAAM,CACpF,MAAMd,EAAQqI,EAAQvH,GAClBd,GAA0B,kBAAVA,EACV,eAAgBqI,EAAQvH,KAE1BuH,EAAQvH,GAAOJ,OAAO8C,OAAO9C,OAAO8C,OAAO,CAAC,EAAG6E,EAAQvH,IAAO,CAAE,cAAc,MAKlFuH,EAAQvH,GAAO,CACX,MAAOd,EACP,cAAc,GAEd0E,EAAOwB,KAAK6L,6BAA6B/R,EAAO6R,KAChDxJ,EAAQvH,GAAOJ,OAAO8C,OAAO9C,OAAO8C,OAAO,CAAC,EAAG6E,EAAQvH,IAAO,CAAE,WAAW,KAGvF,QAEGuH,EAAQ,aACnB,CAER,CASA,4BAAA2J,CAA6BC,EAAeC,EAAcL,EAAelR,GACrE,IAAK,MAAMG,KAAiB,OAATH,QAA0B,IAATA,EAAkBA,EAAOD,OAAOC,KAAKuR,GACrE,GAAIxN,EAAOwB,KAAK4L,gBAAgBG,EAAenR,KAIV,kBAAtBoR,EAAapR,GACpBoR,EAAapR,GAAO,CAAE,MAAOoR,EAAapR,GAAM,cAAc,GAM9DoR,EAAapR,GAAOJ,OAAO8C,OAAO9C,OAAO8C,OAAO,CAAC,EAAG0O,EAAapR,IAAO,CAAE,cAAc,KAGvF4D,EAAOwB,KAAKiM,UAAUF,EAAcnR,GAAMoR,EAAapR,KACxD,MAAM,IAAIgO,EAAanH,WAAW,+CAA+C7G,UAAY6O,KAAKC,UAAUlL,EAAOwB,KAAK0K,kBAAkBqB,EAAcnR,WAAa6O,KAAKC,UAAUlL,EAAOwB,KAAK0K,kBAAkBsB,EAAapR,OAAUgO,EAAalH,YAAYwK,4BAIlR,CAMA,QAAAtN,CAASuD,GAAS,eAAEiJ,IAChB,IAAK,MAAMxQ,KAAOJ,OAAOC,KAAK0H,GAAU,CAEpC,GAAI3D,EAAOwB,KAAKqK,0BAA0BzP,GACtC,SAGJ,GAAY,KAARA,EACA,MAAM,IAAIgO,EAAanH,WAAW,wCAAwC7G,QAAU6O,KAAKC,UAAUvH,EAAQvH,OAAUgO,EAAalH,YAAYqB,yBAElJ,MAAMjJ,EAAQqI,EAAQvH,GAChBuR,SAAmBrS,EAEzB,GAAI0E,EAAOwB,KAAK8C,mBAAmBlI,GAAnC,CACI,OAAQA,EAAIwR,OAAO,IACf,IAAK,QACD,GAAc,OAAVtS,GAAgC,WAAdqS,EAClB,MAAM,IAAIvD,EAAanH,WAAW,gCAAgC3H,IAAS8O,EAAalH,YAAY2K,uBAExG,MACJ,IAAK,OACD,GAAc,OAAVvS,GAAgC,WAAdqS,EAClB,MAAM,IAAIvD,EAAanH,WAAW,+BAA+BU,EAAQvH,KAAQgO,EAAalH,YAAY4K,kBAE9G,MACJ,IAAK,WACa,OAAVxS,GACA4O,EAAca,iBAAiBzP,GAAO,EAAM8O,EAAalH,YAAY6K,0BAEzE,MACJ,IAAK,UACD,GAAc,OAAVzS,GAAgC,WAAdqS,EAClB,MAAM,IAAIvD,EAAanH,WAAW,qCAAqC3H,IAAS8O,EAAalH,YAAY8K,uBAE7G,MACJ,IAAK,YACa,OAAV1S,GACA4O,EAAckB,kBAAkB9P,GAAO,GAE3C,MACJ,IAAK,YACD,GAAuB,IAAnBsR,EACA,MAAM,IAAIxC,EAAanH,WAAW,wCAAwC3H,IAAS8O,EAAalH,YAAY+K,uBAEhH,GAAc,OAAV3S,GAAgC,YAAdqS,EAClB,MAAM,IAAIvD,EAAanH,WAAW,sCAAsC3H,IAAS8O,EAAalH,YAAYgL,yBAE9G,MAGR,GAAIlO,EAAOwB,KAAKgK,eAAepP,IAAQ4D,EAAOwB,KAAKgK,eAAexL,EAAOwB,KAAK0K,kBAAkB5Q,IAC5F,MAAM,IAAI8O,EAAanH,WAAW,gDAAgD7G,QAAU4D,EAAOwB,KAC9F0K,kBAAkB5Q,MAAW8O,EAAalH,YAAY8I,qBAGnE,MAEA,GAAc,OAAV1Q,EACA,OAAQqS,GACJ,IAAK,SACD,GAAI3N,EAAOwB,KAAK2M,UAAU7S,EAAOqI,KAAavH,EAC1C,MAAM,IAAIgO,EAAanH,WAAW,oDAAoD7G,QAAU6O,KAC3FC,UAAU5P,MAAW8O,EAAalH,YAAYkL,oBAEvD,GAAIpO,EAAOwB,KAAK6M,eAAejS,GAAM,CACjC,GAAc,UAAVd,EACA,MAAM,IAAI8O,EAAanH,WAAW,4CAA4C7G,QAAUd,KAAU8O,EAAalH,YAAYuI,qBAE1H,GAAIzL,EAAOwB,KAAKgL,WAAWlR,IAAUA,IAAU,IAAIgP,EAA0BL,wBAAwBtG,GAAS2I,WAAWlQ,GAC1H,MAAM,IAAIgO,EAAanH,WAAW,iDAAiD7G,QAAUd,KAAU8O,EAAalH,YAAYuI,oBAExI,CACA,MACJ,IAAK,SACD,IAAKzL,EAAOwB,KAAK8M,aAAalS,MAAU,QAASd,KACtB,QAAnBA,EAAM,UAAsBqI,EAAQ,UAAYA,EAAQ,WAC5D,MAAM,IAAIyG,EAAanH,WAAW,kCAAkC7G,QAAU6O,KAAKC,UAAU5P,MAAW8O,EAAalH,YAAYuI,qBAErI,IAAK,MAAM8C,KAAavS,OAAOC,KAAKX,GAAQ,CACxC,MAAMkT,EAAclT,EAAMiT,GAC1B,GAAKC,EAGL,OAAQD,GACJ,IAAK,MACD,GAAIvO,EAAOwB,KAAKgK,eAAegD,IACR,UAAhBA,GAA2C,QAAhBA,GAAyC,WAAhBA,GAA4C,UAAhBA,EACnF,MAAM,IAAIpE,EAAanH,WAAW,gDAAgD7G,QAAU6O,KAAKC,UAAU5P,MAAW8O,EAAalH,YAAYuI,qBAEnJ,GAAIzL,EAAOwB,KAAK6M,eAAejS,GAAM,CACjC,GAAoB,UAAhBoS,EACA,MAAM,IAAIpE,EAAanH,WAAW,4CAA4C7G,QAAU6O,KAAKC,UAAU5P,MAAW8O,EAAalH,YAAYuI,qBAE1I,GAAIzL,EAAOwB,KAAKgL,WAAWgC,IACzBA,IAAgB,IAAIlE,EAA0BL,wBAAwBtG,GAAS2I,WAAWlQ,GAC7F,MAAM,IAAIgO,EAAanH,WAAW,iDAAiD7G,QAAU6O,KAAKC,UAAU5P,MAAW8O,EAAalH,YAAYuI,oBAExJ,CACA,GAA2B,kBAAhB+C,EACP,MAAM,IAAIpE,EAAanH,WAAW,8CAA8C7G,QAAU6O,KAAKC,UAAU5P,MAAW8O,EAAalH,YAAYuI,qBAEjJ,GAAIzL,EAAOwB,KAAK2M,UAAUK,EAAa7K,KAAavH,EAChD,MAAM,IAAIgO,EAAanH,WAAW,oDAAoD7G,QAAU6O,KAC3FC,UAAU5P,MAAW8O,EAAalH,YAAYkL,oBAEvD,MACJ,IAAK,QACD,GAA4B,UAAxB9S,EAAM,eAA6C,QAAhBkT,GAAyC,WAAhBA,EAC5D,MAAM,IAAIpE,EAAanH,WAAW,iEAAiE7G,QAAUoS,KAAgBpE,EAAalH,YAAYuL,sBAE1J,GAA2B,kBAAhBD,EACP,MAAM,IAAIpE,EAAanH,WAAW,kDAAkDgI,KAAKC,UAAUyC,MAAevD,EAAalH,YAAYuL,sBAE/I,GAAoB,QAAhBD,GAAyC,WAAhBA,IACF,IAAnB5B,GAA0C,UAAhB4B,KACP,IAAnB5B,GAA0C,UAAhB4B,KACP,MAAnBA,EAAY,KAAexO,EAAOwB,KAAKgL,WAAWgC,IACtD,MAAM,IAAIpE,EAAanH,WAAW,oDAAoD7G,QAAUoS,KAAgBpE,EAAalH,YAAYuL,sBAE7I,MACJ,IAAK,WACD,GAA2B,kBAAhBD,GAA4BlT,EAAM,QAAUA,EAAM,SAAWkT,EACpE,MAAM,IAAIpE,EAAanH,WAAW,uDAAuD7G,OAC9HoS,WAAqBlT,EAAM,UAAW8O,EAAalH,YAAYwL,0BAE9B,GAAI,UAAWpT,EACX,MAAM,IAAI8O,EAAanH,WAAW,iDAAiD7G,KAAQgO,EAAalH,YAAYwL,0BAExH,MACJ,IAAK,aACD,GAAuB,IAAnB9B,IACI5Q,OAAOC,KAAKuS,GAAatS,OAAS,GAC/B8D,EAAOwB,KAAKmN,eAAe9Q,QAAQ7B,OAAOC,KAAKuS,GAAa,IAAM,GACrE,MAAM,IAAIpE,EAAanH,WAAW,gCAAgC7G,QAAUJ,OAAOC,KAAKuS,oCAC9GxO,EAAOwB,KAAKmN,eAAepQ,KAAK,QAAS6L,EAAalH,YAAY0L,2BAGpD,IAAK,MAAM3B,KAAkBjR,OAAOC,KAAKuS,GAAc,CACnD,GAAuB,UAAnBvB,GAA8B3R,EAAM,YACpC,MAAM,IAAI8O,EAAanH,WAAW,6EAA6E7G,KAAQgO,EAAalH,YAAYwL,0BAEpJ,GAAI1O,EAAOwB,KAAKqN,WAAWhR,QAAQoP,GAAkB,EACjD,MAAM,IAAI7C,EAAanH,WAAW,gCAAgC7G,QAAU6Q,uBACvGjN,EAAOwB,KAAKqN,WAAWtQ,KAAK,QAAS6L,EAAalH,YAAY0L,0BAE3C,CACA,MACJ,IAAK,YACD1E,EAAca,iBAAiByD,GAAa,EAAMpE,EAAalH,YAAY4L,0BAC3E,MACJ,IAAK,aACD5E,EAAckB,kBAAkBoD,GAAa,GAC7C,MACJ,IAAK,UACD,GAAoB,OAAhBA,GAA+C,mBAAhBA,EAC/B,MAAM,IAAIpE,EAAanH,WAAW,8CAA8C7G,QAAU6O,KAAKC,UAAU5P,MAAW8O,EAAalH,YAAY6L,sBAEjJ,KAAM,QAASzT,KAAW0E,EAAOwB,KAAKgL,WAAWpQ,GAC7C,MAAM,IAAIgO,EAAanH,WAAW,mCAAmC7G,QAAU6O,KAAKC,UAAU5P,MAAW8O,EAAalH,YAAYqB,yBAEtI,MACJ,IAAK,SACD,GAAuB,IAAnBqI,IAA2BtR,EAAM,gBAAkBA,EAAM,cAAc,UACvE,MAAM,IAAI8O,EAAanH,WAAW,gDAAgD7G,QAAU6O,KAAKC,UAAU5P,MAAW8O,EAAalH,YAAYqB,yBAEnJ,MACJ,IAAK,QACD,GAAIvE,EAAOwB,KAAK8C,mBAAmBkK,IAAgC,UAAhBA,EAC/C,MAAM,IAAIpE,EAAanH,WAAW,0CAA0C7G,QAAU6O,KAAKC,UAAU5P,MAAW8O,EAAalH,YAAY0C,oBAGzJ,CACA,MACJ,QACI,MAAM,IAAIwE,EAAanH,WAAW,iCAAiC7G,QAAUd,KAAU8O,EAAalH,YAAYqB,yBAGhI,CACJ,CAQA,cAAAyK,CAAerL,EAAS4G,EAAS0E,GAE7B,MAAuB,kBAAZtL,IAIPsL,KAAuB,UAAWtL,IAAY4G,EAAQhJ,eAClB,kBAA1BgJ,EAAQhJ,eAA8B,UAAWgJ,EAAQhJ,gBACnEoC,EAAQ,SAAW4G,EAAQhJ,cAAc,SACrCgJ,EAAQhJ,cAAc,qBACtBoC,EAAQ,oBAAqB,IAIjC4G,EAAQ2E,UAAY3E,EAAQ4E,WACtB,UAAWxL,EAKa,OAArBA,EAAQ,UAAiD,kBAArBA,EAAQ,UAC7C3D,EAAOwB,KAAKgL,WAAW7I,EAAQ,YAEnCA,EAAQ,UAAW,EAAIwG,EAA2BR,SAAShG,EAAQ,SAAU4G,EAAQhJ,eAAiBgJ,EAAQhJ,cAAc,UAAYgJ,EAAQ2E,WANhJvL,EAAQ,SAAW4G,EAAQ2E,QAC3BvL,EAAQ,oBAAqB,KAf1BA,CAwBf,CAOA,mBAAAyL,CAAoBC,EAAYH,GAC5B,IAAKlP,EAAOwB,KAAKgL,WAAW6C,GACxB,IACIA,GAAa,EAAIlF,EAA2BR,SAAS0F,EAAYH,EACrE,CACA,MAAOI,GACH,MAAM,IAAI5R,MAAM,wBAAwB2R,IAC5C,CAMJ,OAHI9S,KAAKuO,wBAA0BuE,EAAWE,WAAW,uBACrDF,EAAa,uBAEVA,CACX,CASA,wBAAMG,CAAmB7L,EAAS4G,EAAStO,GACvC,IAAK,MAAMG,KAAiB,OAATH,QAA0B,IAATA,EAAkBA,EAAOD,OAAOC,KAAK0H,GAAW,CAChF,MAAMrI,EAAQqI,EAAQvH,GACtB,GAAId,GAA0B,kBAAVA,GACZ,aAAcA,GAA+B,OAAtBA,EAAM,cAAyBiP,EAAQkF,qBAAsB,CAMpF,GAAIlT,KAAK+J,gBACL,IACI,MAAM/E,EAAgBvF,OAAO8C,OAAO9C,OAAO8C,OAAO,CAAC,EAAG6E,GAAU,CAAE,CAACvH,GAAMJ,OAAO8C,OAAO,CAAC,EAAG6E,EAAQvH,aAC5FmF,EAAcnF,GAAK,kBACpBG,KAAKE,MAAMnB,EAAM,YAAaU,OAAO8C,OAAO9C,OAAO8C,OAAO,CAAC,EAAGyL,GAAU,CAAE4E,UAAU,EAAO5N,gBAAemO,kBAAkB,EAAMC,4BAA4B,EAAMF,sBAAsB,IACpM,CACA,MAAOG,GACH,MAAM,IAAIxF,EAAanH,WAAW2M,EAAEC,QAASzF,EAAalH,YAAY4M,uBAC1E,CAEJnM,EAAQvH,GAAOJ,OAAO8C,OAAO9C,OAAO8C,OAAO,CAAC,EAAGxD,GAAQ,CAAE,kBAAmBiB,KAAKE,MAAMnB,EAAM,YAAaU,OAAO8C,OAAO9C,OAAO8C,OAAO,CAAC,EAAGyL,GAAU,CAAE4E,UAAU,EAAOY,mBAAmB,EAAMJ,4BAA4B,EAAMpO,cAAeoC,MACxOyC,iBACb,CAER,CACA,OAAOzC,CACX,CACA,WAAMlH,CAAMkH,EAAS4G,EAAU,CAAC,EAGhCyF,EAAkB,CAAC,GACf,MAAM,QAAEd,EAAO,cAAE3N,EAAa,SAAE4N,EAAQ,eAAEvC,EAAiB1C,EAAc+F,wBAAuB,sBAAEpD,EAAqB,iBAAE6C,EAAgB,kBAAEK,GAAuBxF,EAC5J2F,EAAiB3F,EAAQ2F,gBAAkB,CAAC,EAElD,GAAIlU,OAAOC,KAAKiU,GAAgBhU,QAAUK,KAAKsO,yBAC3C,MAAM,IAAIT,EAAanH,WAAW,sDAAwDjH,OAAOC,KAAKiU,GAAiB9F,EAAalH,YAAYiN,kBAEpJ,GAAgB,OAAZxM,QAAgCtC,IAAZsC,EAAuB,CAE3C,IAAK+L,GAAoBnO,GAAiBvB,EAAOwB,KAAK4O,kBAAkB7O,GACpE,MAAM,IAAI6I,EAAanH,WAAW,yDAA0DmH,EAAalH,YAAYmN,+BAGzH,OAAO,IAAI/F,EAA0BL,wBAAwB1N,KAAKyS,eAAe,CAAC,EAAGzE,GAAS,GAClG,CACK,GAAuB,kBAAZ5G,EAAsB,CAClC,MAAM0L,EAAa9S,KAAK6S,oBAAoBzL,EAASuL,GAC/CoB,EAAiB/T,KAAKgU,kBAAkBlB,EAAY9E,GAC1D,GAAI+F,EACA,OAAO,IAAIhG,EAA0BL,wBAAwBqG,GAEjE,MAAME,QAA4BjU,KAAKE,YAAYF,KAAKkU,KAAKpB,GAAarT,OAAO8C,OAAO9C,OAAO8C,OAAO,CAAC,EAAGyL,GAAU,CAAE2E,QAASG,EAAYF,UAAU,EAAMe,eAAgBlU,OAAO8C,OAAO9C,OAAO8C,OAAO,CAAC,EAAGoR,GAAiB,CAAE,CAACb,IAAa,OAE5O,OADA9S,KAAKyS,eAAewB,EAAoBpK,gBAAiBmE,GAAS,GAC3DiG,CACX,CACK,GAAItS,MAAMC,QAAQwF,GAAU,CAE7B,MAAM+M,EAAc,GACdC,QAAiBjH,QAAQkH,IAAIjN,EAAQ9E,IAAI,CAAC4E,EAAY3G,KACxD,GAA0B,kBAAf2G,EAAyB,CAChC,MAAM4L,EAAa9S,KAAK6S,oBAAoB3L,EAAYyL,GACxDwB,EAAY5T,GAAKuS,EACjB,MAAMiB,EAAiB/T,KAAKgU,kBAAkBlB,EAAY9E,GAC1D,OAAI+F,GAGG/T,KAAKkU,KAAKpB,EACrB,CAEI,OAAO5L,KAIf,GAAIsM,EACA,OAAO,IAAIzF,EAA0BL,wBAAwB0G,GAEjE,MAAME,QAAwBF,EAAStS,OAAO,CAACyS,EAAmBC,EAAcjU,IAAMgU,EACjFpN,KAAMsN,GAAezU,KAAKE,MAAMsU,EAAc/U,OAAO8C,OAAO9C,OAAO8C,OAAO,CAAC,EAAGyL,GAAU,CAAE2E,QAASwB,EAAY5T,IAAMyN,EAAQ2E,QAASC,WAAYuB,EAAY5T,IAAMyN,EAAQ4E,SAAU5N,cAAeyP,EAAW5K,gBAAiB8J,eAAgBQ,EAAY5T,GAAKd,OAAO8C,OAAO9C,OAAO8C,OAAO,CAAC,EAAGoR,GAAiB,CAAE,CAACQ,EAAY5T,KAAK,IAAUoT,IAEtV,CACIvF,eAAgB7N,EAAI6T,EAASzU,OAAS,KACrCwN,QAAQC,QAAQ,IAAIW,EAA0BL,wBAAwB1I,GAAiB,CAAC,KAG7F,OADAhF,KAAKyS,eAAe6B,EAAgBzK,gBAAiBmE,GAAS,GACvDsG,CACX,CACK,GAAuB,kBAAZlN,EAAsB,CAClC,GAAI,aAAcA,EACd,aAAapH,KAAKE,MAAMkH,EAAQ,YAAa4G,GAcjD,GAXA5G,EAAU3H,OAAO8C,OAAO,CAAC,EAAG6E,GAExBwL,UACOxL,EAAQ,SAGnBpH,KAAKyS,eAAerL,EAAS4G,GAAS,GAGtChO,KAAKwQ,iBAAiBpJ,GAElBoM,EACA,OAAO,IAAIzF,EAA0BL,wBAAwBtG,GAGjE,IAAIsN,EAAgB,CAAC,EACrB,GAAI,YAAatN,EAAS,CACtB,KAAIiJ,GAAkB,KAUlB,MAAM,IAAIxC,EAAanH,WAAW,oDAAqDmH,EAAalH,YAAY+K,uBARhH,GAAkC,kBAAvBtK,EAAQ,WACf,MAAM,IAAIyG,EAAanH,WAAW,qDAAuDU,EAAQ,WAAYyG,EAAalH,YAAYgO,sBAG1ID,QAAsB1U,KAAK4U,kBAAkB5U,KAAK6S,oBAAoBzL,EAAQ,WAAYuL,WACnFvL,EAAQ,UAKvB,CACApH,KAAK2Q,qBAAqB+D,EAAe,CAAErE,kBAAkBtC,EAA0B8G,sBACvF,MAAMC,EAAarV,OAAO8C,OAAOmS,EAAetN,GAEhDpH,KAAKgP,kBAAkB8F,GACvB9U,KAAKoQ,UAAU0E,EAAY,CAAEzE,iBAAgBC,0BAC7CtQ,KAAK2Q,qBAAqBmE,EAAY,CAAEzE,kBAAkBtC,EAA0B8G,sBACpF,MAAMnV,EAAOD,OAAOC,KAAKoV,GACnBC,EAAkB,GACxB,GAA6B,kBAAlB/P,EAEP,IAAK,MAAMnF,KAAOmF,EACVnF,KAAOiV,EACPC,EAAgBvU,KAAKX,GAGrBiV,EAAWjV,GAAOmF,EAAcnF,SAKtCG,KAAKiT,mBAAmB6B,EAAY9G,EAAStO,GACnD,MAAMsV,EAAoB,IAAIjH,EAA0BL,wBAAwBoH,GAoBhF,OAlBKA,GAAcA,EAAW,aAAenH,EAAc+F,0BAA4B,MAC9EtM,EAAQ,WAA0C,kBAAtBA,EAAQ,WAAiD,KAAtBA,EAAQ,aACxEpC,GAAiB,WAAYA,GAAiBoC,EAAQ,UAAU9F,QAAQ,KAAO,EAC/EwT,EAAW,UAAY9P,EAAc,UAAYoC,EAAQ,WAEpD3D,EAAOwB,KAAK8M,aAAa3K,EAAQ,YAAcA,EAAQ,YAAa0N,KAEzEA,EAAW,UAAYE,EAAkBjF,WAAW3I,EAAQ,WAAW,KAG/EpH,KAAKmP,oBAAoB6F,EAAmBhV,KAAKqO,wBAAyB3O,IAErEyT,GAAoBnO,GAAiBqL,GAAkB,KACxDrQ,KAAK+Q,6BAA6B/L,EAAe8P,EAAY/G,EAA0B8G,qBAAsBE,GAE7G/U,KAAK+J,kBAAoB0J,EAAgBrF,gBACzCpO,KAAK6D,SAASiR,EAAY,CAAEzE,mBAEzB2E,CACX,CAEI,MAAM,IAAInH,EAAanH,WAAW,0EAA0EU,IAAWyG,EAAalH,YAAYsO,sBAExJ,CAMA,UAAMf,CAAKgB,GAEP,MAAMC,EAASnV,KAAKmO,cAAc+G,GAClC,GAAIC,EACA,OAAOA,EAGX,IAAIC,EACJ,IACIA,QAAiBpV,KAAKiO,eAAeiG,KAAKgB,EAC9C,CACA,MAAO7B,GACH,MAAM,IAAIxF,EAAanH,WAAW,iCAAiCwO,MAAQ7B,EAAEC,UAAWzF,EAAalH,YAAY0O,8BACrH,CAEA,KAAM,aAAcD,GAChB,MAAM,IAAIvH,EAAanH,WAAW,yCAAyCwO,IAAOrH,EAAalH,YAAY2O,wBAE/G,OAAOtV,KAAKmO,cAAc+G,GAAOE,EAAS,WAC9C,CAUA,iBAAApB,CAAkBkB,EAAKlH,GACnB,GAAIkH,KAAQlH,EAAQ2F,gBAAkB,CAAC,GAAI,CACvC,GAAI3F,EAAQoF,2BACR,OAAO8B,EAGP,MAAM,IAAIrH,EAAanH,WAAW,0CAA4CwO,EAAKrH,EAAalH,YAAY4O,4BAEpH,CACA,OAAO,IACX,CAKA,uBAAMX,CAAkBY,GAEpB,IAAId,QAAsB1U,KAAKkU,KAAKsB,GAEpC,GAA6B,kBAAlBd,GAA8B/S,MAAMC,QAAQ8S,GACnD,MAAM,IAAI7G,EAAanH,WAAW,gDAAkD8O,EAAkB3H,EAAalH,YAAY2O,wBAGnI,GAAI,YAAaZ,EACb,MAAM,IAAI7G,EAAanH,WAAW,uDAAyD8O,EAAkB3H,EAAalH,YAAY+K,uBAM1I,OAJAgD,EAAgBjV,OAAO8C,OAAO,CAAC,EAAGmS,GAGlC1U,KAAKwQ,iBAAiBkE,GACfA,CACX,EAEJ/G,EAAc+F,wBAA0B,IACxCpQ,EAAQqK,cAAgBA,C,iCC/vBxBtK,EAAOC,QAAU,SAASmS,EAAW9Q,GACnC,OAAe,OAAXA,GAAqC,kBAAXA,GAAwC,MAAjBA,EAAO+Q,OACnDhH,KAAKC,UAAUhK,GAGpBhD,MAAMC,QAAQ+C,GACT,IAAMA,EAAO7C,OAAO,CAAC6T,EAAGC,EAAIC,KACjC,MAAMC,EAAe,IAAPD,EAAW,GAAK,IACxB9W,OAAe+F,IAAP8Q,GAAkC,kBAAPA,EAAkB,KAAOA,EAClE,OAAOD,EAAIG,EAAQL,EAAU1W,IAC5B,IAAM,IAGJ,IAAMU,OAAOC,KAAKiF,GAAQ2I,OAAOxL,OAAO,CAAC6T,EAAGC,EAAIC,KACrD,QAAmB/Q,IAAfH,EAAOiR,IACe,kBAAfjR,EAAOiR,GAChB,OAAOD,EAET,MAAMG,EAAqB,IAAbH,EAAEhW,OAAe,GAAK,IACpC,OAAOgW,EAAIG,EAAQL,EAAUG,GAAM,IAAMH,EAAU9Q,EAAOiR,KACzD,IAAM,GACX,C,qCCxBAnW,OAAO8D,eAAeD,EAAS,aAAc,CAAEvE,OAAO,IACtDuE,EAAQyS,iCAA8B,EACtC,MAAMrS,EAA0B,EAAQ,OAClCwF,EAAwB,EAAQ,OAItC,MAAM6M,UAAoC7M,EAAsBC,oBAC5D,WAAApJ,GACIqJ,MAAM,YACV,CACA,YAAMlF,CAAOJ,EAAgBC,EAAMlE,EAAKH,EAAMX,EAAOiF,GAC5B,kBAAVjF,GACP+E,EAAe2C,UAAU,IAAI/C,EAAwBgD,WAAW,4BAA4B3H,KAAU2E,EAAwBiD,YAAYqP,yBAE9I,MAAMC,QAAsBlS,EAAK4B,gBAAgB5G,EAAOW,EAAMsE,QAAaF,EAAeY,WAAWhF,IACjG,WAAYuW,GACZnS,EAAe2C,UAAU,IAAI/C,EAAwBgD,WAAW,2CAA2CgI,KAAKC,UAAU5P,MAAW2E,EAAwBiD,YAAYqP,yBAEzK,UAAWC,GACXnS,EAAe2C,UAAU,IAAI/C,EAAwBgD,WAAW,0CAA0CgI,KAAKC,UAAU5P,MAAW2E,EAAwBiD,YAAYqP,yBAE5KlS,EAAeqB,aAAanB,IAAS,CACzC,EAEJV,EAAQyS,4BAA8BA,C,mCCzBtCtW,OAAO8D,eAAeD,EAAS,aAAc,CAAEvE,OAAO,IACtDuE,EAAQ6F,yBAAsB,EAI9B,MAAMA,EACF,WAAApJ,CAAYmW,GACRlW,KAAKkW,QAAUA,CACnB,CACA,iBAAAvS,GACI,OAAO,CACX,CACA,gBAAAC,GACI,OAAO,CACX,CACA,cAAMC,CAASC,EAAgBC,EAAMrE,EAAMsE,EAAOC,GAC9C,OAAO,CACX,CACA,UAAM/E,CAAK4E,EAAgBC,EAAMlE,EAAKH,EAAMsE,GACxC,OAAOnE,IAAQG,KAAKkW,OACxB,EAEJ5S,EAAQ6F,oBAAsBA,C,qCCtB9B1J,OAAO8D,eAAeD,EAAS,aAAc,CAAEvE,OAAO,IACtDuE,EAAQ6S,kBAAe,EAEvB,MAAMC,EAAS,EAAQ,OACjB1S,EAA0B,EAAQ,OAClC2S,EAAoB,EAAQ,OAC5BC,EAA2B,EAAQ,MACnCC,EAA0B,EAAQ,OAClCC,EAAgC,EAAQ,MACxChP,EAA0B,EAAQ,OAClCiP,EAA+B,EAAQ,OACvCC,EAA6B,EAAQ,OACrCC,EAA0B,EAAQ,OAClCC,EAAgC,EAAQ,OACxCC,EAA4B,EAAQ,MACpCC,EAA4B,EAAQ,OACpCC,EAAuC,EAAQ,OAC/CC,EAA6B,EAAQ,OACrCC,EAAmB,EAAQ,OAC3BxT,EAAS,EAAQ,OACjByT,EAAqB,EAAQ,MAC7BC,EAAkC,EAAQ,OAIhD,MAAMhB,UAAqBE,EAAkBe,UACzC,WAAArX,CAAYiO,GACR5E,MAAM,CAAEiO,oBAAoB,IAC5BrJ,EAAUA,GAAW,CAAC,EACtBhO,KAAKgO,QAAUA,EACfhO,KAAK8D,eAAiB,IAAImT,EAAiBK,eAAe7X,OAAO8C,OAAO,CAAEgV,OAAQvX,MAAQgO,IAC1FhO,KAAK+D,KAAO,IAAIN,EAAOwB,KAAK,CAAEY,YAAamI,EAAQnI,YAAa/B,eAAgB9D,KAAK8D,iBACrF9D,KAAKwX,WAAa,IAAIpB,EACtBpW,KAAKyX,YAAc,GACnBzX,KAAK0X,SAAW,GAChB1X,KAAK2X,oBAAsB,GAC3B3X,KAAK4X,UAAY,EACjB5X,KAAK6X,SAAW,GAChB7X,KAAK8X,eAAiB3K,QAAQC,UAC9BpN,KAAK+X,4BACL/X,KAAKgY,GAAG,MAAO,KACyB,qBAAzBhY,KAAKwX,WAAWS,MACvBjY,KAAKkY,KAAK,QAAS,IAAI/W,MAAM,uBAGzC,CAgBA,uBAAOgX,CAAiBxF,EAASyF,EAAWC,EAASrK,GACjD,IAAI5G,EA8BAoC,EA7BA8O,EAAsB,CAAC,6BAK3B,GAJItK,GAAWA,EAAQsK,sBACnBA,EAAsBtK,EAAQsK,qBAGhB,wBAAdF,IAAwCE,EAAoBC,SAASH,GAAY,CAEjF,GAAkB,qBAAdA,IAAqCA,EAAUI,SAAS,SACxD,MAAM,IAAI9U,EAAwBgD,WAAW,kCAAkC0R,IAAa1U,EAAwBiD,YAAY8R,yBAgBpI,GAbIJ,GAAWA,EAAQrX,IAAI,SACvBqX,EAAQK,QAAQ,CAAC3Z,EAAOc,KACpB,GAAY,SAARA,EAAgB,CAChB,MAAM8Y,GAAa,EAAIzB,EAAmBhX,OAAOnB,GACjD,IAAK,MAAM6B,KAAQ+X,EAAWlY,IAAI,MAAO,wCAAyC,CAC9E,GAAI2G,EACA,MAAM,IAAI1D,EAAwBgD,WAAW,uDAAyDiM,EAASjP,EAAwBiD,YAAYiS,+BAEvJxR,EAAUxG,EAAKW,GACnB,CACJ,KAGH6F,KAAyB,OAAZ4G,QAAgC,IAAZA,OAAqB,EAASA,EAAQ6K,gCACxE,MAAM,IAAInV,EAAwBgD,WAAW,8CAA8C0R,QAAgBzF,IAAWjP,EAAwBiD,YAAY8R,wBAElK,CAGA,GAAIJ,GAAWA,EAAQrX,IAAI,gBAAiB,CACxC,MAAM8X,EAAcT,EAAQ5X,IAAI,gBAC1BsY,EAAQ,qBAAqBtW,KAAKqW,GACpCC,GAAsB,2CAAbA,EAAM,KACfvP,GAAmB,EAE3B,CACA,OAAO,IAAI2M,EAAa1W,OAAO8C,OAAO,CAAEoQ,UACpCvL,UACAoC,oBAAoBwE,GAAoB,CAAC,GACjD,CAMA,MAAAgL,CAAOC,GACH,GAAI,SAAUA,EAAQ,CAClBA,EAAOjB,GAAG,QAAUkB,GAAUC,EAAOjB,KAAK,QAASgB,IACnD,MAAMC,EAASF,EAAOG,KAAK,IAAIjD,EAAanW,KAAKgO,UACjD,OAAOmL,CACX,CACK,CACD,MAAME,EAAS,IAAIhD,EAAkBiD,YAAY,CAAEjC,oBAAoB,IACvE4B,EAAOjB,GAAG,QAAUkB,GAAUC,EAAOjB,KAAK,QAASgB,IACnDD,EAAOjB,GAAG,OAASlV,GAASuW,EAAO7Y,KAAKsC,IACxCmW,EAAOjB,GAAG,MAAO,IAAMqB,EAAO7Y,KAAK,OACnC,MAAM2Y,EAASE,EAAOD,KAAK,IAAIjD,EAAanW,KAAKgO,UACjD,OAAOmL,CACX,CACJ,CACA,UAAAI,CAAWC,EAAO7W,EAAU8W,GACxBzZ,KAAKwX,WAAWkC,MAAMF,GACtBxZ,KAAK8X,eACA3Q,KAAK,IAAMsS,IAAaP,GAAUO,EAASP,GACpD,CAYA,mBAAMrU,CAAcnF,EAAMX,EAAOiF,EAAO2V,GACpC,IAAIC,GAAc,EAGlB,GAAID,GAAkB3V,EAAQhE,KAAK4X,UAAW,CAE1C,MAAMnS,EAAczF,KAAK8D,eAAe4B,iBAAiB1F,KAAK4X,WAC1DnS,IAEIA,EAAY1G,OACZiB,KAAKQ,KAAKR,KAAK+D,KAAK8B,YAAYG,KAAKP,EAAY1G,MAAOiB,KAAK+D,KAAKkC,QAASjG,KAAK+D,KAAKuC,OAAQtG,KAAK+D,KAAKmC,oBAG3GT,EAAYW,OAAOyT,UAAW,EAC9B7Z,KAAK8D,eAAeuE,QAAQ5C,EAAYnB,cAAgB,GAAK,CAACmB,EAAYW,QAC1EpG,KAAK8D,eAAe4B,iBAAiBoU,OAAO9Z,KAAK4X,UAAW,UAItDrB,EAAwBvM,sBAAsBiB,6BAA6BjL,KAAK8D,eAAgB9D,KAAK6X,SAAU7X,KAAK4X,YAC1H5X,KAAK8D,eAAeiW,6BACfvZ,KAAK,CAAEwD,MAAOhE,KAAK4X,UAAWlY,KAAMM,KAAK6X,SAAS5W,MAAM,EAAGjB,KAAK6X,SAASlY,UAC9Eia,GAAc,SAGR5Z,KAAKga,YAAYha,KAAK4X,UAAW5X,KAAK6X,SAEpD,CACA,MAAMhY,QAAYG,KAAK+D,KAAKgB,eAAerF,EAAKsE,GAAQtE,EAAMsE,GACxDG,QAAkBnE,KAAK+D,KAAKK,qBAAqB1E,EAAMsE,GAC7DhE,KAAK8D,eAAeqB,aAAanB,IAAS,EAC1C,IAAIiW,GAAY,EAEZvW,EAAwBuB,KAAKgK,eAAepP,IAAsB,aAAdsE,GAAoC,aAARtE,GAChFG,KAAKkY,KAAK,QAAS,IAAIxU,EAAwBgD,WAAW,kBAAkB3H,iCAAsC2E,EAAwBiD,YAAYuT,+BAI1J,IAAIjW,GAAa,EACbjE,KAAK8D,eAAeqW,gBAAgBxa,OAAS,IAC7CsE,EAAajE,KAAK8D,eAAeqW,gBAAgBna,KAAK8D,eAAeqW,gBAAgBxa,OAAS,GAAGya,UAErG,IAAK,IAAI7Z,EAAI8Z,KAAKC,IAAI,EAAGta,KAAK8D,eAAeqW,gBAAgBxa,OAAS,GAAIY,EAAIb,EAAKC,OAAS,EAAGY,IAAK,CAChG,MAAMga,EAAmBva,KAAK8D,eAAeqW,gBAAgB5Z,KACrDP,KAAK8D,eAAeqW,gBAAgB5Z,SAAWP,KAAKwa,YAAY9a,EAAKuB,MAAM,EAAGV,EAAI,GAAIA,EAAG0D,IACjG,IAAKsW,EAAiBE,MAAO,CACzBza,KAAK8D,eAAeqB,aAAanB,IAAS,EAC1CiW,GAAY,EACZ,KACJ,EACUhW,GAAcsW,EAAiBH,WACrCnW,GAAa,EAErB,CAMA,SAJUjE,KAAK+D,KAAK2W,UAAUhb,EAAMsE,KAChCiW,GAAY,GAGZA,EACA,IAAK,MAAMU,KAAgBxE,EAAayE,eAAgB,CACpD,MAAMxP,QAAmBuP,EAAazb,KAAKc,KAAK8D,eAAgB9D,KAAK+D,KAAMlE,EAAKH,EAAMsE,GACtF,GAAIoH,EAAY,OAENuP,EAAazW,OAAOlE,KAAK8D,eAAgB9D,KAAK+D,KAAMlE,EAAKH,EAAMX,EAAOiF,EAAOoH,GAE/EuP,EAAa/W,qBACb5D,KAAK8D,eAAe2F,gBAAgBzF,IAAS,GAEjD,KACJ,CACJ,CAGU,IAAVA,GAAerC,MAAMC,QAAQ7C,UACvBiB,KAAK+D,KAAK8W,qBAAqB9b,GAGrC6a,GAAe5V,EAAQhE,KAAK4X,WAE5B5X,KAAK4Z,YAAY5Z,KAAK4X,WAE1B5X,KAAK4X,UAAY5T,EACjBhE,KAAK6X,SAAWnY,EAEhBM,KAAK8D,eAAegX,2BAA2BhB,OAAO9V,EAAQ,EAClE,CAKA,WAAA4V,CAAY5V,GACRhE,KAAK8D,eAAe2F,gBAAgBqQ,OAAO9V,EAAO,GAClDhE,KAAK8D,eAAe4F,eAAeoQ,OAAO9V,EAAO,GACjDhE,KAAK8D,eAAeqB,aAAa2U,OAAO9V,EAAO,GAC/ChE,KAAK8D,eAAeuE,QAAQyR,OAAO9V,EAAO,GAC1ChE,KAAK8D,eAAeiX,WAAWjB,OAAO9V,EAAQ,EAAG,GACjDhE,KAAK8D,eAAekX,wBAAwBlB,OAAO9V,EAAO,GAC1DhE,KAAK8D,eAAemX,iBAAiBnB,OAAO9V,EAAO,GACnDhE,KAAK8D,eAAeqW,gBAAgBL,OAAO9V,EAAQ,EAAG,GACtDhE,KAAK8D,eAAeoX,aAAapB,OAAO9V,EAAOhE,KAAK8D,eAAeoX,aAAavb,OAASqE,GACzFhE,KAAK8D,eAAe0C,kBAAkBsT,OAAO9V,EAAO,EAExD,CAUA,iBAAMgW,CAAYhW,EAAOtE,GACrB,IAAIyb,EAAWnb,KAAK8D,eAAeuE,QAAQrE,GAC3C,MAAMoX,IAAuBD,EACxBC,IACDD,EAAWnb,KAAK8D,eAAeuE,QAAQrE,GAAS,CAAChE,KAAK+D,KAAK8B,YAAYC,cAG3E,MAAMuV,EAAcrb,KAAK8D,eAAewX,yBAAyBtX,GACjE,GAAIqX,EAAa,CACb,IAAK,MAAME,KAAWJ,EAAU,CAC5B,MAAMK,QAAyBxb,KAAK+D,KAAK0X,oBAAoBzX,EAAOtE,GAC9Dgc,EAAU1b,KAAK8D,eAAeiX,WAAW/W,IAAUwX,GAAoB,EACvExb,KAAK8D,eAAeuE,QAAQrE,EAAQwX,EAAmB,GACvD,OAAOxb,KAAK+D,KAAK4E,uBAAuBjJ,EAAMsE,IACpD,GAAI0X,EACA,IAAK,MAAMC,KAASD,EAAQ,CAExB1b,KAAK8D,eAAeqB,aAAanB,IAAS,EAC1C,IAAK,MAAM4X,KAAiBP,EACxBrb,KAAK+D,KAAK8X,gBAAgB7X,EAAOuX,EAASK,EAActP,UAAWsP,EAAcjX,OAAQgX,EAAOC,EAAcpP,QAASoP,EAAclP,WAE7I,KAEC,CAED,MAAMoP,EAAiB9b,KAAK8D,eAAeiY,+BAA+B/X,QAAchE,KAAK+D,KAAK0X,oBAAoBzX,EAAOtE,GAAQ,GACrI,IAAK,MAAMkc,KAAiBP,EACpBO,EAAcpP,QACdsP,EAAetb,KAAK,CAChBmE,OAAQ4W,EACRjP,UAAWsP,EAActP,UACzBiP,QAASK,EAAcjX,OACvB+H,WAAYkP,EAAclP,aAI9BoP,EAAetb,KAAK,CAChBmE,OAAQiX,EAAcjX,OACtB2H,UAAWsP,EAActP,UACzBiP,UACA7O,WAAYkP,EAAclP,YAI1C,CACJ,CACA1M,KAAK8D,eAAewX,yBAAyBxB,OAAO9V,EAAO,GAC3DhE,KAAK8D,eAAeoX,aAAapB,OAAO9V,EAAO,GAC/ChE,KAAK8D,eAAemX,iBAAiBnB,OAAO9V,EAAO,EACvD,CAEA,MAAMgY,EAAchc,KAAK8D,eAAemY,yBAAyBjY,GACjE,GAAIgY,EAAa,CACb,IAAK,MAAMT,KAAWJ,EAAU,CAI5B,MAAMQ,EAAkB,IAAV3X,GAAoC,cAArBuX,EAAQW,UAC7Blc,KAAK8D,eAAeqY,mBAAmDZ,EAA9Bvb,KAAK+D,KAAKmC,kBAC3DlG,KAAK8D,eAAeqB,aAAanB,IAAS,EAC1C,IAAK,MAAM4X,KAAiBI,EACxBhc,KAAK8D,eAAeiC,SAAS/B,EAAOhE,KAAK+D,KAAK8B,YAAYG,KAAK4V,EAAcL,QAASK,EAActP,UAAWsP,EAAcjX,OAAQgX,GAE7I,CACA3b,KAAK8D,eAAemY,yBAAyBnC,OAAO9V,EAAO,EAC/D,CAEA,MAAMwC,EAAoBxG,KAAK8D,eAAe0C,kBAAkBxC,GAChE,GAAIwC,EAAmB,CAEfA,EAAkB7G,OAAS,GAAe,IAAVqE,GAChChE,KAAK8D,eAAe2C,UAAU,IAAI/C,EAAwBgD,WAAW,iDAAkDhD,EAAwBiD,YAAYC,qBAG/J,MAAMwV,EAA0Bpc,KAAK8D,eAAeuY,yBAAyBrY,EAAQ,GACrF,IAAK,MAAMsY,KAAc9V,EACrB4V,EAAwB5b,KAAK8b,UAE1Btc,KAAK8D,eAAe0C,kBAAkBxC,EACjD,CACJ,CAQA,iBAAMwW,CAAY9a,EAAMsE,EAAOC,GAC3B,IAAK,MAAM0W,KAAgBxE,EAAayE,eACpC,SAAUD,EAAa9W,SAAS7D,KAAK8D,eAAgB9D,KAAK+D,KAAMrE,EAAMsE,EAAOC,GACzE,MAAO,CAAEwW,OAAO,EAAML,SAAUnW,GAAc0W,EAAahX,qBAGnE,MAAO,CAAE8W,OAAO,EAAOL,UAAU,EACrC,CAMA,yBAAArC,GAEI/X,KAAKwX,WAAW+E,QAAWxd,IACvB,MAAMiF,EAAQhE,KAAKwX,WAAWgF,MAAM7c,OAC9BD,EAAQ,IAAIiC,MAAMqC,EAAQ,GAAGyY,KAAK,GAAIna,IAAI,CAACoa,EAAGnc,IACzCA,IAAMyD,EAAQhE,KAAKwX,WAAW3X,IAAMG,KAAKwX,WAAWgF,MAAMjc,GAAGV,KAExE,IAAKG,KAAK2c,sBAAsB3Y,GAAQ,CACpC,MAAM4Y,EAAa,IAAM5c,KAAK6E,cAAcnF,EAAMX,EAAOiF,GAAO,GAChE,GAAKhE,KAAK8D,eAAe0F,kBACjBxJ,KAAK8D,eAAeuB,YAAYX,WAAWhF,EAAKuB,MAAM,GAAI,IAmB9DjB,KAAK8X,eAAiB9X,KAAK8X,eAAe3Q,KAAKyV,QAb/C,GAAoB,aAAhBld,EAAKsE,GAAuB,CAC5B,IAAI6Y,EAAO7c,KAAKyX,YAAYzT,GACvB6Y,IACDA,EAAO7c,KAAKyX,YAAYzT,GAAS,IAErC6Y,EAAKrc,KAAKoc,EACd,MAEI5c,KAAK2X,oBAAoBnX,KAAK,CAAEsc,IAAKF,EAAYld,OAAMsE,UAQ1DhE,KAAK8D,eAAe0F,kBAA8B,IAAVxF,IACzChE,KAAK8X,eAAiB9X,KAAK8X,eACtB3Q,KAAK,IAAMnH,KAAK+c,uBAE7B,GAEJ/c,KAAKwX,WAAWwF,QAAW9D,IACvBlZ,KAAKkY,KAAK,QAASgB,GAE3B,CAMA,qBAAAyD,CAAsB3Y,GAClB,IAAK,IAAIzD,EAAIyD,EAAOzD,EAAI,EAAGA,IACvB,GAAyC,aAArCP,KAAKwX,WAAWgF,MAAMjc,EAAI,GAAGV,IAC7B,OAAO,EAGf,OAAO,CACX,CAKA,yBAAMkd,GAEF,IAAK,MAAMF,KAAQ7c,KAAKyX,YACpB,GAAIoF,EACA,IAAK,MAAMC,KAAOD,QACRC,IAKlB9c,KAAK8D,eAAegX,2BAA2BhB,OAAO,GACtD,MAAMnC,EAAsB,GAC5B,IAAK,MAAMmF,KAAO9c,KAAK2X,oBACsE,gBAA9E3X,KAAK+D,KAAKgB,eAAe+X,EAAIpd,KAAKod,EAAI9Y,OAAQ8Y,EAAIpd,KAAMod,EAAI9Y,OAAO,IACxC,kBAAxB8Y,EAAIpd,KAAKod,EAAI9Y,QAAoH,gBAAtFhE,KAAK+D,KAAKgB,eAAe+X,EAAIpd,KAAKod,EAAI9Y,MAAQ,GAAI8Y,EAAIpd,KAAMod,EAAI9Y,MAAQ,GAAG,GAEhIhE,KAAK0X,SAASlX,KAAK,CAAEsc,IAAKA,EAAIA,IAAKpd,KAAMod,EAAIpd,KAAKuB,MAAM,EAAG6b,EAAIpd,KAAKC,OAAS,KAG7EgY,EAAoBnX,KAAKsc,GAIjC,IAAK,MAAMA,KAAOnF,EAAqB,CAGnC,GAAI3X,KAAK0X,SAAS/X,OAAS,EAAG,CAE1B,MAAMsd,EAAqB,GACrBC,EAAuB,GAC7B,IAAK,IAAI3c,EAAI,EAAGA,EAAIP,KAAK0X,SAAS/X,OAAQY,IAAK,CAC3C,MAAM4c,EAAUnd,KAAK0X,SAASnX,GAC1BkD,EAAOwB,KAAKmY,cAAcD,EAAQzd,KAAMod,EAAIpd,QAC5Cud,EAAmBzc,KAAK2c,GACxBD,EAAqB1c,KAAKD,GAElC,CAEA,MAAM8c,EAAiBJ,EAAmB3P,KAAK,CAACgQ,EAAMC,IAASD,EAAK5d,KAAKC,OAAS4d,EAAK7d,KAAKC,QAE5F,IAAK,MAAMwd,KAAWE,QACZF,EAAQL,MAIlB,MAAMU,EAA6BN,EAAqB5P,OAAOd,UAC/D,IAAK,MAAMiR,KAASD,EAChBxd,KAAK0X,SAASoC,OAAO2D,EAAO,EAEpC,OACMX,EAAIA,KACd,CACJ,EAEJxZ,EAAQ6S,aAAeA,EACvBA,EAAazC,wBAA0B,MACvCyC,EAAayE,eAAiB,CAC1B,IAAItE,EAAyB9S,uBAC7B,IAAIiT,EAA6BlN,2BACjC,IAAIoN,EAAwB+G,sBAC5B,IAAI9G,EAA8Bb,4BAClC,IAAIW,EAA2BiH,yBAC/B,IAAI9G,EAA0B5N,wBAC9B,IAAI6N,EAA0B1K,wBAC9B,IAAI4K,EAA2B4G,yBAC/B,IAAIzG,EAAgC0G,8BACpC,IAAItH,EAAwBvM,sBAC5B,IAAI+M,EAAqCvL,mCACzC,IAAIhE,EAAwBqB,sBAC5B,IAAI2N,EAA8BlN,4B,mCCletC7J,OAAO8D,eAAeD,EAAS,aAAc,CAAEvE,OAAO,IACtDuE,EAAQ2B,UAAO,EACf,MAAMA,EAOF,mBAAO8M,CAAa7F,GAChB,OAAOA,EAAK5K,QAAQ,KAAO,KAAO4K,GAAoB,MAAZA,EAAK,GACnD,CAQA,gBAAO0F,CAAU1F,EAAM9E,GAEnB,GAAI8E,GAAoB,MAAZA,EAAK,GACb,OAAO,KAEX,MAAM4R,EAAe5R,EAAK5K,QAAQ,KAClC,GAAIwc,GAAgB,EAAG,CAEnB,GAAI5R,EAAKvM,OAASme,EAAe,GACQ,MAAlC5R,EAAK6R,OAAOD,EAAe,IACO,MAAlC5R,EAAK6R,OAAOD,EAAe,GAC9B,OAAO,KAEX,MAAME,EAAS9R,EAAKmF,OAAO,EAAGyM,GAE9B,GAAe,MAAXE,EACA,OAAO,KAGX,GAAI5W,EAAQ4W,GACR,OAAOA,CAEf,CACA,OAAO,IACX,CAMA,wBAAOrO,CAAkBsO,GACrB,GAAqB,OAAjBA,GAAiD,kBAAjBA,EAChC,OAAOA,EAEX,MAAM9V,EAAK8V,EAAa,OACxB,OAAO9V,GAAU,IACrB,CAOA,mCAAO2I,CAA6B/R,EAAOiP,GACvC,OAAQ/I,EAAK8C,mBAAmBhJ,KACxBiP,EAAQkQ,yBAA6C,kBAAVnf,IAAoC,MAAbA,EAAM,IAAckG,EAAKkZ,8BAA8Bpf,IACrI,CAMA,yBAAOgJ,CAAmBmO,GACtB,MAA0B,kBAAZA,GAAwBjR,EAAKmZ,cAAclf,KAAKgX,EAClE,CAMA,oCAAOiI,CAA8BE,GACjC,OAAOpZ,EAAKqZ,oBAAoBpf,KAAKmf,EACzC,CAMA,oBAAOxO,CAAc9Q,GACjB,OAAOA,IAA2B,kBAAVA,GAAuBA,GAA0B,kBAAVA,EACnE,CAMA,iBAAOkR,CAAWsO,GACd,OAAOC,QAAQD,GAAOtZ,EAAKwZ,UAAUvf,KAAKqf,GAC9C,CAMA,qBAAOzM,CAAeyM,GAClB,QAASA,GAAkB,MAAXA,EAAI,IAActZ,EAAKyZ,eAAexf,KAAKqf,EAC/D,CAMA,qBAAOtP,CAAeiH,GAClB,OAAOjR,EAAK0Z,eAAezI,EAC/B,CAOA,sBAAOrF,CAAgBzJ,EAASvH,GAC5B,MAAMd,EAAQqI,EAAQvH,GACtB,QAA0B,kBAAVd,IAAuBA,GAASA,EAAM,aAC1D,CAMA,wBAAO8U,CAAkBzM,GACrB,IAAK,MAAMvH,KAAOJ,OAAOC,KAAK0H,GAC1B,GAAInC,EAAK4L,gBAAgBzJ,EAASvH,GAC9B,OAAO,EAGf,OAAO,CACX,CAKA,gCAAOyP,CAA0BzP,GAC7B,OAAOA,EAAImT,WAAW,MAC1B,CAMA,gBAAO9B,CAAU3R,EAASC,GACtB,MAAMof,EAAWnf,OAAOC,KAAKH,GACvBsf,EAAWpf,OAAOC,KAAKF,GAC7B,OAAIof,EAASjf,SAAWkf,EAASlf,QAE1Bif,EAAShf,MAAOC,IACnB,MAAMif,EAASvf,EAAQM,GACjBkf,EAASvf,EAAQK,GACvB,OAAQif,IAAWC,GAAuB,OAAXD,GAChB,OAAXC,GACkB,kBAAXD,GACW,kBAAXC,GACP/e,KAAKkR,UAAU4N,EAAQC,IAEnC,EAIJ9Z,EAAKwZ,UAAY,6DAEjBxZ,EAAKyZ,eAAiB,eAEtBzZ,EAAKmZ,cAAgB,aAErBnZ,EAAKqZ,oBAAsB,eAE3BrZ,EAAK2J,mBAAqB,8BAE1B3J,EAAK8J,oBAAsB,gBAG3B9J,EAAK0Z,eAAiB,CAClB,eAAe,EACf,SAAS,EACT,cAAc,EACd,YAAY,EACZ,cAAc,EACd,UAAU,EACV,OAAO,EACP,WAAW,EACX,aAAa,EACb,UAAU,EACV,SAAS,EACT,aAAa,EACb,SAAS,EACT,SAAS,EACT,SAAS,EACT,WAAW,EACX,cAAc,EACd,cAAc,EACd,YAAY,EACZ,QAAQ,EACR,SAAS,EACT,UAAU,EACV,YAAY,EACZ,UAAU,GAGd1Z,EAAKoK,sBAAwB,CACzB,QACA,SACA,YACA,WACA,cAGJpK,EAAKuK,uBAAyB,CAC1B,aACA,SACA,MACA,SACA,QACA,QACA,QACA,UACA,WACA,OACA,QACA,SACA,YAGJvK,EAAKyK,sBAAwB,CACzB,WACA,aAGJzK,EAAKqN,WAAa,CACd,QACA,OACA,SACA,YACA,SACA,MACA,SAGJrN,EAAKmN,eAAiB,CAClB,QACA,OACA,UAEJ9O,EAAQ2B,KAAOA,C,qCC3Pf,IAAI+Z,EAAmBhf,MAAQA,KAAKgf,kBAAqBvf,OAAOwf,OAAS,SAAUC,EAAGC,EAAGC,EAAGC,QAC7Eva,IAAPua,IAAkBA,EAAKD,GAC3B,IAAIE,EAAO7f,OAAO8f,yBAAyBJ,EAAGC,GACzCE,KAAS,QAASA,GAAQH,EAAEK,WAAaF,EAAKG,UAAYH,EAAKI,gBAClEJ,EAAO,CAAEK,YAAY,EAAMlf,IAAK,WAAa,OAAO0e,EAAEC,EAAI,IAE5D3f,OAAO8D,eAAe2b,EAAGG,EAAIC,EAChC,EAAI,SAAUJ,EAAGC,EAAGC,EAAGC,QACTva,IAAPua,IAAkBA,EAAKD,GAC3BF,EAAEG,GAAMF,EAAEC,EACb,GACGQ,EAAgB5f,MAAQA,KAAK4f,cAAiB,SAAST,EAAG7b,GAC1D,IAAK,IAAIuc,KAAKV,EAAa,YAANU,GAAoBpgB,OAAOqgB,UAAUC,eAAeC,KAAK1c,EAASuc,IAAIb,EAAgB1b,EAAS6b,EAAGU,EAC3H,EACApgB,OAAO8D,eAAeD,EAAS,aAAc,CAAEvE,OAAO,IACtD6gB,EAAa,EAAQ,OAAwBtc,GAC7Csc,EAAa,EAAQ,OAAqBtc,GAC1Csc,EAAa,EAAQ,OAA8Btc,GACnDsc,EAAa,EAAQ,OAA0Btc,GAC/Csc,EAAa,EAAQ,OAAwBtc,GAC7Csc,EAAa,EAAQ,OAAkCtc,GACvDsc,EAAa,EAAQ,OAAetc,E,mCCtBpC,MAAM2c,EAAY,IAAIC,IAAI,CAAC,SAAU,iBAAkB,aAEvD,SAASC,EAAUC,GACjB,OAAO,IAAIC,MAAMD,EAAQ,CACvB,GAAApf,CAAKsf,EAAQzgB,GACX,OAAIogB,EAAUjf,IAAInB,IAIX0gB,QAAQvf,OAAOwf,UACxB,EACA,GAAA/f,CAAK6f,EAAQzgB,GACX,GAAIogB,EAAUjf,IAAInB,GAChB,OAGF,MAAM4gB,EAASF,QAAQ9f,OAAO+f,WAE9B,OAAIC,GAAiC,oBAAhBA,EAAOC,KACnBD,EAAOC,KAAKJ,GAGdG,CACT,EACA,GAAA9f,CAAK2f,EAAQzgB,EAAKd,GAChB,IAAIkhB,EAAUjf,IAAInB,GAIlB,OAAO0gB,QAAQ5f,OAAO6f,UACxB,GAEJ,CAEA,K,mCCjCA/gB,OAAO8D,eAAeD,EAAS,aAAc,CAAEvE,OAAO,G,wBCDtD,IAAI,OAAEkE,GAAW,EAAQ,OAErB0d,EAAI,CAAC,EAELC,EAAgBD,EAAEC,WAAgB,EAClCC,EAAgBF,EAAEE,YAAgB,EAClCC,EAAgBH,EAAEG,aAAgB,EAClCC,EAAgBJ,EAAEI,cAAgB,EAClCC,EAAgBL,EAAEK,MAAgB,EAClCC,EAAgBN,EAAEM,MAAgB,EAClCC,EAAgBP,EAAEO,KAAgB,EAClCC,EAAgBR,EAAEQ,MAAgB,EAClCC,EAAgBT,EAAES,KAAgB,EAClCC,EAAgBV,EAAEU,OAAgB,GAClCC,EAAgBX,EAAEW,OAAgB,GAElCC,EAAUZ,EAAEY,MAAU,GACtBC,EAAUb,EAAEa,KAAU,GACtBC,EAAUd,EAAEc,MAAU,GACtBC,EAAUf,EAAEe,MAAU,GACtBC,EAAUhB,EAAEgB,MAAU,GACtBC,EAAUjB,EAAEiB,OAAU,GACtBC,EAAUlB,EAAEkB,OAAU,GACtBC,EAAUnB,EAAEmB,OAAU,GACtBC,EAAUpB,EAAEoB,OAAU,GACtBC,EAAUrB,EAAEqB,MAAU,GACtBC,EAAUtB,EAAEsB,MAAU,GACtBC,EAAUvB,EAAEuB,MAAU,GACtBC,EAAUxB,EAAEwB,QAAU,GACtBC,EAAUzB,EAAEyB,QAAU,GACtBC,EAAU1B,EAAE0B,QAAU,GACtBC,EAAU3B,EAAE2B,QAAU,GACtBC,EAAU5B,EAAE4B,QAAU,GACtBC,EAAU7B,EAAE6B,QAAU,IACtBC,EAAU9B,EAAE8B,QAAU,IACtBC,EAAU/B,EAAE+B,QAAU,IAEtBC,EAAUhC,EAAEgC,MAAU,IACtBC,EAAUjC,EAAEiC,IAAU,IAEtBC,EAAUlC,EAAEkC,OAAU,IACtBC,EAAUnC,EAAEmC,MAAU,IAEtBC,EAAkB,KAAKC,WAAW,GAClCC,EAAkB,IAAKD,WAAW,GAClCE,EAAkB,KAAKF,WAAW,GAClCG,EAAkB,KAAKH,WAAW,GAClCI,EAAkB,KAAKJ,WAAW,GAClCK,EAAkB,KAAKL,WAAW,GAClCM,EAAkB,KAAKN,WAAW,GAElCO,EAAqB,MAEzB,SAASC,EAAMC,GACb,OAAOxgB,EAAOugB,MAAQvgB,EAAOugB,MAAMC,GAAQ,IAAIxgB,EAAOwgB,EACxD,CAEA,SAASrN,IACPpW,KAAK0jB,OAASnC,EACdvhB,KAAKjB,WAAQ+F,EAEb9E,KAAK2jB,YAAS7e,EACd9E,KAAK4jB,aAAeJ,EAAMD,GAC1BvjB,KAAK6jB,mBAAqB,EAC1B7jB,KAAK8jB,aAAUhf,EACf9E,KAAK+jB,mBAAgBjf,EAErB9E,KAAKH,SAAMiF,EACX9E,KAAKiY,UAAOnT,EACZ9E,KAAKwc,MAAQ,GACbxc,KAAKkB,MAAQyhB,EACb3iB,KAAKgkB,gBAAkB,EACvBhkB,KAAKikB,kBAAoB,EACzBjkB,KAAKkkB,WAAa,CAAE,EAAKV,EAAM,GAAI,EAAKA,EAAM,GAAI,EAAKA,EAAM,IAG7DxjB,KAAKZ,QAAU,CACjB,CAGAgX,EAAO+N,OAAS,SAAUC,GAExB,IADA,IAAI1kB,EAAOD,OAAOC,KAAKihB,GACdpgB,EAAI,EAAG8jB,EAAI3kB,EAAKC,OAAQY,EAAI8jB,EAAG9jB,IAAK,CAC3C,IAAIV,EAAMH,EAAKa,GACf,GAAIogB,EAAE9gB,KAASukB,EAAQ,OAAOvkB,CAChC,CACA,OAAOukB,GAAS,KAAOA,EAAKviB,SAAS,GACvC,EAEA,IAAIyiB,EAAQlO,EAAO0J,UACnBwE,EAAMtH,QAAU,SAAUuH,GAAO,MAAMA,CAAK,EAC5CD,EAAME,UAAY,SAAUC,EAAQlkB,GAClCP,KAAK0jB,OAASlC,EACdxhB,KAAKgd,QAAQ,IAAI7b,MAAM,cAAgBuN,KAAKC,UAAU+V,OAAOC,aAAaF,EAAOlkB,KAAO,gBAAkBA,EAAI,aAAe6V,EAAO+N,OAAOnkB,KAAK0jB,SAClJ,EACAY,EAAMM,iBAAmB,SAAUC,GAC7B7kB,KAAK6jB,oBAAsBN,IAC7BvjB,KAAK2jB,QAAU3jB,KAAK4jB,aAAa/hB,SAAS,QAC1C7B,KAAK6jB,mBAAqB,GAG5B7jB,KAAK4jB,aAAa5jB,KAAK6jB,sBAAwBgB,CACjD,EACAP,EAAMQ,gBAAkB,SAAUC,EAAKC,EAAO3jB,GAC5C,IAAIoiB,EAAOsB,EAAIplB,OACM,kBAAVqlB,IAILvB,EAHe,kBAARpiB,EACLA,EAAM,EAED0jB,EAAIplB,OAASqlB,EAAQ3jB,EAErBA,EAAM2jB,EAGRD,EAAIplB,OAASqlB,GAIpBvB,EAAO,IACTA,EAAO,GAGLzjB,KAAK6jB,mBAAqBJ,EAAOF,IACnCvjB,KAAK2jB,QAAU3jB,KAAK4jB,aAAa/hB,SAAS,OAAQ,EAAG7B,KAAK6jB,oBAC1D7jB,KAAK6jB,mBAAqB,GAG5BkB,EAAIE,KAAKjlB,KAAK4jB,aAAc5jB,KAAK6jB,mBAAoBmB,EAAO3jB,GAC5DrB,KAAK6jB,oBAAsBJ,CAC7B,EACAa,EAAM5K,MAAQ,SAAU+K,GAEtB,IAAIS,EADkB,kBAAXT,IAAqBA,EAAS,IAAIxhB,EAAOwhB,IAEpD,IAAK,IAAIlkB,EAAI,EAAG8jB,EAAII,EAAO9kB,OAAQY,EAAI8jB,EAAG9jB,IACxC,GAAIP,KAAK0jB,SAAWnC,GAGlB,GAFA2D,EAAIT,EAAOlkB,GACXP,KAAKZ,SACI,MAAN8lB,EAAallB,KAAKmlB,QAAQvE,EAAY,UACnC,GAAS,MAANsE,EAAallB,KAAKmlB,QAAQtE,EAAa,UAC1C,GAAS,KAANqE,EAAallB,KAAKmlB,QAAQrE,EAAc,UAC3C,GAAS,KAANoE,EAAallB,KAAKmlB,QAAQpE,EAAe,UAC5C,GAAS,KAANmE,EAAallB,KAAKmlB,QAAQnE,EAAO,UACpC,GAAS,KAANkE,EAAallB,KAAKmlB,QAAQlE,EAAO,UACpC,GAAS,MAANiE,EAAallB,KAAK0jB,OAASjC,OAC9B,GAAS,MAANyD,EAAallB,KAAK0jB,OAAS9B,OAC9B,GAAS,MAANsD,EAAallB,KAAK0jB,OAAS1B,OAC9B,GAAS,KAANkD,EACPllB,KAAK2jB,OAAS,GACd3jB,KAAK6jB,mBAAqB,EAC1B7jB,KAAK0jB,OAASrB,OACV,GAAS,KAAN6C,EAAallB,KAAK2jB,OAAS,IAAK3jB,KAAK0jB,OAASvB,OAErD,GAAI+C,GAAK,IAAQA,EAAI,GACnBllB,KAAK2jB,OAASe,OAAOC,aAAaO,GAAIllB,KAAK0jB,OAAStB,OAC/C,GAAU,KAAN8C,GAAoB,IAANA,GAAoB,KAANA,GAAoB,KAANA,EAGnD,OAAOllB,KAAKwkB,UAAUC,EAAQlkB,QAG9B,GAAIP,KAAK0jB,SAAWrB,EAIxB,GAHA6C,EAAIT,EAAOlkB,GAGPP,KAAKgkB,gBAAkB,EAAG,CAC5B,IAAK,IAAIoB,EAAI,EAAGA,EAAIplB,KAAKgkB,gBAAiBoB,IACxCplB,KAAKkkB,WAAWlkB,KAAKikB,mBAAmBjkB,KAAKikB,kBAAoBjkB,KAAKgkB,gBAAkBoB,GAAKX,EAAOW,GAGtGplB,KAAK8kB,gBAAgB9kB,KAAKkkB,WAAWlkB,KAAKikB,oBAC1CjkB,KAAKikB,kBAAoBjkB,KAAKgkB,gBAAkB,EAChDzjB,EAAIA,EAAI6kB,EAAI,CACd,MAAO,GAA6B,IAAzBplB,KAAKgkB,iBAAyBkB,GAAK,IAAK,CACjD,GAAIA,GAAK,KAAOA,EAAI,IAClB,OAAOllB,KAAKgd,QAAQ,IAAI7b,MAAM,uCAAyCZ,EAAI,aAAe6V,EAAO+N,OAAOnkB,KAAK0jB,UAK/G,GAHKwB,GAAK,KAASA,GAAK,MAAMllB,KAAKikB,kBAAoB,GAClDiB,GAAK,KAASA,GAAK,MAAMllB,KAAKikB,kBAAoB,GAClDiB,GAAK,KAASA,GAAK,MAAMllB,KAAKikB,kBAAoB,GAClDjkB,KAAKikB,kBAAoB1jB,EAAKkkB,EAAO9kB,OAAQ,CAChD,IAAK,IAAIyf,EAAI,EAAGA,GAAMqF,EAAO9kB,OAAS,EAAIY,EAAI6e,IAC5Cpf,KAAKkkB,WAAWlkB,KAAKikB,mBAAmB7E,GAAKqF,EAAOlkB,EAAI6e,GAE1Dpf,KAAKgkB,gBAAmBzjB,EAAIP,KAAKikB,kBAAqBQ,EAAO9kB,OAC7DY,EAAIkkB,EAAO9kB,OAAS,CACtB,MACEK,KAAK8kB,gBAAgBL,EAAQlkB,EAAGA,EAAIP,KAAKikB,mBACzC1jB,EAAIA,EAAIP,KAAKikB,kBAAoB,CAErC,MAAO,GAAU,KAANiB,EACTllB,KAAK0jB,OAASnC,EACdvhB,KAAK2jB,QAAU3jB,KAAK4jB,aAAa/hB,SAAS,OAAQ,EAAG7B,KAAK6jB,oBAC1D7jB,KAAK6jB,mBAAqB,EAC1B7jB,KAAKmlB,QAAQ9D,EAAQrhB,KAAK2jB,QAC1B3jB,KAAKZ,QAAU6D,EAAOoiB,WAAWrlB,KAAK2jB,OAAQ,QAAU,EACxD3jB,KAAK2jB,YAAS7e,OAEX,GAAU,KAANogB,EACPllB,KAAK0jB,OAASpB,MAEX,MAAI4C,GAAK,IAEV,OAAOllB,KAAKwkB,UAAUC,EAAQlkB,GAFZP,KAAK4kB,iBAAiBM,EAG5C,MACI,GAAIllB,KAAK0jB,SAAWpB,EAExB,GADA4C,EAAIT,EAAOlkB,GACF,KAAN2kB,EAAallB,KAAK4kB,iBAAiBM,GAAIllB,KAAK0jB,OAASrB,OAClD,GAAS,KAAN6C,EAAallB,KAAK4kB,iBAAiB7B,GAAa/iB,KAAK0jB,OAASrB,OACjE,GAAS,KAAN6C,EAAallB,KAAK4kB,iBAAiB3B,GAAgBjjB,KAAK0jB,OAASrB,OACpE,GAAS,KAAN6C,EAAallB,KAAK4kB,iBAAiB1B,GAAYljB,KAAK0jB,OAASrB,OAChE,GAAS,MAAN6C,EAAallB,KAAK4kB,iBAAiBzB,GAAYnjB,KAAK0jB,OAASrB,OAChE,GAAS,MAAN6C,EAAallB,KAAK4kB,iBAAiBxB,GAAUpjB,KAAK0jB,OAASrB,OAC9D,GAAS,MAAN6C,EAAallB,KAAK4kB,iBAAiBvB,GAAkBrjB,KAAK0jB,OAASrB,OACtE,GAAS,MAAN6C,EAAallB,KAAK4kB,iBAAiBtB,GAAMtjB,KAAK0jB,OAASrB,MAC1D,IAAS,MAAN6C,EAEP,OAAOllB,KAAKwkB,UAAUC,EAAQlkB,GAFVP,KAAK8jB,QAAU,GAAI9jB,KAAK0jB,OAASnB,CAGvD,MACI,GAAIviB,KAAK0jB,SAAWnB,GAAWviB,KAAK0jB,SAAWlB,GAAWxiB,KAAK0jB,SAAWjB,GAAWziB,KAAK0jB,SAAWhB,EAAQ,CAGjH,GAFAwC,EAAIT,EAAOlkB,KAEN2kB,GAAK,IAAQA,EAAI,IAAUA,EAAI,IAAQA,GAAK,IAAUA,EAAI,IAAQA,GAAK,KAoB1E,OAAOllB,KAAKwkB,UAAUC,EAAQlkB,GAlB9B,GADAP,KAAK8jB,SAAWY,OAAOC,aAAaO,GAChCllB,KAAK0jB,WAAahB,EAAS,CAC7B,IAAI4C,EAASC,SAASvlB,KAAK8jB,QAAS,IACpC9jB,KAAK8jB,aAAUhf,OACYA,IAAvB9E,KAAK+jB,eAA+BuB,GAAU,OAAUA,EAAS,OACnEtlB,KAAK8kB,gBAAgB,IAAI7hB,EAAOyhB,OAAOC,aAAa3kB,KAAK+jB,cAAeuB,KACxEtlB,KAAK+jB,mBAAgBjf,QACWA,IAAvB9E,KAAK+jB,eAA+BuB,GAAU,OAAUA,EAAS,MAC1EtlB,KAAK+jB,cAAgBuB,QAEMxgB,IAAvB9E,KAAK+jB,gBACP/jB,KAAK8kB,gBAAgB,IAAI7hB,EAAOyhB,OAAOC,aAAa3kB,KAAK+jB,iBACzD/jB,KAAK+jB,mBAAgBjf,GAEvB9E,KAAK8kB,gBAAgB,IAAI7hB,EAAOyhB,OAAOC,aAAaW,MAEtDtlB,KAAK0jB,OAASrB,CAChB,CAIJ,MAAO,GAAIriB,KAAK0jB,SAAWvB,GAAWniB,KAAK0jB,SAAWtB,EAGlD,OAFA8C,EAAIT,EAAOlkB,GAEH2kB,GACN,KAAK,GACL,KAAK,GACL,KAAK,GACL,KAAK,GACL,KAAK,GACL,KAAK,GACL,KAAK,GACL,KAAK,GACL,KAAK,GACL,KAAK,GACL,KAAK,GACL,KAAK,IACL,KAAK,GACL,KAAK,GACL,KAAK,GACHllB,KAAK2jB,QAAUe,OAAOC,aAAaO,GACnCllB,KAAK0jB,OAAStB,EACd,MACF,QACEpiB,KAAK0jB,OAASnC,EACd,IAAIrI,EAAQlZ,KAAKwlB,cAAcxlB,KAAK2jB,OAAQc,EAAQlkB,GACpD,GAAI2Y,EACF,OAAOA,EAGTlZ,KAAKZ,QAAUY,KAAK2jB,OAAOhkB,OAAS,EACpCK,KAAK2jB,YAAS7e,EACdvE,IACA,WAEF,GAAIP,KAAK0jB,SAAWjC,EAAM,CAC9B,GAAkB,MAAdgD,EAAOlkB,GACJ,OAAOP,KAAKwkB,UAAUC,EAAQlkB,GADXP,KAAK0jB,OAAShC,CAE1C,MAAM,GAAI1hB,KAAK0jB,SAAWhC,EAAM,CAC9B,GAAkB,MAAd+C,EAAOlkB,GACJ,OAAOP,KAAKwkB,UAAUC,EAAQlkB,GADXP,KAAK0jB,OAAS/B,CAE1C,MAAM,GAAI3hB,KAAK0jB,SAAW/B,EAAM,CAC9B,GAAkB,MAAd8C,EAAOlkB,GACJ,OAAOP,KAAKwkB,UAAUC,EAAQlkB,GADXP,KAAK0jB,OAASnC,EAAOvhB,KAAKmlB,QAAQjE,GAAM,GAAOlhB,KAAKZ,QAAS,CAEzF,MAAM,GAAIY,KAAK0jB,SAAW9B,EAAO,CAC/B,GAAkB,KAAd6C,EAAOlkB,GACJ,OAAOP,KAAKwkB,UAAUC,EAAQlkB,GADXP,KAAK0jB,OAAS7B,CAE1C,MAAM,GAAI7hB,KAAK0jB,SAAW7B,EAAO,CAC/B,GAAkB,MAAd4C,EAAOlkB,GACJ,OAAOP,KAAKwkB,UAAUC,EAAQlkB,GADXP,KAAK0jB,OAAS5B,CAE1C,MAAM,GAAI9hB,KAAK0jB,SAAW5B,EAAO,CAC/B,GAAkB,MAAd2C,EAAOlkB,GACJ,OAAOP,KAAKwkB,UAAUC,EAAQlkB,GADXP,KAAK0jB,OAAS3B,CAE1C,MAAM,GAAI/hB,KAAK0jB,SAAW3B,EAAO,CAC/B,GAAkB,MAAd0C,EAAOlkB,GACJ,OAAOP,KAAKwkB,UAAUC,EAAQlkB,GADXP,KAAK0jB,OAASnC,EAAOvhB,KAAKmlB,QAAQhE,GAAO,GAAQnhB,KAAKZ,QAAS,CAE3F,MAAM,GAAIY,KAAK0jB,SAAW1B,EAAM,CAC9B,GAAkB,MAAdyC,EAAOlkB,GACJ,OAAOP,KAAKwkB,UAAUC,EAAQlkB,GADXP,KAAK0jB,OAASzB,CAE1C,MAAM,GAAIjiB,KAAK0jB,SAAWzB,EAAM,CAC9B,GAAkB,MAAdwC,EAAOlkB,GACJ,OAAOP,KAAKwkB,UAAUC,EAAQlkB,GADXP,KAAK0jB,OAASxB,CAE1C,MAAM,GAAIliB,KAAK0jB,SAAWxB,EAAM,CAC9B,GAAkB,MAAduC,EAAOlkB,GACJ,OAAOP,KAAKwkB,UAAUC,EAAQlkB,GADXP,KAAK0jB,OAASnC,EAAOvhB,KAAKmlB,QAAQ/D,EAAM,MAAOphB,KAAKZ,QAAU,CAE1F,CAEJ,EACAklB,EAAMa,QAAU,SAAUM,EAAO1mB,GAEjC,EAEAulB,EAAMoB,WAAa,SAAUD,EAAO1mB,GAClCiB,KAAK0jB,OAASlC,EACdxhB,KAAKgd,QAAQ,IAAI7b,MAAM,cAAgBiV,EAAO+N,OAAOsB,IAAU1mB,EAAS,IAAM2P,KAAKC,UAAU5P,GAAS,IAAO,IAAM,aAAeqX,EAAO+N,OAAOnkB,KAAKkB,QACvJ,EACAojB,EAAM9jB,KAAO,WACXR,KAAKwc,MAAMhc,KAAK,CAACzB,MAAOiB,KAAKjB,MAAOc,IAAKG,KAAKH,IAAKoY,KAAMjY,KAAKiY,MAChE,EACAqM,EAAMqB,IAAM,WACV,IAAI5mB,EAAQiB,KAAKjB,MACb6mB,EAAS5lB,KAAKwc,MAAMmJ,MACxB3lB,KAAKjB,MAAQ6mB,EAAO7mB,MACpBiB,KAAKH,IAAM+lB,EAAO/lB,IAClBG,KAAKiY,KAAO2N,EAAO3N,KACnBjY,KAAKkY,KAAKnZ,GACLiB,KAAKiY,OAAQjY,KAAKkB,MAAQyhB,EACjC,EACA2B,EAAMpM,KAAO,SAAUnZ,GACjBiB,KAAKiY,OAAQjY,KAAKkB,MAAQ+f,GAC9BjhB,KAAKuc,QAAQxd,EACf,EACAulB,EAAM/H,QAAU,SAAUxd,GAE1B,EACAulB,EAAMa,QAAU,SAAUM,EAAO1mB,GAC/B,GAAGiB,KAAKkB,QAAUyhB,EAChB,GAAG8C,IAAUpE,GAAUoE,IAAUnE,GAAUmE,IAAUvE,GAAQuE,IAAUtE,GAASsE,IAAUrE,EACpFphB,KAAKjB,QACPiB,KAAKjB,MAAMiB,KAAKH,KAAOd,GAEzBiB,KAAKkY,KAAKnZ,QACN,GAAG0mB,IAAU7E,EACjB5gB,KAAKQ,OACDR,KAAKjB,MACPiB,KAAKjB,MAAQiB,KAAKjB,MAAMiB,KAAKH,KAAO,CAAC,EAErCG,KAAKjB,MAAQ,CAAC,EAEhBiB,KAAKH,SAAMiF,EACX9E,KAAKkB,MAAQ0hB,EACb5iB,KAAKiY,KAAO4K,OACR,GAAG4C,IAAU3E,EACjB9gB,KAAKQ,OACDR,KAAKjB,MACPiB,KAAKjB,MAAQiB,KAAKjB,MAAMiB,KAAKH,KAAO,GAEpCG,KAAKjB,MAAQ,GAEfiB,KAAKH,IAAM,EACXG,KAAKiY,KAAO6K,EACZ9iB,KAAKkB,MAAQyhB,OACT,GAAG8C,IAAU5E,EAAY,CAC7B,GAAI7gB,KAAKiY,OAAS4K,EAGhB,OAAO7iB,KAAK0lB,WAAWD,EAAO1mB,GAF9BiB,KAAK2lB,KAIT,KAAM,IAAGF,IAAU1E,EAOjB,OAAO/gB,KAAK0lB,WAAWD,EAAO1mB,GAN9B,GAAIiB,KAAKiY,OAAS6K,EAGhB,OAAO9iB,KAAK0lB,WAAWD,EAAO1mB,GAF9BiB,KAAK2lB,KAMT,MACI,GAAG3lB,KAAKkB,QAAU0hB,EACtB,GAAI6C,IAAUpE,EACZrhB,KAAKH,IAAMd,EACXiB,KAAKkB,MAAQ8f,MACR,IAAIyE,IAAU5E,EAGnB,OAAO7gB,KAAK0lB,WAAWD,EAAO1mB,GAF9BiB,KAAK2lB,KAGP,MACI,GAAG3lB,KAAKkB,QAAU8f,EAAM,CAC5B,GAAIyE,IAAUzE,EACP,OAAOhhB,KAAK0lB,WAAWD,EAAO1mB,GADdiB,KAAKkB,MAAQyhB,CAEtC,KAAM,IAAG3iB,KAAKkB,QAAU+f,EAWtB,OAAOjhB,KAAK0lB,WAAWD,EAAO1mB,GAV9B,GAAI0mB,IAAUxE,EACRjhB,KAAKiY,OAAS6K,GAAS9iB,KAAKH,MAAOG,KAAKkB,MAAQyhB,GAC3C3iB,KAAKiY,OAAS4K,IAAU7iB,KAAKkB,MAAQ0hB,OAEzC,MAAI6C,IAAU1E,GAAiB/gB,KAAKiY,OAAS6K,GAAS2C,IAAU5E,GAAe7gB,KAAKiY,OAAS4K,GAGlG,OAAO7iB,KAAK0lB,WAAWD,EAAO1mB,GAF9BiB,KAAK2lB,KAGP,CAGF,CACF,EAIArB,EAAMkB,cAAgB,SAAUK,EAAMpB,EAAQlkB,GAC5C,IAAIkgB,EAASqF,OAAOD,GAEpB,GAAIE,MAAMtF,GACR,OAAOzgB,KAAKwkB,UAAUC,EAAQlkB,GAG3BslB,EAAK9M,MAAM,WAAa8M,GAAUpF,EAAO5e,YAAcgkB,EAE1D7lB,KAAKmlB,QAAQ9D,EAAQwE,GAErB7lB,KAAKmlB,QAAQ7D,EAAQb,EAEzB,EAEArK,EAAOuK,EAAIA,EAEXtd,EAAOC,QAAU8S,C,qCCxajB,IAAI4I,EAAmBhf,MAAQA,KAAKgf,kBAAqBvf,OAAOwf,OAAS,SAAUC,EAAGC,EAAGC,EAAGC,QAC7Eva,IAAPua,IAAkBA,EAAKD,GAC3B,IAAIE,EAAO7f,OAAO8f,yBAAyBJ,EAAGC,GACzCE,KAAS,QAASA,GAAQH,EAAEK,WAAaF,EAAKG,UAAYH,EAAKI,gBAClEJ,EAAO,CAAEK,YAAY,EAAMlf,IAAK,WAAa,OAAO0e,EAAEC,EAAI,IAE5D3f,OAAO8D,eAAe2b,EAAGG,EAAIC,EAChC,EAAI,SAAUJ,EAAGC,EAAGC,EAAGC,QACTva,IAAPua,IAAkBA,EAAKD,GAC3BF,EAAEG,GAAMF,EAAEC,EACb,GACGQ,EAAgB5f,MAAQA,KAAK4f,cAAiB,SAAST,EAAG7b,GAC1D,IAAK,IAAIuc,KAAKV,EAAa,YAANU,GAAoBpgB,OAAOqgB,UAAUC,eAAeC,KAAK1c,EAASuc,IAAIb,EAAgB1b,EAAS6b,EAAGU,EAC3H,EACApgB,OAAO8D,eAAeD,EAAS,aAAc,CAAEvE,OAAO,IACtD6gB,EAAa,EAAQ,OAAuBtc,E,qCCf5C7D,OAAO8D,eAAeD,EAAS,aAAc,CAAEvE,OAAO,IACtDuE,EAAQuR,qBAAuBvR,EAAQoK,6BAA0B,EACjE,MAAME,EAA6B,EAAQ,OACrCC,EAAe,EAAQ,OACvBpK,EAAS,EAAQ,OAIvB,MAAMiK,EACF,WAAA3N,CAAYqP,GACRpP,KAAKoP,WAAaA,CACtB,CAIA,aAAAvF,GACI,OAAO7J,KAAKoP,UAChB,CAsBA,UAAAW,CAAW7D,EAAM8Z,EAAahY,EAAU1K,EAAQuR,sBAC5C,MAAMoJ,EAAeje,KAAKoP,WAAWlD,GAErC,GAAqB,OAAjB+R,GAA0BA,GAAwC,OAAxBA,EAAa,OACvD,OAAO,KAGX,IAAIgI,GAAkB,EACtB,GAAIhI,GAAgB+H,EAAa,CAC7B,MAAMjnB,EAAQ0E,EAAOwB,KAAK0K,kBAAkBsO,GAC5C,GAAIlf,GAASA,IAAUmN,EAAM,CACzB,GAAqB,kBAAVnN,IAAwB0E,EAAOwB,KAAKgL,WAAWlR,IAAW0E,EAAOwB,KAAKgK,eAAelQ,IAO5F,OAAOA,EALF0E,EAAOwB,KAAK8C,mBAAmBhJ,KAChCknB,GAAkB,EAM9B,CACJ,CAEA,MAAMjI,EAASva,EAAOwB,KAAK2M,UAAU1F,EAAMlM,KAAKoP,YAC1C8W,EAAQlmB,KAAKoP,WAAW,UACxB+W,KAAmBD,GAAmB,KAAVA,IAAiBA,EAAM5kB,QAAQ,KAAO,EAClE8kB,EAAOpmB,KAAKoP,WAAW,SACvBiX,EAAmB5iB,EAAOwB,KAAK8C,mBAAmBmE,GACxD,GAAI8R,EAAQ,CACR,MAAMsI,EAAqBtmB,KAAKoP,WAAW4O,GACrCjf,EAAQ0E,EAAOwB,KAAK0K,kBAAkB2W,GAC5C,GAAIvnB,EAAO,CACP,GAAkC,kBAAvBunB,GAAoCtY,EAAQuY,oBAWnD,GAAiB,MAAbxnB,EAAM,KAAesnB,IAAqBC,EAAmB,cAAgBpa,KAAQlM,KAAKoP,YAE1F,OAAOlD,OATX,IAAKzI,EAAOwB,KAAK6L,6BAA6B/R,EAAOiP,GAEjD,OAAO9B,EAUf,OAAOnN,EAAQmN,EAAKmF,OAAO2M,EAAOre,OAAS,EAC/C,CACJ,KACK,IAAIqmB,IAAiBE,GAAmB,KAAVA,GAAkBlY,EAAQwY,0BAA6BJ,GAAQD,KAC1FE,IAAqB5iB,EAAOwB,KAAK8M,aAAa7F,GAAO,CACzD,GAAIia,EAAe,CACf,GAAInY,EAAQwY,yBACR,OAASN,GAASE,GAAQ,EAAIxY,EAA2BR,SAAS8Y,EAAOE,GAAQ,IAAMla,EAGvF,MAAM,IAAI2B,EAAanH,WAAW,sCAAsCwF,kBAAqBga,qBAA0BrY,EAAalH,YAAY2K,sBAExJ,CAEI,OAAO4U,EAAQha,CAEvB,CACK,IAAK8Z,GAAeI,IAASC,IAAqB5iB,EAAOwB,KAAK8M,aAAa7F,GAC5E,OAAO,EAAI0B,EAA2BR,SAASlB,EAAMka,EACzD,CAEA,GAAIH,EACA,OAAO/Z,EAGP,MAAM,IAAI2B,EAAanH,WAAW,gDAAgDwF,QAAWwC,KAAKC,UAAUsP,MAAkBpQ,EAAalH,YAAYuI,oBAE/J,CAWA,UAAAuX,CAAWlI,EAAK2H,GAEZ,GAAIA,GAASlmB,KAAKoP,WAAW,WAAamP,EAAIvL,WAAWhT,KAAKoP,WAAW,WACrE,OAAOmP,EAAIlN,OAAOrR,KAAKoP,WAAW,UAAUzP,QAGhD,IAAKumB,GAASlmB,KAAKoP,WAAW,UAAYmP,EAAIvL,WAAWhT,KAAKoP,WAAW,UACrE,OAAOmP,EAAIlN,OAAOrR,KAAKoP,WAAW,SAASzP,QAK/C,MAAM+mB,EAAoB,CAAE1I,OAAQ,GAAI2I,OAAQpI,GAChD,IAAK,MAAM1e,KAAOG,KAAKoP,WAAY,CAC/B,MAAMrQ,EAAQiB,KAAKoP,WAAWvP,GAC9B,GAAId,IAAU0E,EAAOwB,KAAK8C,mBAAmBlI,GAAM,CAC/C,MAAMiT,EAAarP,EAAOwB,KAAK0K,kBAAkB5Q,GACjD,GAAIwf,EAAIvL,WAAWF,GAAa,CAC5B,MAAM6T,EAASpI,EAAIlN,OAAOyB,EAAWnT,QACrC,GAAKgnB,EAMIA,EAAOhnB,OAAS+mB,EAAkBC,OAAOhnB,SAE9C+mB,EAAkB1I,OAASne,EAC3B6mB,EAAkBC,OAASA,QAR3B,GAAIT,EAEA,OAAOrmB,CAQnB,CACJ,CACJ,CAEA,OAAI6mB,EAAkB1I,OACX0I,EAAkB1I,OAAS,IAAM0I,EAAkBC,OAEvDpI,CACX,EAEJjb,EAAQoK,wBAA0BA,EAClCpK,EAAQuR,qBAAuB,CAC3B0R,oBAAoB,EACpBrI,yBAAyB,EACzBsI,0BAA0B,E,qCCzK9B/mB,OAAO8D,eAAeD,EAAS,aAAc,CAAEvE,OAAO,IACtDuE,EAAQ4K,yBAAsB,EAC9B,MAAML,EAAe,EAAQ,OACvBqJ,EAAqB,EAAQ,MAC7BtJ,EAA6B,EAAQ,OAI3C,MAAMM,EACF,WAAAnO,CAAY6mB,GACR5mB,KAAK4mB,QAAUA,CACnB,CACA,UAAM1S,CAAKgB,GACP,MAAM2R,QAAkB7mB,KAAK4mB,SAAWE,OAAO5R,EAAK,CAAEmD,QAAS,IAAI0O,QAAQ,CAAEC,OAAQ,0BACrF,GAAIH,EAASI,IAAMJ,EAASxO,QAAS,CACjC,IAAID,EAAYyO,EAASxO,QAAQ5X,IAAI,gBACrC,GAAI2X,EAAW,CACX,MAAM8O,EAAW9O,EAAU9W,QAAQ,KAC/B4lB,EAAW,IACX9O,EAAYA,EAAU/G,OAAO,EAAG6V,GAExC,CACA,GAAkB,wBAAd9O,EAEA,aAAcyO,EAASM,OAIvB,GAAIN,EAASxO,QAAQrX,IAAI,QAAS,CAC9B,IAAIomB,EAcJ,GAbAP,EAASxO,QAAQK,QAAQ,CAAC3Z,EAAOc,KAC7B,GAAY,SAARA,EAAgB,CAChB,MAAM8Y,GAAa,EAAIzB,EAAmBhX,OAAOnB,GACjD,IAAK,MAAM6B,KAAQ+X,EAAWlY,IAAI,OAAQ,uBACtC,GAAiB,cAAbG,EAAKT,IAAqB,CAC1B,GAAIinB,EACA,MAAM,IAAIjmB,MAAM,kDAAoD+T,GAExEkS,GAAe,EAAIxZ,EAA2BR,SAASxM,EAAKW,IAAK2T,EACrE,CAER,IAEAkS,EACA,OAAOpnB,KAAKkU,KAAKkT,EAEzB,CACA,MAAM,IAAIvZ,EAAanH,WAAW,kCAAkC0R,IAAavK,EAAalH,YAAY8R,wBAElH,CAEI,MAAM,IAAItX,MAAM0lB,EAASQ,YAAc,gBAAgBR,EAASS,SAExE,EAEJhkB,EAAQ4K,oBAAsBA,C,qCCvD9BzO,OAAO8D,eAAeD,EAAS,aAAc,CAAEvE,OAAO,IACtDuE,EAAQgU,oBAAiB,EACzB,MAAM5T,EAA0B,EAAQ,OAClCmK,EAAe,EAAQ,OACvB0Z,EAAgB,EAAQ,MACxBC,EAAiB,EAAQ,OAI/B,MAAMlQ,EACF,WAAAvX,CAAYiO,GAERhO,KAAKynB,cAAgB,IAAI/jB,EAAwBiK,cAAc,CAAEM,eAAgBD,EAAQC,eAAgBG,eAAgBJ,EAAQ0Z,wBACjI1nB,KAAKwJ,mBAAqBwE,EAAQxE,iBAClCxJ,KAAK2S,QAAU3E,EAAQ2E,QACvB3S,KAAK2nB,wBAA0B3Z,EAAQ2Z,sBACvC3nB,KAAK4nB,mBAAqB5Z,EAAQ4Z,iBAClC5nB,KAAKqQ,eAAiBrC,EAAQqC,gBAAkBmX,EAAerR,aAAazC,wBAC5E1T,KAAK4L,eAAiBoC,EAAQpC,aAC9B5L,KAAK6a,uBAAyB7M,EAAQ6M,qBACtC7a,KAAK6nB,aAAe7Z,EAAQ6Z,aAC5B7nB,KAAK8nB,aAAe9Z,EAAQ8Z,aAC5B9nB,KAAKsQ,sBAAwBtC,EAAQsC,sBACrCtQ,KAAKyN,yCAA2CO,EAAQP,yCACxDzN,KAAKuG,SAA8B,IAApByH,EAAQzH,QACvBvG,KAAK+nB,yBAA2B/Z,EAAQ+Z,yBACxC/nB,KAAKmc,oBAAqB,EAC1Bnc,KAAKgoB,qBAAuBC,WAAWjoB,KAAKqQ,gBAE5CrQ,KAAKyJ,gBAAkB,GACvBzJ,KAAK0J,eAAiB,GACtB1J,KAAKmF,aAAe,GACpBnF,KAAKqI,QAAU,GACfrI,KAAK+a,WAAa,GAClB/a,KAAKgb,wBAA0B,GAC/Bhb,KAAK0F,iBAAmB,GACxB1F,KAAKqF,YAAc,IAAIkiB,EAAc1gB,YACrC7G,KAAKkb,aAAe,GACpBlb,KAAKma,gBAAkB,GACvBna,KAAK8a,2BAA6B,GAClC9a,KAAKib,iBAAmB,GACxBjb,KAAKsb,yBAA2B,GAChCtb,KAAKic,yBAA2B,GAChCjc,KAAKwG,kBAAoB,GACzBxG,KAAK+Z,6BAA+B,GACpC/Z,KAAKuX,OAASvJ,EAAQuJ,OAClBvJ,EAAQ5G,SACRpH,KAAKkoB,YAAcloB,KAAK4J,aAAaoE,EAAQ5G,SAC7CpH,KAAKkoB,YAAY/gB,KAAMC,GAAYpH,KAAK+J,gBAAgB3C,KAGxDpH,KAAKkoB,YAAc/a,QAAQC,QAAQ,IAAI1J,EAAwBgK,wBAAwB1N,KAAK2S,QAAU,CAAE,QAAS3S,KAAK2S,QAAS,mBAAmB,GAAS,CAAC,GAEpK,CAQA,kBAAM/I,CAAaxC,EAASpC,EAAemO,GACvC,OAAOnT,KAAKynB,cAAcvnB,MAAMkH,EAAS,CACrCuL,QAAS3S,KAAK2S,QACdQ,mBACA7C,sBAAuBtQ,KAAKsQ,sBAC5BtL,gBACAqL,eAAgBrQ,KAAKgoB,sBAE7B,CAMA,eAAAje,CAAgB3C,GACZ,MAAM+gB,EAAgB/gB,EAAQyC,gBAAgB,YAC9C,GAAIse,EAAe,CACf,GAAInoB,KAAKgoB,sBAAwBG,EAAgBnoB,KAAKgoB,qBAClD,MAAM,IAAIna,EAAanH,WAAW,gCAAgCyhB,mCAA+CnoB,KAAKgoB,wBAAyBna,EAAalH,YAAYyhB,0BAGxK,GAAIpoB,KAAKgoB,sBAAwBG,EAAgBnoB,KAAKgoB,qBAClD,MAAM,IAAIna,EAAanH,WAAW,2BAA2ByhB,kCAA8CnoB,KAAKgoB,wBAAyBna,EAAalH,YAAY8K,uBAEtKzR,KAAKgoB,qBAAuBG,CAEpC,CACJ,CAOA,gBAAMzjB,CAAWhF,EAAMN,EAAS,GAC5B,MAAMipB,EAAe3oB,EAErB,MAAwC,kBAA1BA,EAAKA,EAAKC,OAAS,GAC7BD,EAAOA,EAAKuB,MAAM,EAAGvB,EAAKC,OAAS,GAGnCP,IACAM,EAAOA,EAAKuB,MAAM,GAAI7B,IAG1B,MAAMkpB,QAAoBtoB,KAAKuoB,2BAA2B7oB,GACpD0H,EAAUkhB,EAAYlhB,QAE5B,IAAIgI,EAAahI,EAAQyC,gBACzB,IAAK,IAAItJ,EAAI+nB,EAAYtkB,MAAOzD,EAAI8nB,EAAa1oB,OAASP,EAAQmB,IAAK,CACnE,MAAMV,EAAMwoB,EAAa9nB,GACnBioB,EAAkBpZ,EAAWvP,GACnC,GAAI2oB,GAA8C,kBAApBA,GAAgC,aAAcA,EAAiB,CACzF,MAAMtb,SAAuBlN,KAAK4J,aAAa4e,EAAiBpZ,GAAY,IAAOvF,gBAC7E4e,IAAc5oB,KAAOqN,IACpBA,EAAcrN,GAAK,YAAY,eACpB,IAAd4oB,GAAuBloB,IAAM8nB,EAAa1oB,OAAS,EAAIP,IACvDgQ,EAAa3P,OAAO8C,OAAO,CAAC,EAAG2K,UAExBkC,EAAW,cAClBA,EAAWvP,GAAOJ,OAAO8C,OAAO,CAAC,EAAG6M,EAAWvP,IAC3C,QAAS2oB,IACTpZ,EAAWvP,GAAK,OAAS2oB,EAAgB,eAEtCpZ,EAAWvP,GAAK,aACL,IAAd4oB,GACAzoB,KAAKqF,YAAYgC,WAAWghB,EAAapnB,MAAM,EAAGV,EAAInB,GAAS+N,QAAQC,QAAQ,IAAI1J,EAAwBgK,wBAAwB0B,KAG/I,CACJ,CACA,OAAO,IAAI1L,EAAwBgK,wBAAwB0B,EAC/D,CAaA,gCAAMmZ,CAA2B7oB,GAC7B,MAAMgpB,EAAgBhpB,EAAKC,OAC3B,IACIgpB,EADAL,EAAc,KAElB,EAAG,CACCK,GAAqC,EACjCL,GAAe,yBAA0BA,EAAYlhB,QAAQyC,gBAG7Dye,EAAYlhB,QAAU,IAAI1D,EAAwBgK,wBAAwB4a,EAAYlhB,QAAQyC,gBAAgB,0BAG1Gye,IAIA5oB,EAAOA,EAAKuB,MAAM,EAAGqnB,EAAYtkB,MAAQ,IAE7CskB,QAAoBtoB,KAAKqF,YAAYX,WAAWhF,IAAS,CAAE0H,cAAepH,KAAKkoB,YAAalkB,MAAO,IAKvG,MAAM4kB,EAAUlpB,EAAKA,EAAKC,OAAS,GACnC,GAAIipB,KAAWN,EAAYlhB,QAAQyC,gBAAiB,CAChD,MAAMgf,EAAeP,EAAYlhB,QAAQyC,gBAAgB+e,GACrDC,GAAwC,kBAAjBA,GAA6B,aAAcA,IAClEF,GAAqC,EAE7C,CACJ,OAASL,EAAYtkB,MAAQ,IACgC,IAAtDskB,EAAYlhB,QAAQyC,gBAAgB,eACpCye,EAAYtkB,QAAU0kB,IACrBC,GAQR,OAL0B,IAAtBL,EAAYtkB,QAC6C,IAAtDskB,EAAYlhB,QAAQyC,gBAAgB,eACpCye,EAAYtkB,QAAU0kB,IACzBJ,EAAYlhB,QAAU,IAAI1D,EAAwBgK,wBAAwB,CAAC,IAExE4a,CACX,CASA,mBAAMzjB,CAAcnF,EAAMX,EAAOiF,EAAO2V,SAC9B3Z,KAAKuX,OAAO1S,cAAcnF,EAAMX,EAAOiF,EAAO2V,EACxD,CAKA,wCAAM3Q,GACF,GAAIhJ,KAAK+Z,6BAA6Bpa,OAAS,EAAG,CAC9C,IAAK,MAAMmpB,KAAsB9oB,KAAK+Z,mCAC5B/Z,KAAKuX,OAAOyC,YAAY8O,EAAmB9kB,MAAO8kB,EAAmBppB,MAC3EM,KAAKuX,OAAOqC,YAAYkP,EAAmB9kB,OAG/C,OADAhE,KAAK+Z,6BAA6BD,OAAO,EAAG9Z,KAAK+Z,6BAA6Bpa,SACvE,CACX,CAEI,OAAO,CAEf,CAMA,QAAAoG,CAAS/B,EAAOgC,GACE,IAAVhC,IACAhE,KAAKmc,oBAAqB,GAE9Bnc,KAAKuX,OAAO/W,KAAKwF,EACrB,CAKA,SAAAS,CAAUyS,GACNlZ,KAAKuX,OAAOW,KAAK,QAASgB,EAC9B,CAKA,WAAApP,CAAY1C,GACRpH,KAAKuX,OAAOW,KAAK,UAAW9Q,EAChC,CAOA,8BAAA2hB,CAA+B/kB,GAC3B,IAAIygB,EAASzkB,KAAKsb,yBAAyBtX,GAK3C,OAJKygB,IACDA,EAAS,GACTzkB,KAAKsb,yBAAyBtX,GAASygB,GAEpCA,CACX,CAOA,8BAAA1I,CAA+B/X,GAC3B,IAAIygB,EAASzkB,KAAKic,yBAAyBjY,GAK3C,OAJKygB,IACDA,EAAS,GACTzkB,KAAKic,yBAAyBjY,GAASygB,GAEpCA,CACX,CAMA,wBAAApI,CAAyBrY,GACrB,IAAIygB,EAASzkB,KAAKwG,kBAAkBxC,GAKpC,OAJKygB,IACDA,EAAS,GACTzkB,KAAKwG,kBAAkBxC,GAASygB,GAE7BA,CACX,CAIA,gBAAAuE,GACI,OAAO1R,EAAe2R,eAAejpB,KAAKgoB,qBAC9C,CAUA,UAAA5iB,CAAWpB,EAAO+E,GAEd,MAAMmgB,EAAgBlpB,KAAKqI,QAAQrE,EAAQ+E,GAO3C,GANImgB,IACAlpB,KAAKqI,QAAQrE,GAASklB,EACtBlpB,KAAKmF,aAAanB,IAAS,SACpBhE,KAAKqI,QAAQrE,EAAQ+E,IAG5B/I,KAAK+Z,6BAA6Bpa,OAClC,IAAK,MAAM8kB,KAAUzkB,KAAK+Z,6BAClB0K,EAAOzgB,OAASA,EAAQ+E,IACxB0b,EAAOzgB,OAAS+E,EAChB0b,EAAO/kB,KAAKoa,OAAO9V,EAAO+E,IAKlC/I,KAAKsb,yBAAyBtX,EAAQ+E,KACtC/I,KAAKsb,yBAAyBtX,GAAShE,KAAKsb,yBAAyBtX,EAAQ+E,UACtE/I,KAAKsb,yBAAyBtX,EAAQ+E,IAE7C/I,KAAKwG,kBAAkBxC,EAAQ+E,EAAc,KACxC/I,KAAKwG,kBAAkBxC,EAAQ,KAChChE,KAAKwG,kBAAkBxC,EAAQ,GAAK,IAExChE,KAAKwG,kBAAkBxC,EAAQ,GAAK,IAC7BhE,KAAKwG,kBAAkBxC,EAAQ,MAC/BhE,KAAKwG,kBAAkBxC,EAAQ+E,EAAc,WAE7C/I,KAAKwG,kBAAkBxC,EAAQ+E,EAAc,GAG5D,EAEJzF,EAAQgU,eAAiBA,EACzBA,EAAe2R,eAAiB,CAC5B,EAAK,CACD1C,oBAAoB,EACpBrI,yBAAyB,EACzBsI,0BAA0B,GAE9B,IAAK,CACDD,oBAAoB,EACpBrI,yBAAyB,EACzBsI,0BAA0B,G,qCCvVlC/mB,OAAO8D,eAAeD,EAAS,aAAc,CAAEvE,OAAO,IACtDuE,EAAQ2B,UAAO,EACf,MAAMvB,EAA0B,EAAQ,OAClCylB,EAAqB,EAAQ,OAC7B5S,EAA0B,EAAQ,OAElC6S,EAAmB,EAAQ,OAIjC,MAAMnkB,EACF,WAAAlF,CAAYiO,GACRhO,KAAK8D,eAAiBkK,EAAQlK,eAC9B9D,KAAK6F,YAAcmI,EAAQnI,aAAe,IAAIsjB,EAAmBE,YACjErpB,KAAKqG,SAAWrG,KAAK6F,YAAYyjB,UAAUrkB,EAAKskB,IAAM,SACtDvpB,KAAKiG,QAAUjG,KAAK6F,YAAYyjB,UAAUrkB,EAAKskB,IAAM,QACrDvpB,KAAKsG,OAAStG,KAAK6F,YAAYyjB,UAAUrkB,EAAKskB,IAAM,OACpDvpB,KAAKuM,QAAUvM,KAAK6F,YAAYyjB,UAAUrkB,EAAKskB,IAAM,QACrDvpB,KAAKwpB,QAAUxpB,KAAK6F,YAAYyjB,UAAUrkB,EAAKskB,IAAM,OACzD,CAYA,sBAAO1e,CAAgBzD,EAASqiB,EAAY5pB,EAAK6K,GAC7C,MAAMgf,EAAQtiB,EAAQyC,gBAAgBhK,GACtC,IAAK6pB,EACD,OAAOhf,EAEX,MAAMrK,EAAOqpB,EAAMD,GACnB,YAAgB3kB,IAATzE,EAAqBqK,EAAWrK,CAC3C,CAYA,+BAAO6E,CAAyBkC,EAASvH,GACrC,OAAOoF,EAAK4F,gBAAgBzD,EAAS,aAAcvH,EAAK,CAAE,QAAQ,GACtE,CAOA,0BAAOoI,CAAoBb,EAASvH,GAChC,MAAMuR,EAAYnM,EAAK4F,gBAAgBzD,EAAS,QAASvH,EAAK,MAC9D,MAAkB,UAAduR,EACO,KAEJA,CACX,CAOA,8BAAOuY,CAAwBviB,EAASvH,GACpC,OAAOoF,EAAK4F,gBAAgBzD,EAAS,YAAavH,EAAKuH,EAAQyC,gBAAgB,cAAgB,KACnG,CAOA,+BAAO+f,CAAyBxiB,EAASvH,GACrC,OAAOoF,EAAK4F,gBAAgBzD,EAAS,aAAcvH,EAAKuH,EAAQyC,gBAAgB,eAAiB,KACrG,CAOA,4BAAOggB,CAAsBziB,EAASvH,GAClC,QAASoF,EAAK4F,gBAAgBzD,EAAS,WAAYvH,EAAK,KAC5D,CAOA,2BAAOiI,CAAqBV,EAASvH,GACjC,OAAOoF,EAAK4F,gBAAgBzD,EAAS,SAAUvH,EAAKuH,EAAQyC,gBAAgB,WAAa,KAC7F,CAQA,wBAAO4C,CAAkBrF,EAASvH,EAAKsE,GAEnC,MAAqB,aAAdA,IAA6Bc,EAAK4kB,sBAAsBziB,EAASvH,EAC5E,CAMA,+BAAO8M,CAAyBxI,GAC5B,MAAqB,QAAdA,CACX,CAMA,mCAAO2I,CAA6B3I,GAChC,MAAqB,gBAAdA,CACX,CAMA,iBAAO8L,CAAWsO,GACd,OAAe,OAARA,GAAgB7a,EAAwBuB,KAAKgL,WAAWsO,EACnE,CAMA,oBAAOnB,CAAc0M,EAAQC,GACzB,GAAID,EAAOnqB,OAASoqB,EAASpqB,OACzB,OAAO,EAEX,IAAK,IAAIY,EAAI,EAAGA,EAAIupB,EAAOnqB,OAAQY,IAC/B,GAAIupB,EAAOvpB,KAAOwpB,EAASxpB,GACvB,OAAO,EAGf,OAAO,CACX,CAOA,0BAAMsa,CAAqB9b,GACvB,GAAIiB,KAAK8D,eAAe+W,qBAAsB,CAC1C,MAAMmP,EAAc,CAAC,EACrB,IAAK,MAAMN,KAAS3qB,EAChB,GAAI2qB,GAA0B,kBAAVA,EAAoB,CACpC,MAAMvhB,EAAKuhB,EAAM,OACXlf,EAAQkf,EAAM,UACpB,GAAIvhB,GAAMqC,EAAO,CACb,MAAMyf,EAAqBD,EAAY7hB,GACvC,GAAI8hB,GAAsBA,IAAuBzf,EAC7C,MAAM,IAAI9G,EAAwBgD,WAAW,gCAAgCyB,IAAMzE,EAAwBiD,YAAYujB,qBAE3HF,EAAY7hB,GAAMqC,CACtB,CACJ,CAER,CACJ,CAUA,iBAAM/F,CAAY2C,EAASvH,EAAKd,EAAOiF,EAAOtE,GAE1C,GAA+C,UAA3CuF,EAAKgD,oBAAoBb,EAASvH,GAClC,MAAO,CAACG,KAAK6F,YAAYskB,QAAQnqB,KAAKoqB,kBAAkBrrB,GAAQiB,KAAKwpB,UAEzE,MAAMnpB,SAActB,EACpB,OAAQsB,GACJ,IAAK,SAED,GAAc,OAAVtB,QAA4B+F,IAAV/F,EAClB,MAAO,GAGX,GAAI4C,MAAMC,QAAQ7C,GAGd,MAAI,UAAWkG,EAAKC,yBAAyBkC,EAASvH,GAC7B,IAAjBd,EAAMY,OACC,CAACK,KAAKsG,QAGNtG,KAAK8D,eAAeuE,QAAQrE,EAAQ,IAAM,UAGnDhE,KAAK6a,qBAAqB9b,GACzB,IAUX,GAPAqI,QAAgBpH,KAAKqqB,+BAA+BjjB,EAASvH,GAEzD,aAAcd,IACdqI,QAAgBpH,KAAK8D,eAAe8F,aAAa7K,EAAM,mBAAoBiB,KAAK8D,eAAeY,WAAWhF,EAAM,IAAImK,kBAGxH9K,QAAciB,KAAK2F,gBAAgB5G,EAAOW,EAAMsE,EAAOoD,GACnD,WAAYrI,EAAO,CACnB,IAAIurB,EACAC,EACAC,EACApZ,EACAqZ,EACJ,IAAK5qB,KAAOd,EAAO,CACf,MAAM2rB,EAAW3rB,EAAMc,GACvB,OAAQA,GACJ,IAAK,SACDyqB,EAAMI,EACN,MACJ,IAAK,YACDH,EAAgBG,EAChB,MACJ,IAAK,aACDF,EAAiBE,EACjB,MACJ,IAAK,QACDtZ,EAAYsZ,EACZ,MACJ,IAAK,SACDD,EAAaC,EACb,MACJ,IAAK,cAED,MACJ,QACI,MAAM,IAAIhnB,EAAwBgD,WAAW,wBAAwB7G,iBAAmB6O,KAAKC,UAAU5P,KAAU2E,EAAwBiD,YAAYuB,sBAEjK,CAEA,GAAyE,gBAA/DlI,KAAK+E,eAAeqM,EAAW1R,EAAMsE,GAAO,EAAMoD,GACxD,MAAO,CAACpH,KAAK6F,YAAYskB,QAAQnqB,KAAKoqB,kBAAkBE,GAAMtqB,KAAKwpB,UAGvE,GAAY,OAARc,EACA,MAAO,GAEX,GAAmB,kBAARA,EACP,MAAM,IAAI5mB,EAAwBgD,WAAW,uDAAuDgI,KAAKC,UAAU2b,MAAS5mB,EAAwBiD,YAAYgkB,4BAGpK,GAAI3qB,KAAK8D,eAAe+W,sBAAwB4P,GAAoC,kBAAfA,EACjE,MAAM,IAAI/mB,EAAwBgD,WAAW,mDAAmDgI,KAAKC,UAAU8b,MAAgB/mB,EAAwBiD,YAAYkF,qBAGvK,GAAI0e,EAAe,CACf,GAAmB,kBAARD,EACP,MAAM,IAAI5mB,EAAwBgD,WAAW,4EAA4EgI,KAAKC,UAAU2b,MAAS5mB,EAAwBiD,YAAYikB,+BAEzL,IAAKlnB,EAAwBiK,cAAca,iBAAiB+b,EAAevqB,KAAK8D,eAAe8H,aAAclI,EAAwBiD,YAAYkkB,gCAC7I,MAAO,IAGP7qB,KAAK8D,eAAewM,uBAAsE,IAA7CtQ,KAAK8D,eAAekkB,wBACjEuC,EAAgBA,EAAcjqB,cAEtC,CACA,GAAIkqB,EAAgB,CAChB,GAAmB,kBAARF,EACP,MAAM,IAAInpB,MAAM,6EAA6EuN,KAAKC,UAAU2b,OAEhH,IAAK5mB,EAAwBiK,cAAckB,kBAAkB2b,EAAgBxqB,KAAK8D,eAAe8H,cAC7F,MAAO,EAEf,CAEA,GAAI2e,GAAiBC,EAAgB,CACjC,GAAIpZ,EACA,MAAM,IAAI1N,EAAwBgD,WAAW,mEAAmEgI,KAC3GC,UAAU5P,MAAW2E,EAAwBiD,YAAYuB,sBAElE,OAAOlI,KAAK8qB,oBAAoB9qB,KAC3B+qB,+BAA+B/mB,EAAOsmB,EAAKC,EAAeC,GACnE,CACK,GAAID,EAAe,CACpB,GAAInZ,EACA,MAAM,IAAI1N,EAAwBgD,WAAW,0DAA0DgI,KAAKC,UAAU5P,MAAW2E,EAAwBiD,YAAYuB,sBAEzK,MAAO,CAAClI,KAAK6F,YAAYskB,QAAQG,EAAKC,GAC1C,CACK,GAAIC,EAAgB,CACrB,GAAIpZ,EACA,MAAM,IAAI1N,EAAwBgD,WAAW,2DAA2DgI,KAAKC,UAAU5P,MAAW2E,EAAwBiD,YAAYuB,sBAE1K,OAAOlI,KAAK8qB,oBAAoB9qB,KAC3B+qB,+BAA+B/mB,EAAOsmB,EAAKC,EAAeC,GACnE,CACK,GAAIpZ,EAAW,CAChB,GAAyB,kBAAdA,EACP,MAAM,IAAI1N,EAAwBgD,WAAW,kDAAkDgI,KAAKC,UAAUyC,MAAe1N,EAAwBiD,YAAYqkB,qBAErK,MAAMC,EAAWjrB,KAAKuI,sBAAsBnB,EAASgK,GACrD,IAAK6Z,EACD,MAAM,IAAIvnB,EAAwBgD,WAAW,+BAA+BgI,KAAKC,UAAUyC,MAAe1N,EAAwBiD,YAAYqkB,qBAElJ,GAA0B,cAAtBC,EAAS/O,SACT,MAAM,IAAIxY,EAAwBgD,WAAW,uBAAuBukB,EAAS/O,cAAc9K,IAAa1N,EAAwBiD,YAAYqkB,qBAEhJ,MAAO,CAAChrB,KAAK6F,YAAYskB,QAAQG,EAAKW,GAC1C,CAEA,aAAajrB,KAAKyE,YAAY,IAAIf,EAAwBgK,wBAAwB,CAAC,GAAI7N,EAAKyqB,EAAKtmB,EAAOtE,EAC5G,CACK,GAAI,SAAUX,EAAO,CAEtB,GAAIU,OAAOC,KAAKX,GAAOY,OAAS,EAC5B,MAAM,IAAI+D,EAAwBgD,WAAW,6DAA6D7G,KAAQ6D,EAAwBiD,YAAYukB,4BAG1J,MAAO,EACX,CACK,GAAI,UAAWnsB,EAAO,CAEvB,GAAIU,OAAOC,KAAKX,GAAOY,OAAS,EAC5B,MAAM,IAAI+D,EAAwBgD,WAAW,8DAA8D7G,KAAQ6D,EAAwBiD,YAAYukB,4BAE3J,MAAMC,EAAYpsB,EAAM,SAGxB,OAAI4C,MAAMC,QAAQupB,GACW,IAArBA,EAAUxrB,OACH,CAACK,KAAKsG,QAGNtG,KAAK8D,eAAeuE,QAAQrE,EAAQ,IAAM,SAKxChE,KAAKyE,kBAAkBzE,KAAK8D,eAAeY,WAAWhF,GAAOG,EAAKsrB,EAAWnnB,EAAQ,EAAGtE,EAAKuB,MAAM,GAAI,GAE5H,CACK,GAAI,aAAclC,GAAsC,mBAAtBA,EAAM,YAGzC,MAAO,GAEN,GAAI,WAAYkG,EAAKC,+BAA+BlF,KAAK8D,eAAeY,WAAWhF,GAAOG,GAAM,CAEjG,MAAMurB,EAAwBprB,KAAK8D,eAAekX,wBAAwBhX,EAAQ,GAClF,OAAOonB,EAAwB3rB,OAAO+E,OAAO4mB,GAAyB,CAACprB,KAAK6F,YAAYC,YAC5F,CACK,GAAI,QAAS/G,EAAO,CASrB,GAPIU,OAAOC,KAAKX,GAAOY,OAAS,IAC5ByH,QAAgBpH,KAAK8D,eAAeY,WAAWhF,EAAM,IAGrD,aAAcX,IACdqI,QAAgBpH,KAAK8D,eAAe8F,aAAa7K,EAAM,YAAaqI,EAAQyC,kBAEzD,WAAnB9K,EAAM,SACN,OAAOiB,KAAK8qB,oBAAoB9qB,KAAKuI,sBAAsBnB,EAASrI,EAAM,SAEzE,CACD,MAAMssB,EAAUtsB,EAAM,OACtB,IAAIusB,EACJ,GAAuB,kBAAZD,EAAsB,CAC7B,IAAIrrB,KAAK8D,eAAeyC,QAIpB,MAAM,IAAI7C,EAAwBgD,WAAW,sBAAsB3H,KAAU2E,EAAwBiD,YAAY4kB,kBAHjHD,EAAYtrB,KAAK8D,eAAeuE,QAAQrE,EAAQ,GAAG,EAK3D,MAEIsnB,EAAYtrB,KAAKoI,eAAehB,EAASikB,GAE7C,OAAOrrB,KAAK8qB,oBAAoBQ,EACpC,CACJ,CAGI,OAAItrB,KAAK8D,eAAeqB,aAAanB,EAAQ,IACrCjF,GAA0B,kBAAVA,GAAoD,IAA9BU,OAAOC,KAAKX,GAAOY,OACrDK,KAAK8D,eAAeuE,QAAQrE,EAAQ,KACpChE,KAAK8D,eAAeuE,QAAQrE,EAAQ,GAAK,CAAChE,KAAK6F,YAAYC,cAG5D,GAGnB,IAAK,SACD,OAAO9F,KAAK8qB,oBAAoB9qB,KAAKwrB,kBAAkBxnB,QAAahE,KAAKqqB,+BAA+BjjB,EAASvH,GAAMA,EAAKd,EAAO,OACvI,IAAK,UACD,OAAOiB,KAAK8qB,oBAAoB9qB,KAAKwrB,kBAAkBxnB,QAAahE,KAAKqqB,+BAA+BjjB,EAASvH,GAAMA,EAAK2e,QAAQzf,GAAO8C,WAAY7B,KAAK6F,YAAYyjB,UAAUrkB,EAAKwmB,eAC3L,IAAK,SACD,OAAOzrB,KAAK8qB,oBAAoB9qB,KAAKwrB,kBAAkBxnB,QAAahE,KAAKqqB,+BAA+BjjB,EAASvH,GAAMA,EAAKd,EAAOiB,KAAK6F,YAAYyjB,UAAUvqB,EAAQ,IAAM,GAAKA,EAAQ,KAAOkG,EAAKymB,YAAczmB,EAAK0mB,cAC5N,QAEI,OADA3rB,KAAK8D,eAAe2C,UAAU,IAAItF,MAAM,yCAAyCd,MAC1E,GAEnB,CAUA,oCAAMgqB,CAA+BjjB,EAASvH,GAC1C,MAAM2oB,EAAkBphB,EAAQyC,gBAAgBhK,GAIhD,OAHI2oB,GAA8C,kBAApBA,GAAgC,aAAcA,IACxEphB,QAAgBpH,KAAK8D,eAAe8F,aAAa4e,EAAiBphB,EAAQyC,iBAAiB,IAExFzC,CACX,CAKA,mBAAA0jB,CAAoB5e,GAChB,OAAOA,EAAO,CAACA,GAAQ,EAC3B,CAQA,eAAA0f,CAAgBxkB,EAASvH,GACrB,MAAMgsB,EAAWzkB,EAAQ2I,WAAWlQ,GAAK,EAAMG,KAAK8D,eAAeklB,oBAEnE,OAAK6C,EAIe,MAAhBA,EAAS,IAA8B,MAAhBA,EAAS,GAC5B7rB,KAAK8D,eAAe6jB,sBACb3nB,KAAK6F,YAAYC,UAAU+lB,EAASxa,OAAO,IAG3C,KAIXpM,EAAKgL,WAAW4b,GACT7rB,KAAK6F,YAAYyjB,UAAUuC,GAG9BA,GAAY7rB,KAAK8D,eAAe8H,cAChC5L,KAAK8D,eAAe2C,UAAU,IAAI/C,EAAwBgD,WAAW,0BAA0BmlB,IAAYnoB,EAAwBiD,YAAYuI,sBAMhJ,MAHQ,KApBJ,IAwBf,CAQA,cAAA9G,CAAehB,EAASvH,GACpB,GAAIA,EAAImT,WAAW,MACf,OAAOhT,KAAK6F,YAAYC,UAAUjG,EAAIwR,OAAO,IAEjD,MAAMkN,EAAMnX,EAAQ2I,WAAWlQ,GAAK,EAAOG,KAAK8D,eAAeklB,oBAC/D,IAAK/jB,EAAKgL,WAAWsO,GAAM,CACvB,IAAIA,IAAOve,KAAK8D,eAAe8H,aAI3B,OAAO,KAHP5L,KAAK8D,eAAe2C,UAAU,IAAItF,MAAM,yBAAyBod,KAKzE,CACA,OAAOve,KAAK6F,YAAYyjB,UAAU/K,EACtC,CASA,qBAAAhW,CAAsBnB,EAASvH,GAC3B,GAAIA,EAAImT,WAAW,MACf,OAAOhT,KAAK6F,YAAYC,UAAUjG,EAAIwR,OAAO,IAEjD,MAAMT,EAAgB5Q,KAAK8D,eAAeklB,mBAC1C,IAAI6C,EAAWzkB,EAAQ2I,WAAWlQ,GAAK,EAAM+Q,GAI7C,GAHIib,IAAahsB,IACbgsB,EAAWzkB,EAAQ2I,WAAWlQ,GAAK,EAAO+Q,KAEzC3L,EAAKgL,WAAW4b,GAAW,CAC5B,IAAIA,IAAY7rB,KAAK8D,eAAe8H,cAAiBigB,EAAS7Y,WAAW,KAIrE,OAAO,KAHPhT,KAAK8D,eAAe2C,UAAU,IAAItF,MAAM,qBAAqB0qB,KAKrE,CACA,OAAO7rB,KAAK6F,YAAYyjB,UAAUuC,EACtC,CAOA,WAAAC,CAAY/sB,EAAOgtB,GACf,GAAqB,kBAAVhtB,EAAoB,CAC3B,GAAI+mB,OAAOkG,SAASjtB,GAAQ,CACxB,MAAMktB,EAAYltB,EAAQ,IAAM,EAChC,OAAIktB,GAAeF,GAAYA,EAAShtB,QAAUkG,EAAK0mB,WAI5C5sB,EAAMmtB,cAAc,IAAIltB,QAAQ,aAAc,OAH9C8mB,OAAO/mB,GAAO8C,UAK7B,CAEI,OAAO9C,EAAQ,EAAI,MAAQ,MAEnC,CAEI,OAAOA,CAEf,CAUA,iBAAAysB,CAAkBxnB,EAAOoD,EAASvH,EAAKd,EAAOotB,GAE1C,MAAMC,EAAcnnB,EAAKgD,oBAAoBb,EAASvH,GACtD,GAAIusB,EACA,GAAoB,QAAhBA,GACA,IAAKD,EACD,OAAOnsB,KAAKoI,eAAehB,EAASpH,KAAK8rB,YAAY/sB,EAAOotB,SAG/D,GAAoB,WAAhBC,GACL,IAAKD,EACD,OAAOnsB,KAAKuI,sBAAsBnB,EAASpH,KAAK8rB,YAAY/sB,EAAOotB,SAIvEA,EAAkBnsB,KAAK6F,YAAYyjB,UAAU8C,GAIrD,IAAKD,EAAiB,CAClB,MAAME,EAAkBpnB,EAAK0kB,wBAAwBviB,EAASvH,GACxDysB,EAAmBrnB,EAAK2kB,yBAAyBxiB,EAASvH,GAChE,OAAIysB,EACOtsB,KAAK+qB,+BAA+B/mB,EAAOhE,KAAK8rB,YAAY/sB,EAAOotB,GAAkBE,EAAiBC,GAGtGtsB,KAAK6F,YAAYskB,QAAQnqB,KAAK8rB,YAAY/sB,EAAOotB,GAAkBE,EAElF,CAEA,OAAOrsB,KAAK6F,YAAYskB,QAAQnqB,KAAK8rB,YAAY/sB,EAAOotB,GAAkBA,EAC9E,CAUA,8BAAApB,CAA+B/mB,EAAOjF,EAAO2D,EAAU6pB,GACnD,GAAyC,kBAArCvsB,KAAK8D,eAAegkB,aAKpB,OAHKplB,IACDA,EAAW,IAER1C,KAAK6F,YAAYskB,QAAQprB,EAAOiB,KAAK6F,YAAYyjB,UAAU,8BAA8B5mB,KAAY6pB,MAE3G,GAAyC,qBAArCvsB,KAAK8D,eAAegkB,aAAqC,CAE9D,MAAM0E,EAAYxsB,KAAK6F,YAAYC,YAC7B6V,EAAQ3b,KAAKkG,kBAMnB,OALAlG,KAAK8D,eAAeiC,SAAS/B,EAAOhE,KAAK6F,YAAYG,KAAKwmB,EAAWxsB,KAAK6F,YAAYyjB,UAAUrkB,EAAKskB,IAAM,SAAUvpB,KAAK6F,YAAYskB,QAAQprB,GAAQ4c,IAClJjZ,GACA1C,KAAK8D,eAAeiC,SAAS/B,EAAOhE,KAAK6F,YAAYG,KAAKwmB,EAAWxsB,KAAK6F,YAAYyjB,UAAUrkB,EAAKskB,IAAM,YAAavpB,KAAK6F,YAAYskB,QAAQznB,GAAWiZ,IAEhK3b,KAAK8D,eAAeiC,SAAS/B,EAAOhE,KAAK6F,YAAYG,KAAKwmB,EAAWxsB,KAAK6F,YAAYyjB,UAAUrkB,EAAKskB,IAAM,aAAcvpB,KAAK6F,YAAYskB,QAAQoC,GAAY5Q,IACvJ6Q,CACX,CAEI,OAAOxsB,KAAK6F,YAAYskB,QAAQprB,EAAO,CAAE2D,SAAUA,GAAY,GAAI6pB,UAAWA,GAEtF,CAMA,iBAAAnC,CAAkBrrB,GACd,OAAOqqB,EAAiBrqB,EAC5B,CAYA,oBAAMgG,CAAelF,EAAKH,EAAMsE,EAAOyoB,EAAcrlB,GAEjD,GAAI0e,OAAOmG,UAAUpsB,GACjB,OAAOA,EAGX,IAAK4sB,EAAc,CACf,MAAMC,EAAyB1sB,KAAK8D,eAAegX,2BAA2B9W,GAC9E,GAAI0oB,EACA,OAAOA,CAEf,CACA,IAAKhpB,EAAwBuB,KAAK8C,mBAAmBlI,GAAM,CACvDuH,EAAUA,SAAiBpH,KAAK8D,eAAeY,WAAWhF,GAC1D,IAAIitB,EAAWvlB,EAAQyC,gBAAgBhK,GACnC8sB,GAAgC,kBAAbA,IACnBA,EAAWA,EAAS,QAEpBjpB,EAAwBuB,KAAKgK,eAAe0d,KAC5C9sB,EAAM8sB,EAEd,CACA,OAAOF,EAAe5sB,EAAOG,KAAK8D,eAAegX,2BAA2B9W,GAASnE,CACzF,CAQA,0BAAMuE,CAAqB1E,EAAMsE,GAC7B,aAAahE,KAAK+E,eAAef,EAAQ,GAAKtE,EAAKsE,EAAQ,GAAItE,EAAMsE,EAAQ,EACjF,CAUA,qBAAM2B,CAAgBinB,EAAMltB,EAAMsE,EAAOoD,GACrC,MAAMylB,EAAU,CAAC,EACjB,IAAK,MAAMhtB,KAAO+sB,EACdC,QAAc7sB,KAAK+E,eAAelF,EAAKH,EAAMsE,EAAQ,GAAG,EAAMoD,IAAYwlB,EAAK/sB,GAEnF,OAAOgtB,CACX,CAUA,eAAMnS,CAAUhb,EAAMsE,GAClB,IAAK,IAAIzD,EAAIyD,EAAOzD,GAAK,EAAGA,IAAK,CAC7B,GAAoD,sBAA1CP,KAAK+E,eAAerF,EAAKa,GAAIb,EAAMa,GAEzC,OAAO,EAEX,GAAIP,KAAK8D,eAAeoX,aAAa3a,IAAMP,KAAK8D,eAAemX,iBAAiB1a,GAC5E,OAAO,CAEf,CACA,OAAO,CACX,CAQA,yBAAMkb,CAAoBzX,EAAOtE,GAC7B,IAAK,IAAIa,EAAIyD,EAAQ,EAAGzD,EAAI,EAAGA,IAC3B,GAAoD,iBAA1CP,KAAK+E,eAAerF,EAAKa,GAAIb,EAAMa,GAAiB,CAE1D,MAAMmH,SAAoB6O,EAAwBvM,sBAAsBS,oBAAoBzK,KAAK8D,eAAgBpE,EAAMa,IAAImH,WAC3H,OAAI6O,EAAwBvM,sBAAsBM,wBAAwB5C,IAC9D,EAEL1D,EAAQzD,EAAI,CACvB,CAEJ,OAAQ,CACZ,CAMA,sBAAAusB,CAAuBvR,GACnB,GAAyB,YAArBA,EAAQW,SACR,MAAM,IAAIxY,EAAwBgD,WAAW,8CAA8C6U,EAAQxc,QAAS2E,EAAwBiD,YAAYomB,+BAExJ,CAKA,eAAA7mB,GACI,OAAOlG,KAAK8D,eAAe+jB,cAAgB7nB,KAAK6F,YAAYgiB,cAChE,CAOA,4BAAMlf,CAAuBjJ,EAAMsE,GAE/B,IAAI2X,EAAQ3b,KAAKkG,kBAEjB,MAAM,WAAEwB,EAAY1D,MAAOgpB,SAAyBzW,EAAwBvM,sBACvES,oBAAoBzK,KAAK8D,eAAgBpE,EAAMsE,GACpD,GAAI,WAAY0D,EAAY,CAExB,MAAMulB,EAAsB1W,EAAwBvM,sBAAsBO,uBAAuB7C,EAAYslB,EAAgBttB,GACvHgqB,EAAQ1pB,KAAK8D,eAAekX,wBAAwBgS,GAG1D,GAFArR,EAAQ+N,EAAQA,EAAMuD,GAAuB,MAExCtR,EAAO,CACR,IAAIjT,EAAU,KACd,GAAI,QAAShB,EAAY,CACrB,MAAMqE,QAAqB/L,KAAKyI,gBAAgB/I,EAAKstB,GAAiBttB,EAAMstB,GACvD,OAAjBjhB,IACArD,QAAgB1I,KAAKoI,qBAAqBpI,KAAK8D,eAAeY,WAAWhF,GAAOqM,GAExF,CACKrD,IACDA,EAAU1I,KAAK6F,YAAYC,aAE1B9F,KAAK8D,eAAekX,wBAAwBgS,KAC7ChtB,KAAK8D,eAAekX,wBAAwBgS,GAAkB,CAAC,GAEnErR,EAAQ3b,KAAK8D,eAAekX,wBAAwBgS,GAAgBC,GAAuBvkB,CAC/F,CACJ,CACA,OAAOiT,CACX,CAeA,wBAAMuR,CAAmBxtB,EAAMsE,GAC3B,IAAImpB,EAAiBnpB,EACrB,IAAK,IAAIzD,EAAIyD,EAAQ,EAAGzD,EAAI,EAAGA,IAC3B,GAAuB,kBAAZb,EAAKa,GAAiB,CAC7B,MAAM4D,QAAkBnE,KAAK+E,eAAerF,EAAKa,GAAIb,EAAMa,GAC3D,GAAkB,aAAd4D,EACA,OAAO5D,EAEN,GAAkB,UAAd4D,EAIL,OAAOgpB,EAHPA,EAAiB5sB,CAKzB,CAEJ,OAAO4sB,CACX,CASA,qBAAM1kB,CAAgB5I,EAAKH,EAAMsE,GAC7B,MAAM+H,QAAqB/L,KAAK+E,eAAelF,EAAKH,EAAMsE,GAC1D,MAAwB,UAAjB+H,EAA2B,KAAOA,CAC7C,CAOA,6BAAAa,CAA8B/M,EAAK2M,EAASE,GACxC,GAAIA,GAAcF,IAAYxM,KAAK8D,eAAeikB,yBAC9C,MAAM,IAAIrkB,EAAwBgD,WAAW,gDAAgD7G,IAAO6D,EAAwBiD,YAAYymB,sBAEhJ,CAWA,eAAAvR,CAAgB7X,EAAOuX,EAASjP,EAAW3H,EAAQgX,EAAOnP,EAASE,GAE/D,IAAI1G,EASJ,GARIwG,GACAxM,KAAK8sB,uBAAuBnoB,GAC5BqB,EAAOhG,KAAK6F,YAAYG,KAAKrB,EAAQ2H,EAAWiP,EAASI,IAGzD3V,EAAOhG,KAAK6F,YAAYG,KAAKuV,EAASjP,EAAW3H,EAAQgX,GAGzDjP,EAAY,CAMZ,GAJ4B,iBAAxB1G,EAAK2V,MAAMO,WACXlW,EAAOhG,KAAK6F,YAAYG,KAAKA,EAAKuV,QAASvV,EAAKsG,UAAWtG,EAAKrB,SAGhE3E,KAAK8D,eAAeuE,QAAQrE,EAAQ,GACpC,MAAM,IAAIN,EAAwBgD,WAAW,kDAAmDhD,EAAwBiD,YAAYymB,uBAExIptB,KAAK8D,eAAeuE,QAAQrE,EAAQ,GAAK,CAACgC,EAC9C,MAEIhG,KAAK8D,eAAeiC,SAAS/B,EAAOgC,GAGxC,MAAMQ,EAAoBxG,KAAK8D,eAAe0C,kBAAkBxC,GAChE,GAAIwC,EAAmB,CACnB,IAAK,MAAM8V,KAAc9V,EACrBxG,KAAKqtB,eAAerpB,EAAOgC,EAAMsW,UAE9Btc,KAAK8D,eAAe0C,kBAAkBxC,EACjD,CACJ,CAEA,cAAAqpB,CAAerpB,EAAOgC,EAAMsW,GAExB,IAAIgR,EACAhR,EAAW9P,SACXxM,KAAK8sB,uBAAuBxQ,EAAW3X,QACvC2oB,EAAiBttB,KAAK6F,YAAYG,KAAKsW,EAAW3X,OAAQ2X,EAAWhQ,UAAWtG,IAGhFsnB,EAAiBttB,KAAK6F,YAAYG,KAAKA,EAAMsW,EAAWhQ,UAAWgQ,EAAW3X,QAGlF3E,KAAK8D,eAAeiC,SAAS/B,EAAOspB,GAEpC,IAAK,MAAMC,KAAoBjR,EAAWkR,kBACtCxtB,KAAKqtB,eAAerpB,EAAOspB,EAAgBC,EAEnD,EAEJjqB,EAAQ2B,KAAOA,EACfA,EAAKwoB,IAAM,oCACXxoB,EAAKwmB,YAAcxmB,EAAKwoB,IAAM,UAC9BxoB,EAAKymB,YAAczmB,EAAKwoB,IAAM,UAC9BxoB,EAAK0mB,WAAa1mB,EAAKwoB,IAAM,SAC7BxoB,EAAKskB,IAAM,6C,qCC74BX9pB,OAAO8D,eAAeD,EAAS,aAAc,CAAEvE,OAAO,IACtDuE,EAAQuF,2BAAwB,EAChC,MAAMnF,EAA0B,EAAQ,OAClCD,EAAS,EAAQ,OAKvB,MAAMoF,EAeF,kCAAaC,CAAsBhF,EAAgBC,EAAMrE,EAAMsE,EAAOsI,EAAW3H,EAAQ6H,EAASE,EAAYG,GAC1G,MAAM6gB,QAAwB3pB,EAAKmpB,mBAAmBxtB,EAAMsE,GACtDwX,QAAyBzX,EAAK0X,oBAAoBzX,EAAOtE,GACzDiuB,EAAuB3pB,EAAQwX,EAC/BL,EAAWrX,EAAeuE,QAAQqlB,GACxC,GAAIvS,IAAatO,EAEb,IAAK,MAAM0O,KAAWJ,EAAU,CAE5B,MAAMyS,EAAUpS,GAAoB,EACpC,GAAIoS,EAAS,CACT,MAAMlS,EAAS5X,EAAeuE,QAAQslB,EAAuB,GAC7D,GAAIjS,EACA,IAAK,MAAMC,KAASD,EAEhB3X,EAAK8X,gBAAgB7X,EAAOuX,EAASjP,EAAW3H,EAAQgX,EAAOnP,EAASE,QAKxEF,GACAzI,EAAK+oB,uBAAuBnoB,GAC5Bb,EAAeiY,+BAA+B4R,EAAuB,GAAGntB,KAAK,CAAE+a,QAAS5W,EAAQ2H,YAAW3H,OAAQ4W,EAAS7O,gBAG5H5I,EAAeiY,+BAA+B4R,EAAuB,GAChEntB,KAAK,CAAE+a,UAASjP,YAAW3H,SAAQ+H,cAGpD,KACK,CAED,MAAMiP,QAAc5X,EAAK4E,uBAAuBjJ,EAAMguB,GACtD3pB,EAAK8X,gBAAgB7X,EAAOuX,EAASjP,EAAW3H,EAAQgX,EAAOnP,EAASE,EAC5E,CACJ,MAQA,GAJIF,GACAzI,EAAK+oB,uBAAuBnoB,GAG5BkI,GAEA,GAAI/I,EAAeyC,QAAS,CAEpBzC,EAAeuE,QAAQrE,IACvBF,EAAe2C,UAAU,IAAI/C,EAAwBgD,WAAW,8CAA8C5C,EAAeuE,QAAQrE,GAAO,GAAGjF,QAAS2E,EAAwBiD,YAAYC,qBAGhM,IAAK,IAAIrG,EAAI,EAAGA,EAAIyD,EAAOzD,IAC6B,cAA1CwD,EAAKgB,eAAerF,EAAKa,GAAIb,EAAMa,IACzCuD,EAAe2C,UAAU,IAAI/C,EAAwBgD,WAAW,sDAAuDhD,EAAwBiD,YAAYC,qBAInK,MAAMJ,EAAoB1C,EAAeuY,yBAAyBqR,GAC5DG,EAAgB,CAAEvhB,YAAW3H,SAAQ6H,UAASghB,kBAAmB,GAAIxpB,MAAO0pB,GAClFlnB,EAAkBhG,KAAKqtB,GAGvB,IAAK,IAAIttB,EAAIiG,EAAkB7G,OAAS,EAAGY,GAAK,EAAGA,IAAK,CAEpD,MAAMutB,EAAqBtnB,EAAkBjG,GACzCutB,EAAmB9pB,MAAQ0pB,IAC3BG,EAAcL,kBAAkBhtB,KAAKstB,GACrCtnB,EAAkBsT,OAAOvZ,EAAG,GAEpC,CACJ,OAGAuD,EAAeilB,+BAA+B2E,GAAiBltB,KAAK,CAAE8L,YAAW3H,SAAQ6H,UAASE,cAG9G,CACA,iBAAA/I,GACI,OAAO,CACX,CACA,gBAAAC,GACI,OAAO,CACX,CACA,cAAMC,CAASC,EAAgBC,EAAMrE,EAAMsE,EAAOC,GAC9C,MAAMpE,EAAMH,EAAKsE,GACjB,GAAInE,EAAK,CACL,MAAMuH,QAAgBtD,EAAeY,WAAWhF,GAChD,IAAKoE,EAAemX,iBAAiBjX,UAAgBD,EAAK6nB,gBAAgBxkB,EAAS1H,EAAKsE,IAKpF,MAHsD,UAAlDP,EAAOwB,KAAKgD,oBAAoBb,EAASvH,KACzCiE,EAAemX,iBAAiBjX,EAAQ,IAAK,IAE1C,CAEf,CACA,OAAO,CACX,CACA,UAAM9E,CAAK4E,EAAgBC,EAAMlE,EAAKH,EAAMsE,GACxC,OAAOtE,EAAKsE,EAChB,CACA,YAAME,CAAOJ,EAAgBC,EAAMlE,EAAKH,EAAMX,EAAOiF,EAAOoH,GACxD,MAAMiB,EAAc3M,EAAKsE,GACnBoD,QAAgBtD,EAAeY,WAAWhF,GAC1C4M,QAAkBvI,EAAK6nB,gBAAgBxkB,EAASvH,GACtD,GAAIyM,EAAW,CACX,MAAMyhB,QAAgBhqB,EAAKU,YAAY2C,EAASvH,EAAKd,EAAOiF,EAAOtE,GACnE,GAAIquB,EAAQpuB,OACR,IAAK,IAAIgF,KAAUopB,EAAS,CAExB,IAAI5pB,QAAkBJ,EAAKK,qBAAqB1E,EAAMsE,GACtD,MAAMwI,EAAU/I,EAAOwB,KAAKwH,kBAAkBrF,EAASiF,EAAalI,GACpE,IAAI6pB,EAAoB,EACxB,MAAqB,aAAd7pB,GAAiD,kBAAdA,EAEb,kBAAdA,EACP6pB,IAGAhqB,IAEJG,QAAkBJ,EAAKK,qBAAqB1E,EAAMsE,EAAQgqB,GAE9D,MAAMthB,EAAajJ,EAAOwB,KAAK0H,yBAAyBxI,GACxDJ,EAAK6I,8BAA8B/M,EAAK2M,EAASE,GACjD,MAAMG,EAAepJ,EAAOwB,KAAK6H,6BAA6B3I,GAC9D,GAAIpF,EAAO,CAGP,MAAMkvB,EAAqB,UAAWxqB,EAAOwB,KAAKC,yBAAyBkC,EAASvH,GACpF,GAAIouB,GAAsBlvB,EAAM,SAAU,CACtC,IAAMkvB,IAAuBtsB,MAAMC,QAAQ7C,KAAWA,EAAM,UACpDA,EAAM,WAAa4C,MAAMC,QAAQ7C,EAAM,YACxC4F,IAAWZ,EAAKuC,OAAQ,CAC3B,MAAMb,EAAc1B,EAAK8B,YAAYC,YACrChC,EAAeiC,SAAS/B,EAAOD,EAAK8B,YAAYG,KAAKP,EAAa1B,EAAKkC,QAASlC,EAAKuC,OAAQvC,EAAKmC,oBAClGpC,EAAeiC,SAAS/B,EAAOD,EAAK8B,YAAYG,KAAKP,EAAa1B,EAAKsC,SAAU1B,EAAQZ,EAAKmC,oBAC9FvB,EAASc,CACb,CAEA,GAAI+G,IAAY1I,EAAe8jB,iBAC3B,MAAM,IAAIlkB,EAAwBgD,WAAW,mDAAmD7G,IAAO6D,EAAwBiD,YAAYomB,+BAEnJ,CACJ,OACMlkB,EAAsBC,sBAAsBhF,EAAgBC,EAAMrE,EAAMsE,EAAOsI,EAAW3H,EAAQ6H,EAASE,EAAYG,EACjI,CAER,CACJ,EAEJvJ,EAAQuF,sBAAwBA,C,mCC5KhCpJ,OAAO8D,eAAeD,EAAS,aAAc,CAAEvE,OAAO,G,qCCDtDU,OAAO8D,eAAeD,EAAS,aAAc,CAAEvE,OAAO,IACtDuE,EAAQoa,2BAAwB,EAChC,MAAMha,EAA0B,EAAQ,OAClCwF,EAAwB,EAAQ,OAItC,MAAMwU,UAA8BxU,EAAsBC,oBACtD,WAAApJ,GACIqJ,MAAM,MACV,CACA,gBAAAxF,GACI,OAAO,CACX,CACA,YAAMM,CAAOJ,EAAgBC,EAAMlE,EAAKH,EAAMX,EAAOiF,GACjD,GAAqB,kBAAVjF,EAAoB,CAE3B,GAAI+E,EAAeyC,SAA4B,kBAAVxH,EAAoB,CACrD,MAAMmvB,EAAYzuB,OAAOC,KAAKX,GACL,IAArBmvB,EAAUvuB,QAAiC,QAAjBuuB,EAAU,IACpCpqB,EAAe2C,UAAU,IAAI/C,EAAwBgD,WAAW,mDAAmD3H,EAAM,SAAU2E,EAAwBiD,YAAYymB,uBAE/K,MAEItpB,EAAe2C,UAAU,IAAI/C,EAAwBgD,WAAW,sBAAsB3H,KAAU2E,EAAwBiD,YAAY4kB,mBAExI,MACJ,CAGA,MAAMmC,QAAwB3pB,EAAKmpB,mBAAmBxtB,EAAMsE,GAc5D,QAZgDc,IAA5ChB,EAAeuE,QAAQqlB,KACnB5pB,EAAeuE,QAAQqlB,GAAiB,GAAG7T,SAE3C/V,EAAe2C,UAAU,IAAI/C,EAAwBgD,WAAW,8DAA8DhH,EAAKsE,EAAQ,MAAON,EAAwBiD,YAAYukB,6BAItLpnB,EAAe2C,UAAU,IAAI/C,EAAwBgD,WAAW,yBAAyB5C,EACpFuE,QAAQqlB,GAAiB,GAAG3uB,eAAeA,KAAU2E,EAAwBiD,YAAYwnB,sBAIlGrqB,EAAeyC,SAAWzC,EAAe0C,kBAAkBxC,GAC3D,IAAK,MAAMsY,KAAcxY,EAAe0C,kBAAkBxC,GAClDsY,EAAWtY,QAAUA,GACrBF,EAAe2C,UAAU,IAAI/C,EAAwBgD,WAAW,8CAA8C3H,IAAS2E,EAAwBiD,YAAYC,qBAKvK9C,EAAeuE,QAAQqlB,GAAmB3pB,EAAK+mB,0BAA0B/mB,EAAKqE,qBAAqBtE,EAAeY,WAAWhF,GAAOX,GACxI,EAEJuE,EAAQoa,sBAAwBA,C,qCCvDhCje,OAAO8D,eAAeD,EAAS,aAAc,CAAEvE,OAAO,IACtDuE,EAAQgI,8BAA2B,EACnC,MAAM5H,EAA0B,EAAQ,OAOxC,MAAM4H,EACF,mBAAA7D,GACI,OAAO,CACX,CACA,YAAMvD,CAAOwD,EAAY5D,EAAgBC,EAAMrE,EAAMX,EAAOiF,GACxD,MAAMtB,QAAiBqB,EAAK0E,gBAAgB/I,EAAKsE,GAAQtE,EAAMsE,GAC/D,GAAIrC,MAAMC,QAAQ7C,GAEdA,EAAQA,EAAMuD,IAAKooB,IAAa,CAAG,SAAUA,EAAU,YAAahoB,SAEnE,CACD,GAAqB,kBAAV3D,EACP,MAAM,IAAI2E,EAAwBgD,WAAW,wCAAwCgI,KAAKC,UAAU5P,2BAAgC2E,EAAwBiD,YAAYynB,4BAE5KrvB,EAAQ,CAAE,SAAUA,EAAO,YAAa2D,EAC5C,OACMoB,EAAee,cAAcnF,EAAKuB,MAAM,EAAGvB,EAAKC,OAAS,GAAIZ,EAAOiF,EAAQ,GAAG,GACrFF,EAAeqB,aAAanB,IAAS,CACzC,EAEJV,EAAQgI,yBAA2BA,C,qCC7BnC7L,OAAO8D,eAAeD,EAAS,aAAc,CAAEvE,OAAO,IACtDuE,EAAQsa,8BAA2B,EACnC,MAAM1U,EAAwB,EAAQ,OAItC,MAAM0U,UAAiC1U,EAAsBC,oBACzD,WAAApJ,GACIqJ,MAAM,SACV,CACA,cAAMvF,CAASC,EAAgBC,EAAMrE,EAAMsE,EAAOC,GAE9C,MAAMpE,EAAMH,EAAKsE,GAIjB,OAHInE,IAAQiE,EAAeoX,aAAalX,UAAgBhE,KAAKd,KAAK4E,EAAgBC,EAAMlE,EAAKH,EAAMsE,KAC/FF,EAAeoX,aAAalX,IAAS,GAElCoF,MAAMvF,SAASC,EAAgBC,EAAMrE,EAAMsE,EAAOC,EAC7D,CACA,UAAM/E,CAAK4E,EAAgBC,EAAMlE,EAAKH,EAAMsE,GACxC,MAAmG,iBAAtFD,EAAKgB,eAAerF,EAAKsE,GAAQtE,EAAKuB,MAAM,EAAGvB,EAAKC,OAAS,GAAIqE,EAAQ,GAAG,EAC7F,CACA,YAAME,CAAOJ,EAAgBC,EAAMlE,EAAKH,EAAMX,EAAOiF,GAMjDF,EAAeoX,aAAalX,IAAS,SAE9BF,EAAewX,yBAAyBtX,UACxCF,EAAemY,yBAAyBjY,GAE/CF,EAAeqB,aAAanB,IAAS,CACzC,EAEJV,EAAQsa,yBAA2BA,C,mCCnCnCne,OAAO8D,eAAeD,EAAS,aAAc,CAAEvE,OAAO,IACtDuE,EAAQqD,YAAcrD,EAAQoD,gBAAa,EAO3C,MAAMA,UAAmBvF,MAErB,WAAApB,CAAYuT,EAAS8Q,GACjBhb,MAAMkK,GACNtT,KAAKokB,KAAOA,CAChB,EAEJ9gB,EAAQoD,WAAaA,EAOrB,SAAWC,GACPA,EAAY,sBAAwB,qBACpCA,EAAY,uBAAyB,sBACrCA,EAAY,sBAAwB,qBACpCA,EAAY,oBAAsB,oBAClCA,EAAY,uBAAyB,uBACrCA,EAAY,sBAAwB,sBACpCA,EAAY,wBAA0B,wBACtCA,EAAY,2BAA6B,2BACzCA,EAAY,yBAA2B,yBACvCA,EAAY,wBAA0B,wBACtCA,EAAY,yBAA2B,yBACvCA,EAAY,oBAAsB,mBAClCA,EAAY,6BAA+B,4BAC3CA,EAAY,yBAA2B,wBACvCA,EAAY,iCAAmC,gCAC/CA,EAAY,4BAA8B,2BAC1CA,EAAY,0BAA4B,0BACxCA,EAAY,uBAAyB,sBACrCA,EAAY,wBAA0B,uBACtCA,EAAY,yBAA2B,wBACvCA,EAAY,8BAAgC,6BAC5CA,EAAY,4BAA8B,2BAC1CA,EAAY,kCAAoC,iCAChDA,EAAY,iCAAmC,gCAC/CA,EAAY,yBAA2B,wBACvCA,EAAY,0BAA4B,yBACxCA,EAAY,4BAA8B,2BAC1CA,EAAY,gCAAkC,+BAC9CA,EAAY,kCAAoC,iCAChDA,EAAY,0BAA4B,yBACxCA,EAAY,0BAA4B,yBACxCA,EAAY,8BAAgC,6BAC5CA,EAAY,2BAA6B,0BACzCA,EAAY,wBAA0B,uBACtCA,EAAY,sBAAwB,qBACpCA,EAAY,uBAAyB,sBACrCA,EAAY,wBAA0B,uBACtCA,EAAY,8BAAgC,6BAC5CA,EAAY,yBAA2B,wBACvCA,EAAY,4BAA8B,2BAC1CA,EAAY,wBAA0B,uBACtCA,EAAY,2BAA6B,0BACzCA,EAAY,iCAAmC,gCAC/CA,EAAY,iCAAmC,gCAC/CA,EAAY,4BAA8B,2BAC1CA,EAAY,+BAAiC,8BAC7CA,EAAY,oBAAsB,mBAClCA,EAAY,0BAA4B,yBACxCA,EAAY,+BAAiC,8BAC7CA,EAAY,+BAAiC,8BAI7CA,EAAY,yBAA2B,wBACvCA,EAAY,sBAAwB,oBACvC,CAxDD,CAwDiBrD,EAAQqD,cAAgBrD,EAAQqD,YAAc,CAAC,G,qCC9EhElH,OAAO8D,eAAeD,EAAS,aAAc,CAAEvE,OAAO,IACtDuE,EAAQiI,0BAAuB,EAC/B,MAAM/D,EAA0B,EAAQ,OAClC/D,EAAS,EAAQ,OAMvB,MAAM8H,EACF,mBAAA9D,GACI,OAAO,CACX,CACA,YAAMvD,CAAOwD,EAAY5D,EAAgBC,EAAMrE,EAAMX,EAAOiF,GACxD,IAAKrC,MAAMC,QAAQ7C,GAAQ,CACvB,GAAqB,kBAAVA,EAAoB,CAE3B,MAAMqI,QAAgBtD,EAAeY,WAAWhF,GAC1C2uB,EAAoB5qB,EAAOwB,KAAKgD,oBAAoBb,EAAS1H,EAAKsE,EAAQ,IAE1EmE,EAA2B,WAAtBkmB,QACCtqB,EAAKwE,sBAAsBnB,EAASrI,SACpCgF,EAAKqE,eAAehB,EAASrI,GACzC,GAAIoJ,EAAI,CAEJ,MAAMuiB,EAAW,CAAE,MAAuB,cAAhBviB,EAAG+T,SAA2B/T,EAAGpJ,MAAQA,SAC7D+E,EAAee,cAAcnF,EAAKuB,MAAM,EAAGvB,EAAKC,OAAS,GAAI+qB,EAAU1mB,EAAQ,GAAG,GAExFF,EAAeuE,QAAQrE,EAAQ,GAAK,CAACmE,EACzC,CACJ,KACK,CAGD,MAAMmmB,IAAuBxqB,EAAeuE,QAAQrE,EAAQ,GAEvDsqB,UACMxqB,EAAeuE,QAAQrE,SAE5BF,EAAee,cAAcnF,EAAKuB,MAAM,EAAGvB,EAAKC,OAAS,GAAIZ,EAAOiF,EAAQ,GAAG,GAChFsqB,IACDxqB,EAAeuE,QAAQrE,EAAQ,GAAKF,EAAeuE,QAAQrE,GAEnE,CAEA,MAAMqI,QAAoBtI,EAAK0E,gBAAgB/I,EAAKsE,GAAQtE,EAAMsE,GAC5D3D,EAAuB,OAAhBgM,EACPtI,EAAKwE,4BAA4BzE,EAAeY,WAAWhF,GAAO2M,GAClE,KACFhM,SAEMmH,EAAwBqB,sBAAsBC,sBAAsBhF,EAAgBC,EAAMrE,EAAMsE,EAAQ,EAAGD,EAAKwI,QAASlM,GAAM,GAAO,GAAO,SAGjJyD,EAAekF,oCACzB,CACAlF,EAAeqB,aAAanB,IAAS,CACzC,EAEJV,EAAQiI,qBAAuBA,C,qCC3D/B9L,OAAO8D,eAAeD,EAAS,aAAc,CAAEvE,OAAO,IACtDuE,EAAQua,mCAAgC,EACxC,MAAM3U,EAAwB,EAAQ,OAChCxF,EAA0B,EAAQ,OAIxC,MAAMma,UAAsC3U,EAAsBC,oBAC9D,WAAApJ,GACIqJ,MAAM,cACV,CACA,YAAMlF,CAAOJ,EAAgBC,EAAMlE,EAAKH,EAAMX,EAAOiF,IAE5B,kBAAVjF,GAAwC,kBAAVA,GAAsBA,EAAM,YACjE+E,EAAe2C,UAAU,IAAI/C,EAAwBgD,WAAW,mCAAmCgI,KAAKC,UAAU5P,KAAU2E,EAAwBiD,YAAYC,oBAGxK,EAEJtD,EAAQua,8BAAgCA,C,qCCnBxCpe,OAAO8D,eAAeD,EAAS,aAAc,CAAEvE,OAAO,IACtDuE,EAAQqa,8BAA2B,EACnC,MAAMzU,EAAwB,EAAQ,OAItC,MAAMyU,UAAiCzU,EAAsBC,oBACzD,WAAApJ,GACIqJ,MAAM,SACV,CACA,YAAMlF,CAAOJ,EAAgBC,EAAMlE,EAAKH,EAAMX,EAAOiF,GAEjDF,EAAeiX,WAAW/W,EAAQ,IAAK,CAC3C,EAEJV,EAAQqa,yBAA2BA,C,mCChBnC,MAAM4Q,EACJ,WAAAxuB,CAAayuB,EAAMxgB,GACjBhO,KAAKwuB,KAAOA,EACZxuB,KAAKgO,QAAUA,CACjB,CAEA,MAAAgL,CAAQyV,EAAOzgB,GACb,MAAMqL,EAAS,IAAIrZ,KAAKwuB,KAAKC,EAAO,IAAKzuB,KAAKgO,WAAYA,IAY1D,OAVAygB,EAAMzW,GAAG,MAAO,KACTqB,EAAO8G,UACV9G,EAAOnB,KAAK,SAIhBuW,EAAMzW,GAAG,QAASuM,IAChBlL,EAAOnB,KAAK,QAASqM,KAGhBlL,CACT,EAGF,K,6IClBA,MAAMqV,EAAsB,QAE5B,SAASC,EAAaC,GACpB,OAAO1iB,GACiB,cAAlBA,EAAKgQ,SACA,KAGJhQ,EAAKnN,MAAMiU,WAAW0b,GAKpBE,EAAQtF,UAAUpd,EAAKnN,MAAMkC,MAAMytB,EAAoB/uB,SAJrD,IAMb,CAEA,SAASkvB,EAAaD,GACpB,MAAME,EAAUH,EAAYC,GAE5B,OAAO5oB,IACL,MAAMuV,EAAUuT,EAAQ9oB,EAAKuV,SACvBjP,EAAYwiB,EAAQ9oB,EAAKsG,WACzB3H,EAASmqB,EAAQ9oB,EAAKrB,QACtBgX,EAAQmT,EAAQ9oB,EAAK2V,OAE3B,OAAIJ,GAAWjP,GAAa3H,GAAUgX,EAC7BiT,EAAQ5oB,KACbuV,GAAWvV,EAAKuV,QAChBjP,GAAatG,EAAKsG,UAClB3H,GAAUqB,EAAKrB,OACfgX,GAAS3V,EAAK2V,OAIX3V,EAEX,CAEA,MAAM+oB,EACJ,WAAAhvB,CAAa0uB,GAAO,QAAE9b,EAAU+b,EAAmB,QAAEtnB,EAAU,KAAI,eAAE6G,EAAc,QAAE2gB,EAAU,KAAQ,CAAC,GACtG,MAAMrX,EAAS,IAAI,EAAApB,aAAa,CAC9BxD,UACAvL,UACAvB,YAAa+oB,EACb3gB,iBACAzE,kBAAkB,IAGpBilB,EAAMrV,KAAK7B,GAEX,MAAMuX,EAAUD,EAAYD,GAEtBI,EAAY,IAAI,EAAA5X,UAAU,CAC9B6X,YAAY,EACZD,UAAW,CAAChpB,EAAMrD,EAAU8W,KAC1BA,EAAS,KAAMqV,EAAQ9oB,OAY3B,OARAuR,EAAOS,GAAG,UAAW5Q,IACnB3H,OAAOyvB,QAAQ9nB,GAASsR,QAAQ,EAAEsF,EAAQO,MACxCyQ,EAAU9W,KAAK,SAAU8F,EAAQ4Q,EAAQtF,UAAU/K,QAGvDhH,EAAOS,GAAG,QAASuM,GAAOyK,EAAUG,QAAQ5K,IAC5ChN,EAAO6B,KAAK4V,IAEL,OAAWA,EACpB,EAGF,QC1EA,MAAM5Y,UAAe,IACnB,WAAArW,CAAaiO,GACX5E,MAAM,EAAc4E,EACtB,EAGF,O","sources":["webpack://heat-rapid-triples/./node_modules/http-link-header/lib/link.js","webpack://heat-rapid-triples/./node_modules/@zazuko/formats-lazy/node_modules/jsonld-streaming-parser/lib/entryhandler/EntryHandlerArrayValue.js","webpack://heat-rapid-triples/./node_modules/@zazuko/formats-lazy/node_modules/jsonld-streaming-parser/lib/ContextTree.js","webpack://heat-rapid-triples/./node_modules/@zazuko/formats-lazy/node_modules/jsonld-streaming-parser/lib/containerhandler/ContainerHandlerIndex.js","webpack://heat-rapid-triples/./node_modules/@zazuko/formats-lazy/node_modules/jsonld-streaming-parser/lib/entryhandler/keyword/EntryHandlerKeywordNest.js","webpack://heat-rapid-triples/./node_modules/@zazuko/formats-lazy/node_modules/jsonld-streaming-parser/lib/entryhandler/EntryHandlerInvalidFallback.js","webpack://heat-rapid-triples/./node_modules/@zazuko/formats-lazy/node_modules/jsonld-streaming-parser/lib/entryhandler/keyword/EntryHandlerKeywordContext.js","webpack://heat-rapid-triples/./node_modules/@zazuko/formats-lazy/node_modules/jsonld-streaming-parser/lib/entryhandler/EntryHandlerContainer.js","webpack://heat-rapid-triples/./node_modules/@zazuko/formats-lazy/node_modules/jsonld-streaming-parser/lib/entryhandler/keyword/EntryHandlerKeywordUnknownFallback.js","webpack://heat-rapid-triples/./node_modules/@zazuko/formats-lazy/node_modules/jsonld-streaming-parser/lib/containerhandler/ContainerHandlerIdentifier.js","webpack://heat-rapid-triples/./node_modules/@zazuko/formats-lazy/node_modules/jsonld-streaming-parser/lib/entryhandler/keyword/EntryHandlerKeywordType.js","webpack://heat-rapid-triples/./node_modules/@zazuko/formats-lazy/node_modules/jsonld-context-parser/lib/ContextParser.js","webpack://heat-rapid-triples/./node_modules/@zazuko/formats-lazy/node_modules/canonicalize/lib/canonicalize.js","webpack://heat-rapid-triples/./node_modules/@zazuko/formats-lazy/node_modules/jsonld-streaming-parser/lib/entryhandler/keyword/EntryHandlerKeywordIncluded.js","webpack://heat-rapid-triples/./node_modules/@zazuko/formats-lazy/node_modules/jsonld-streaming-parser/lib/entryhandler/keyword/EntryHandlerKeyword.js","webpack://heat-rapid-triples/./node_modules/@zazuko/formats-lazy/node_modules/jsonld-streaming-parser/lib/JsonLdParser.js","webpack://heat-rapid-triples/./node_modules/@zazuko/formats-lazy/node_modules/jsonld-context-parser/lib/Util.js","webpack://heat-rapid-triples/./node_modules/@zazuko/formats-lazy/node_modules/jsonld-context-parser/index.js","webpack://heat-rapid-triples/./node_modules/duplex-to/readable.js","webpack://heat-rapid-triples/./node_modules/@zazuko/formats-lazy/node_modules/jsonld-context-parser/lib/IDocumentLoader.js","webpack://heat-rapid-triples/./node_modules/@bergos/jsonparse/jsonparse.js","webpack://heat-rapid-triples/./node_modules/@zazuko/formats-lazy/node_modules/jsonld-streaming-parser/index.js","webpack://heat-rapid-triples/./node_modules/@zazuko/formats-lazy/node_modules/jsonld-context-parser/lib/JsonLdContextNormalized.js","webpack://heat-rapid-triples/./node_modules/@zazuko/formats-lazy/node_modules/jsonld-context-parser/lib/FetchDocumentLoader.js","webpack://heat-rapid-triples/./node_modules/@zazuko/formats-lazy/node_modules/jsonld-streaming-parser/lib/ParsingContext.js","webpack://heat-rapid-triples/./node_modules/@zazuko/formats-lazy/node_modules/jsonld-streaming-parser/lib/Util.js","webpack://heat-rapid-triples/./node_modules/@zazuko/formats-lazy/node_modules/jsonld-streaming-parser/lib/entryhandler/EntryHandlerPredicate.js","webpack://heat-rapid-triples/./node_modules/@zazuko/formats-lazy/node_modules/jsonld-context-parser/lib/JsonLdContext.js","webpack://heat-rapid-triples/./node_modules/@zazuko/formats-lazy/node_modules/jsonld-streaming-parser/lib/entryhandler/keyword/EntryHandlerKeywordId.js","webpack://heat-rapid-triples/./node_modules/@zazuko/formats-lazy/node_modules/jsonld-streaming-parser/lib/containerhandler/ContainerHandlerLanguage.js","webpack://heat-rapid-triples/./node_modules/@zazuko/formats-lazy/node_modules/jsonld-streaming-parser/lib/entryhandler/keyword/EntryHandlerKeywordValue.js","webpack://heat-rapid-triples/./node_modules/@zazuko/formats-lazy/node_modules/jsonld-context-parser/lib/ErrorCoded.js","webpack://heat-rapid-triples/./node_modules/@zazuko/formats-lazy/node_modules/jsonld-streaming-parser/lib/containerhandler/ContainerHandlerType.js","webpack://heat-rapid-triples/./node_modules/@zazuko/formats-lazy/node_modules/jsonld-streaming-parser/lib/entryhandler/keyword/EntryHandlerKeywordAnnotation.js","webpack://heat-rapid-triples/./node_modules/@zazuko/formats-lazy/node_modules/jsonld-streaming-parser/lib/entryhandler/keyword/EntryHandlerKeywordGraph.js","webpack://heat-rapid-triples/./node_modules/@zazuko/formats-lazy/node_modules/@rdfjs/sink/index.js","webpack://heat-rapid-triples/./node_modules/@zazuko/formats-lazy/node_modules/@rdfjs/parser-jsonld/lib/ParserStream.js","webpack://heat-rapid-triples/./node_modules/@zazuko/formats-lazy/node_modules/@rdfjs/parser-jsonld/index.js"],"sourcesContent":["'use strict'\n\nvar COMPATIBLE_ENCODING_PATTERN = /^utf-?8|ascii|utf-?16-?le|ucs-?2|base-?64|latin-?1$/i\nvar WS_TRIM_PATTERN = /^[\\s\\uFEFF\\xA0]+|[\\s\\uFEFF\\xA0]+$/g\nvar WS_CHAR_PATTERN = /\\s|\\uFEFF|\\xA0/\nvar WS_FOLD_PATTERN = /\\r?\\n[\\x20\\x09]+/g\nvar DELIMITER_PATTERN = /[;,\"]/\nvar WS_DELIMITER_PATTERN = /[;,\"]|\\s/\n\n/**\n * Token character pattern\n * @type {RegExp}\n * @see https://tools.ietf.org/html/rfc7230#section-3.2.6\n */\nvar TOKEN_PATTERN = /^[!#$%&'*+\\-\\.^_`|~\\da-zA-Z]+$/\n\nvar STATE = {\n  IDLE: 1 << 0,\n  URI: 1 << 1,\n  ATTR: 1 << 2,\n}\n\nfunction trim( value ) {\n  return value.replace( WS_TRIM_PATTERN, '' )\n}\n\nfunction hasWhitespace( value ) {\n  return WS_CHAR_PATTERN.test( value )\n}\n\nfunction skipWhitespace( value, offset ) {\n  while( hasWhitespace( value[offset] ) ) {\n    offset++\n  }\n  return offset\n}\n\nfunction needsQuotes( value ) {\n  return WS_DELIMITER_PATTERN.test( value ) ||\n    !TOKEN_PATTERN.test( value )\n}\n\n/**\n * Shallow compares two objects to check if their properties match.\n * @param {object} object1 First object to compare.\n * @param {object} object2 Second object to compare.\n * @returns {boolean} Do the objects have matching properties.\n */\nfunction shallowCompareObjects( object1, object2 ) {\n  return (\n    Object.keys( object1 ).length === Object.keys( object2 ).length &&\n    Object.keys( object1 ).every(\n      ( key ) => key in object2 && object1[ key ] === object2[ key ]\n    )\n  );\n}\n\nclass Link {\n\n  /**\n   * Link\n   * @constructor\n   * @param {String} [value]\n   * @returns {Link}\n   */\n  constructor( value ) {\n\n    /** @type {Array} URI references */\n    this.refs = []\n\n    if( value ) {\n      this.parse( value )\n    }\n\n  }\n\n  /**\n   * Get refs with given relation type\n   * @param {String} value\n   * @returns {Array<Object>}\n   */\n  rel( value ) {\n\n    var links = []\n    var type = value.toLowerCase()\n\n    for( var i = 0; i < this.refs.length; i++ ) {\n      if( typeof this.refs[ i ].rel === 'string' && this.refs[ i ].rel.toLowerCase() === type ) {\n        links.push( this.refs[ i ] )\n      }\n    }\n\n    return links\n\n  }\n\n  /**\n   * Get refs where given attribute has a given value\n   * @param {String} attr\n   * @param {String} value\n   * @returns {Array<Object>}\n   */\n  get( attr, value ) {\n\n    attr = attr.toLowerCase()\n    value = value.toLowerCase()\n\n    var links = []\n\n    for( var i = 0; i < this.refs.length; i++ ) {\n      if( typeof this.refs[ i ][ attr ] === 'string' && this.refs[ i ][ attr ].toLowerCase() === value ) {\n        links.push( this.refs[ i ] )\n      }\n    }\n\n    return links\n\n  }\n\n  /** Sets a reference. */\n  set( link ) {\n    this.refs.push( link )\n    return this\n  }\n\n  /**\n   * Sets a reference if a reference with similar properties isnt already set.\n   */\n  setUnique( link ) {\n\n    if( !this.refs.some(( ref ) => shallowCompareObjects( ref, link )) ) {\n      this.refs.push( link )\n    }\n\n    return this\n\n  }\n\n  has( attr, value ) {\n\n    attr = attr.toLowerCase()\n    value = value.toLowerCase()\n\n    for( var i = 0; i < this.refs.length; i++ ) {\n      if( typeof this.refs[ i ][ attr ] === 'string' && this.refs[ i ][ attr ].toLowerCase() === value ) {\n        return true\n      }\n    }\n\n    return false\n\n  }\n\n  parse( value, offset ) {\n\n    offset = offset || 0\n    value = offset ? value.slice( offset ) : value\n\n    // Trim & unfold folded lines\n    value = trim( value ).replace( WS_FOLD_PATTERN, '' )\n\n    var state = STATE.IDLE\n    var length = value.length\n    var offset = 0\n    var ref = null\n\n    while( offset < length ) {\n      if( state === STATE.IDLE ) {\n        if( hasWhitespace( value[offset] ) ) {\n          offset++\n          continue\n        } else if( value[offset] === '<' ) {\n          if( ref != null ) {\n            ref.rel != null ?\n              this.refs.push( ...Link.expandRelations( ref ) ) :\n              this.refs.push( ref )\n          }\n          var end = value.indexOf( '>', offset )\n          if( end === -1 ) throw new Error( 'Expected end of URI delimiter at offset ' + offset )\n          ref = { uri: value.slice( offset + 1, end ) }\n          // this.refs.push( ref )\n          offset = end\n          state = STATE.URI\n        } else {\n          throw new Error( 'Unexpected character \"' + value[offset] + '\" at offset ' + offset )\n        }\n        offset++\n      } else if( state === STATE.URI ) {\n        if( hasWhitespace( value[offset] ) ) {\n          offset++\n          continue\n        } else if( value[offset] === ';' ) {\n          state = STATE.ATTR\n          offset++\n        } else if( value[offset] === ',' ) {\n          state = STATE.IDLE\n          offset++\n        } else {\n          throw new Error( 'Unexpected character \"' + value[offset] + '\" at offset ' + offset )\n        }\n      } else if( state === STATE.ATTR ) {\n        if( value[offset] ===';' || hasWhitespace( value[offset] ) ) {\n          offset++\n          continue\n        }\n        var end = value.indexOf( '=', offset )\n        if( end === -1 ) end = value.indexOf( ';', offset )\n        if( end === -1 ) end = value.length\n        var attr = trim( value.slice( offset, end ) ).toLowerCase()\n        var attrValue = ''\n        offset = end + 1\n        offset = skipWhitespace( value, offset )\n        if( value[offset] === '\"' ) {\n          offset++\n          while( offset < length ) {\n            if( value[offset] === '\"' ) {\n              offset++; break\n            }\n            if( value[offset] === '\\\\' ) {\n              offset++\n            }\n            attrValue += value[offset]\n            offset++\n          }\n        } else {\n          var end = offset + 1\n          while( !DELIMITER_PATTERN.test( value[end] ) && end < length ) {\n            end++\n          }\n          attrValue = value.slice( offset, end )\n          offset = end\n        }\n        if( ref[ attr ] && Link.isSingleOccurenceAttr( attr ) ) {\n          // Ignore multiples of attributes which may only appear once\n        } else if( attr[ attr.length - 1 ] === '*' ) {\n          ref[ attr ] = Link.parseExtendedValue( attrValue )\n        } else {\n          attrValue = attr === 'type' ?\n            attrValue.toLowerCase() : attrValue\n          if( ref[ attr ] != null ) {\n            if( Array.isArray( ref[ attr ] ) ) {\n              ref[ attr ].push( attrValue )\n            } else {\n              ref[ attr ] = [ ref[ attr ], attrValue ]\n            }\n          } else {\n            ref[ attr ] = attrValue\n          }\n        }\n        switch( value[offset] ) {\n          case ',': state = STATE.IDLE; break\n          case ';': state = STATE.ATTR; break\n        }\n        offset++\n      } else {\n        throw new Error( 'Unknown parser state \"' + state + '\"' )\n      }\n    }\n\n    if( ref != null ) {\n      ref.rel != null ?\n        this.refs.push( ...Link.expandRelations( ref ) ) :\n        this.refs.push( ref )\n    }\n\n    ref = null\n\n    return this\n\n  }\n\n  toString() {\n\n    var refs = []\n    var link = ''\n    var ref = null\n\n    for( var i = 0; i < this.refs.length; i++ ) {\n      ref = this.refs[i]\n      link = Object.keys( this.refs[i] ).reduce( function( link, attr ) {\n        if( attr === 'uri' ) return link\n        return link + '; ' + Link.formatAttribute( attr, ref[ attr ] )\n      }, '<' + ref.uri + '>' )\n      refs.push( link )\n    }\n\n    return refs.join( ', ' )\n\n  }\n\n}\n\n/**\n * Determines whether an encoding can be\n * natively handled with a `Buffer`\n * @param {String} value\n * @returns {Boolean}\n */\nLink.isCompatibleEncoding = function( value ) {\n  return COMPATIBLE_ENCODING_PATTERN.test( value )\n}\n\nLink.parse = function( value, offset ) {\n  return new Link().parse( value, offset )\n}\n\nLink.isSingleOccurenceAttr = function( attr ) {\n  return attr === 'rel' || attr === 'type' || attr === 'media' ||\n    attr === 'title' || attr === 'title*'\n}\n\nLink.isTokenAttr = function( attr ) {\n  return attr === 'rel' || attr === 'type' || attr === 'anchor'\n}\n\nLink.escapeQuotes = function( value ) {\n  return value.replace( /\"/g, '\\\\\"' )\n}\n\nLink.expandRelations = function( ref ) {\n  var rels = ref.rel.split( ' ' )\n  return rels.map( function( rel ) {\n    var value = Object.assign( {}, ref )\n    value.rel = rel\n    return value\n  })\n}\n\n/**\n * Parses an extended value and attempts to decode it\n * @internal\n * @param {String} value\n * @return {Object}\n */\nLink.parseExtendedValue = function( value ) {\n  var parts = /([^']+)?(?:'([^']*)')?(.+)/.exec( value )\n  return {\n    language: parts[2].toLowerCase(),\n    encoding: Link.isCompatibleEncoding( parts[1] ) ?\n      null : parts[1].toLowerCase(),\n    value: Link.isCompatibleEncoding( parts[1] ) ?\n      decodeURIComponent( parts[3] ) : parts[3]\n  }\n}\n\n/**\n * Format a given extended attribute and it's value\n * @param {String} attr\n * @param {Object} data\n * @return {String}\n */\nLink.formatExtendedAttribute = function( attr, data ) {\n\n  var encoding = ( data.encoding || 'utf-8' ).toUpperCase()\n  var language = data.language || 'en'\n\n  var encodedValue = ''\n\n  if( Buffer.isBuffer( data.value ) && Link.isCompatibleEncoding( encoding ) ) {\n    encodedValue = data.value.toString( encoding )\n  } else if( Buffer.isBuffer( data.value ) ) {\n    encodedValue = data.value.toString( 'hex' )\n      .replace( /[0-9a-f]{2}/gi, '%$1' )\n  } else {\n    encodedValue = encodeURIComponent( data.value )\n  }\n\n  return attr + '=' + encoding + '\\'' +\n    language + '\\'' + encodedValue\n\n}\n\n/**\n * Format a given attribute and it's value\n * @param {String} attr\n * @param {String|Object} value\n * @return {String}\n */\nLink.formatAttribute = function( attr, value ) {\n\n  if( Array.isArray( value ) ) {\n    return value.map(( item ) => {\n      return Link.formatAttribute( attr, item )\n    }).join( '; ' )\n  }\n\n  if( attr[ attr.length - 1 ] === '*' || typeof value !== 'string' ) {\n    return Link.formatExtendedAttribute( attr, value )\n  }\n\n  if( Link.isTokenAttr( attr ) ) {\n    value = needsQuotes( value ) ?\n      '\"' + Link.escapeQuotes( value ) + '\"' :\n      Link.escapeQuotes( value )\n  } else if( needsQuotes( value ) ) {\n    value = encodeURIComponent( value )\n    // We don't need to escape <SP> <,> <;> within quotes\n    value = value\n      .replace( /%20/g, ' ' )\n      .replace( /%2C/g, ',' )\n      .replace( /%3B/g, ';' )\n\n    value = '\"' + value + '\"'\n  }\n\n  return attr + '=' + value\n\n}\n\nmodule.exports = Link\n","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.EntryHandlerArrayValue = void 0;\nconst Util_1 = require(\"../Util\");\nconst jsonld_context_parser_1 = require(\"jsonld-context-parser\");\n/**\n * Handles values that are part of an array.\n */\nclass EntryHandlerArrayValue {\n    isPropertyHandler() {\n        return false;\n    }\n    isStackProcessor() {\n        return true;\n    }\n    async validate(parsingContext, util, keys, depth, inProperty) {\n        return this.test(parsingContext, util, null, keys, depth);\n    }\n    async test(parsingContext, util, key, keys, depth) {\n        return typeof keys[depth] === 'number';\n    }\n    async handle(parsingContext, util, key, keys, value, depth) {\n        let parentKey = await util.unaliasKeywordParent(keys, depth);\n        // Check if we have an anonymous list\n        if (parentKey === '@list') {\n            // Our value is part of an array\n            // Determine the list root key\n            let listRootKey = null;\n            let listRootDepth = 0;\n            for (let i = depth - 2; i > 0; i--) {\n                const keyOption = keys[i];\n                if (typeof keyOption === 'string' || typeof keyOption === 'number') {\n                    listRootDepth = i;\n                    listRootKey = keyOption;\n                    break;\n                }\n            }\n            if (listRootKey !== null) {\n                // Emit the given objects as list elements\n                const values = await util.valueToTerm(await parsingContext.getContext(keys), listRootKey, value, depth, keys);\n                for (const object of values) {\n                    await this.handleListElement(parsingContext, util, object, value, depth, keys.slice(0, listRootDepth), listRootDepth);\n                }\n                // If no values were found, emit a falsy list element to force an empty RDF list to be emitted.\n                if (values.length === 0) {\n                    await this.handleListElement(parsingContext, util, null, value, depth, keys.slice(0, listRootDepth), listRootDepth);\n                }\n            }\n        }\n        else if (parentKey === '@set') {\n            // Our value is part of a set, so we just add it to the parent-parent\n            await parsingContext.newOnValueJob(keys.slice(0, -2), value, depth - 2, false);\n        }\n        else if (parentKey !== undefined && parentKey !== '@type') {\n            // Buffer our value using the parent key as predicate\n            // Determine the first parent key that is *not* an array key\n            // This is needed in case we have an @list container with nested arrays,\n            // where each of them should produce nested RDF lists.\n            for (let i = depth - 1; i > 0; i--) {\n                if (typeof keys[i] !== 'number') {\n                    parentKey = await util.unaliasKeyword(keys[i], keys, i);\n                    break;\n                }\n            }\n            // Check if the predicate is marked as an @list in the context\n            const parentContext = await parsingContext.getContext(keys.slice(0, -1));\n            if ('@list' in Util_1.Util.getContextValueContainer(parentContext, parentKey)) {\n                // Our value is part of an array\n                // Emit the given objects as list elements\n                parsingContext.emittedStack[depth + 1] = true; // Ensure the creation of bnodes for empty nodes\n                const values = await util.valueToTerm(await parsingContext.getContext(keys), parentKey, value, depth, keys);\n                for (const object of values) {\n                    await this.handleListElement(parsingContext, util, object, value, depth, keys.slice(0, -1), depth - 1);\n                }\n                // If no values were found, emit a falsy list element to force an empty RDF list to be emitted.\n                if (values.length === 0) {\n                    await this.handleListElement(parsingContext, util, null, value, depth, keys.slice(0, -1), depth - 1);\n                }\n            }\n            else {\n                // Copy the stack values up one level so that the next job can access them.\n                parsingContext.shiftStack(depth, 1);\n                // Execute the job one level higher\n                await parsingContext.newOnValueJob(keys.slice(0, -1), value, depth - 1, false);\n                // Remove any defined contexts at this level to avoid it to propagate to the next array element.\n                parsingContext.contextTree.removeContext(keys.slice(0, -1));\n            }\n        }\n    }\n    async handleListElement(parsingContext, util, value, valueOriginal, depth, listRootKeys, listRootDepth) {\n        // Buffer our value as an RDF list using the listRootKey as predicate\n        let listPointer = parsingContext.listPointerStack[depth];\n        if (valueOriginal !== null && (await util.unaliasKeywords(valueOriginal, listRootKeys, depth))['@value'] !== null) {\n            if (!listPointer || !listPointer.value) {\n                const linkTerm = util.dataFactory.blankNode();\n                listPointer = { value: linkTerm, listRootDepth, listId: linkTerm };\n            }\n            else {\n                // rdf:rest links are always emitted before the next element,\n                // as the blank node identifier is only created at that point.\n                // Because of this reason, the final rdf:nil is emitted when the stack depth is decreased.\n                const newLinkTerm = util.dataFactory.blankNode();\n                parsingContext.emitQuad(depth, util.dataFactory.quad(listPointer.value, util.rdfRest, newLinkTerm, util.getDefaultGraph()));\n                // Update the list pointer for the next element\n                listPointer.value = newLinkTerm;\n            }\n            // Emit a list element for the current value\n            // Omit rdf:first if the value is invalid\n            if (value) {\n                parsingContext.emitQuad(depth, util.dataFactory.quad(listPointer.value, util.rdfFirst, value, util.getDefaultGraph()));\n            }\n        }\n        else {\n            // A falsy list element if found.\n            // Mark it as an rdf:nil list until another valid list element comes in\n            if (!listPointer) {\n                listPointer = { listRootDepth, listId: util.rdfNil };\n            }\n        }\n        parsingContext.listPointerStack[depth] = listPointer;\n        // Error if an annotation was defined\n        if (parsingContext.rdfstar && parsingContext.annotationsBuffer[depth]) {\n            parsingContext.emitError(new jsonld_context_parser_1.ErrorCoded(`Found an illegal annotation inside a list`, jsonld_context_parser_1.ERROR_CODES.INVALID_ANNOTATION));\n        }\n    }\n}\nexports.EntryHandlerArrayValue = EntryHandlerArrayValue;\n//# sourceMappingURL=EntryHandlerArrayValue.js.map","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.ContextTree = void 0;\n/**\n * A tree structure that holds all contexts,\n * based on their position in the JSON object.\n *\n * Positions are identified by a path of keys.\n */\nclass ContextTree {\n    constructor() {\n        this.subTrees = {};\n    }\n    getContext(keys) {\n        if (keys.length > 0) {\n            const [head, ...tail] = keys;\n            const subTree = this.subTrees[head];\n            if (subTree) {\n                const subContext = subTree.getContext(tail);\n                if (subContext) {\n                    return subContext.then(({ context, depth }) => ({ context, depth: depth + 1 }));\n                }\n            }\n        }\n        return this.context ? this.context.then((context) => ({ context, depth: 0 })) : null;\n    }\n    setContext(keys, context) {\n        if (keys.length === 0) {\n            this.context = context;\n        }\n        else {\n            const [head, ...tail] = keys;\n            let subTree = this.subTrees[head];\n            if (!subTree) {\n                subTree = this.subTrees[head] = new ContextTree();\n            }\n            subTree.setContext(tail, context);\n        }\n    }\n    removeContext(path) {\n        this.setContext(path, null);\n    }\n}\nexports.ContextTree = ContextTree;\n//# sourceMappingURL=ContextTree.js.map","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.ContainerHandlerIndex = void 0;\nconst jsonld_context_parser_1 = require(\"jsonld-context-parser\");\nconst EntryHandlerPredicate_1 = require(\"../entryhandler/EntryHandlerPredicate\");\nconst Util_1 = require(\"../Util\");\n/**\n * Container handler for @index.\n *\n * This will ignore the current key and add this entry to the parent node.\n */\nclass ContainerHandlerIndex {\n    canCombineWithGraph() {\n        return true;\n    }\n    async handle(containers, parsingContext, util, keys, value, depth) {\n        if (!Array.isArray(value)) {\n            const graphContainer = '@graph' in containers;\n            // Check if the container is a property-based container by checking if there is a valid @index.\n            const context = await parsingContext.getContext(keys);\n            const indexKey = keys[depth - 1];\n            const indexPropertyRaw = Util_1.Util.getContextValueIndex(context, indexKey);\n            if (indexPropertyRaw) {\n                // Validate the @index value\n                if (jsonld_context_parser_1.Util.isPotentialKeyword(indexPropertyRaw)) {\n                    throw new jsonld_context_parser_1.ErrorCoded(`Keywords can not be used as @index value, got: ${indexPropertyRaw}`, jsonld_context_parser_1.ERROR_CODES.INVALID_TERM_DEFINITION);\n                }\n                if (typeof indexPropertyRaw !== 'string') {\n                    throw new jsonld_context_parser_1.ErrorCoded(`@index values must be strings, got: ${indexPropertyRaw}`, jsonld_context_parser_1.ERROR_CODES.INVALID_TERM_DEFINITION);\n                }\n                // When @index is used, values must be node values, unless @type: @id is defined in the context\n                if (typeof value !== 'object') {\n                    // Error if we don't have @type: @id\n                    if (Util_1.Util.getContextValueType(context, indexKey) !== '@id') {\n                        throw new jsonld_context_parser_1.ErrorCoded(`Property-based index containers require nodes as values or strings with @type: @id, but got: ${value}`, jsonld_context_parser_1.ERROR_CODES.INVALID_VALUE_OBJECT);\n                    }\n                    // Add an @id to the stack, so our expanded @index value can make use of it\n                    const id = util.resourceToTerm(context, value);\n                    if (id) {\n                        parsingContext.idStack[depth + 1] = [id];\n                    }\n                }\n                // Expand the @index value\n                const indexProperty = util.createVocabOrBaseTerm(context, indexPropertyRaw);\n                if (indexProperty) {\n                    const indexValues = await util.valueToTerm(context, indexPropertyRaw, await util.getContainerKey(keys[depth], keys, depth), depth, keys);\n                    if (graphContainer) {\n                        // When we're in a graph container, attach the index to the graph identifier\n                        const graphId = await util.getGraphContainerValue(keys, depth + 1);\n                        for (const indexValue of indexValues) {\n                            parsingContext.emitQuad(depth, util.dataFactory.quad(graphId, indexProperty, indexValue, util.getDefaultGraph()));\n                        }\n                    }\n                    else {\n                        // Otherwise, attach the index to the node identifier\n                        for (const indexValue of indexValues) {\n                            await EntryHandlerPredicate_1.EntryHandlerPredicate.handlePredicateObject(parsingContext, util, keys, depth + 1, indexProperty, indexValue, false, false, false);\n                        }\n                    }\n                }\n            }\n            const depthOffset = graphContainer ? 2 : 1;\n            await parsingContext.newOnValueJob(keys.slice(0, keys.length - depthOffset), value, depth - depthOffset, true);\n            // Flush any pending flush buffers\n            await parsingContext.handlePendingContainerFlushBuffers();\n        }\n        parsingContext.emittedStack[depth] = false; // We have emitted a level higher\n    }\n}\nexports.ContainerHandlerIndex = ContainerHandlerIndex;\n//# sourceMappingURL=ContainerHandlerIndex.js.map","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.EntryHandlerKeywordNest = void 0;\nconst jsonld_context_parser_1 = require(\"jsonld-context-parser\");\nconst EntryHandlerKeyword_1 = require(\"./EntryHandlerKeyword\");\n/**\n * Handles @nest entries.\n */\nclass EntryHandlerKeywordNest extends EntryHandlerKeyword_1.EntryHandlerKeyword {\n    constructor() {\n        super('@nest');\n    }\n    async handle(parsingContext, util, key, keys, value, depth) {\n        if (typeof value !== 'object') {\n            parsingContext.emitError(new jsonld_context_parser_1.ErrorCoded(`Found invalid @nest entry for '${key}': '${value}'`, jsonld_context_parser_1.ERROR_CODES.INVALID_NEST_VALUE));\n        }\n        if ('@value' in await util.unaliasKeywords(value, keys, depth, await parsingContext.getContext(keys))) {\n            parsingContext.emitError(new jsonld_context_parser_1.ErrorCoded(`Found an invalid @value node for '${key}'`, jsonld_context_parser_1.ERROR_CODES.INVALID_NEST_VALUE));\n        }\n        parsingContext.emittedStack[depth] = false;\n    }\n}\nexports.EntryHandlerKeywordNest = EntryHandlerKeywordNest;\n//# sourceMappingURL=EntryHandlerKeywordNest.js.map","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.EntryHandlerInvalidFallback = void 0;\n/**\n * A catch-all for properties, that will either emit an error or ignore,\n * depending on whether or not the `strictValues` property is set.\n */\nclass EntryHandlerInvalidFallback {\n    isPropertyHandler() {\n        return false;\n    }\n    isStackProcessor() {\n        return true;\n    }\n    async validate(parsingContext, util, keys, depth, inProperty) {\n        return false;\n    }\n    async test(parsingContext, util, key, keys, depth) {\n        return true;\n    }\n    async handle(parsingContext, util, key, keys, value, depth) {\n        parsingContext.emittedStack[depth] = false;\n    }\n}\nexports.EntryHandlerInvalidFallback = EntryHandlerInvalidFallback;\n//# sourceMappingURL=EntryHandlerInvalidFallback.js.map","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.EntryHandlerKeywordContext = void 0;\nconst jsonld_context_parser_1 = require(\"jsonld-context-parser\");\nconst EntryHandlerKeyword_1 = require(\"./EntryHandlerKeyword\");\n/**\n * Handles @context entries.\n */\nclass EntryHandlerKeywordContext extends EntryHandlerKeyword_1.EntryHandlerKeyword {\n    constructor() {\n        super('@context');\n    }\n    isStackProcessor() {\n        return false;\n    }\n    async handle(parsingContext, util, key, keys, value, depth) {\n        // Error if an out-of-order context was found when support is not enabled.\n        if (parsingContext.streamingProfile\n            && (parsingContext.processingStack[depth]\n                || parsingContext.processingType[depth]\n                || parsingContext.idStack[depth] !== undefined)) {\n            parsingContext.emitError(new jsonld_context_parser_1.ErrorCoded('Found an out-of-order context, while streaming is enabled.' +\n                '(disable `streamingProfile`)', jsonld_context_parser_1.ERROR_CODES.INVALID_STREAMING_KEY_ORDER));\n        }\n        // Find the parent context to inherit from.\n        // We actually request a context for the current depth (with fallback to parent)\n        // because we want to take into account any property-scoped contexts that are defined for this depth.\n        const parentContext = parsingContext.getContext(keys);\n        // Set the context for this scope\n        const context = parsingContext.parseContext(value, (await parentContext).getContextRaw());\n        parsingContext.contextTree.setContext(keys.slice(0, -1), context);\n        parsingContext.emitContext(value);\n        await parsingContext.validateContext(await context);\n    }\n}\nexports.EntryHandlerKeywordContext = EntryHandlerKeywordContext;\n//# sourceMappingURL=EntryHandlerKeywordContext.js.map","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.EntryHandlerContainer = void 0;\nconst ContainerHandlerIdentifier_1 = require(\"../containerhandler/ContainerHandlerIdentifier\");\nconst ContainerHandlerIndex_1 = require(\"../containerhandler/ContainerHandlerIndex\");\nconst ContainerHandlerLanguage_1 = require(\"../containerhandler/ContainerHandlerLanguage\");\nconst ContainerHandlerType_1 = require(\"../containerhandler/ContainerHandlerType\");\nconst Util_1 = require(\"../Util\");\n/**\n * Handles values that are part of a container type (like @index),\n * as specified by {@link IContainerHandler}.\n */\nclass EntryHandlerContainer {\n    /**\n     * Check fit the given container is a simple @graph container.\n     * Concretely, it will check if no @index or @id is active as well.\n     * @param containers A container hash.\n     */\n    static isSimpleGraphContainer(containers) {\n        return '@graph' in containers\n            && (('@set' in containers && Object.keys(containers).length === 2) || Object.keys(containers).length === 1);\n    }\n    /**\n     * Check fit the given container is a complex @graph container.\n     * Concretely, it will check if @index or @id is active as well next to @graph.\n     * @param containers A container hash.\n     */\n    static isComplexGraphContainer(containers) {\n        return '@graph' in containers\n            && (('@set' in containers && Object.keys(containers).length > 2)\n                || (!('@set' in containers) && Object.keys(containers).length > 1));\n    }\n    /**\n     * Create an graph container index that can be used for identifying a graph term inside the graphContainerTermStack.\n     * @param containers The applicable containers.\n     * @param depth The container depth.\n     * @param keys The array of keys.\n     * @return The graph index.\n     */\n    static getContainerGraphIndex(containers, depth, keys) {\n        let isSimpleGraphContainer = EntryHandlerContainer.isSimpleGraphContainer(containers);\n        let index = '';\n        for (let i = depth; i < keys.length; i++) {\n            if (!isSimpleGraphContainer || typeof keys[i] === 'number') {\n                index += ':' + keys[i];\n            }\n            // Only allow a second 'real' key if in a non-simple graph container.\n            if (!isSimpleGraphContainer && typeof keys[i] !== 'number') {\n                isSimpleGraphContainer = true;\n            }\n        }\n        return index;\n    }\n    /**\n     * Return the applicable container type at the given depth.\n     *\n     * This will ignore any arrays in the key chain.\n     *\n     * @param {ParsingContext} parsingContext A parsing context.\n     * @param {any[]} keys The array of keys.\n     * @param {number} depth The current depth.\n     * @return {Promise<{ containers: {[typeName: string]: boolean}, depth: number, fallback: boolean }>}\n     *          All applicable containers for the given depth,\n     *          the `depth` of the container root (can change when arrays are in the key chain),\n     *          and the `fallback` flag that indicates if the default container type was returned\n     *            (i.e., no dedicated container type is defined).\n     */\n    static async getContainerHandler(parsingContext, keys, depth) {\n        const fallback = {\n            containers: { '@set': true },\n            depth,\n            fallback: true,\n        };\n        // A flag that is enabled when @graph container should be tested in next iteration\n        let checkGraphContainer = false;\n        // Iterate from deeper to higher\n        const context = await parsingContext.getContext(keys, 2);\n        for (let i = depth - 1; i >= 0; i--) {\n            if (typeof keys[i] !== 'number') { // Skip array keys\n                // @graph containers without any other types are one level less deep, and require special handling\n                const containersSelf = Util_1.Util.getContextValue(context, '@container', keys[i], false);\n                if (containersSelf && EntryHandlerContainer.isSimpleGraphContainer(containersSelf)) {\n                    return {\n                        containers: containersSelf,\n                        depth: i + 1,\n                        fallback: false,\n                    };\n                }\n                const containersParent = Util_1.Util.getContextValue(context, '@container', keys[i - 1], false);\n                if (!containersParent) { // If we have the fallback container value\n                    if (checkGraphContainer) {\n                        // Return false if we were already expecting a @graph-@id of @graph-@index container\n                        return fallback;\n                    }\n                    // Check parent-parent, we may be in a @graph-@id of @graph-@index container, which have two levels\n                    checkGraphContainer = true;\n                }\n                else {\n                    // We had an invalid container next iteration, so we now have to check if we were in an @graph container\n                    const graphContainer = '@graph' in containersParent;\n                    // We're in a regular container\n                    for (const containerHandleName in EntryHandlerContainer.CONTAINER_HANDLERS) {\n                        if (containersParent[containerHandleName]) {\n                            if (graphContainer) {\n                                // Only accept graph containers if their combined handlers can handle them.\n                                if (EntryHandlerContainer.CONTAINER_HANDLERS[containerHandleName].canCombineWithGraph()) {\n                                    return {\n                                        containers: containersParent,\n                                        depth: i,\n                                        fallback: false,\n                                    };\n                                }\n                                else {\n                                    return fallback;\n                                }\n                            }\n                            else {\n                                // Only accept if we were not expecting a @graph-@id of @graph-@index container\n                                if (checkGraphContainer) {\n                                    return fallback;\n                                }\n                                else {\n                                    return {\n                                        containers: containersParent,\n                                        depth: i,\n                                        fallback: false,\n                                    };\n                                }\n                            }\n                        }\n                    }\n                    // Fail if no valid container handlers were found\n                    return fallback;\n                }\n            }\n        }\n        return fallback;\n    }\n    /**\n     * Check if we are handling a value at the given depth\n     * that is part of something that should be handled as a container,\n     * AND if this container should be buffered, so that it can be handled by a dedicated container handler.\n     *\n     * For instance, any container with @graph will NOT be buffered.\n     *\n     * This will ignore any arrays in the key chain.\n     *\n     * @param {ParsingContext} parsingContext A parsing context.\n     * @param {any[]} keys The array of keys.\n     * @param {number} depth The current depth.\n     * @return {Promise<boolean>} If we are in the scope of a container handler.\n     */\n    static async isBufferableContainerHandler(parsingContext, keys, depth) {\n        const handler = await EntryHandlerContainer.getContainerHandler(parsingContext, keys, depth);\n        return !handler.fallback && !('@graph' in handler.containers);\n    }\n    isPropertyHandler() {\n        return false;\n    }\n    isStackProcessor() {\n        return true;\n    }\n    async validate(parsingContext, util, keys, depth, inProperty) {\n        return !!await this.test(parsingContext, util, null, keys, depth);\n    }\n    async test(parsingContext, util, key, keys, depth) {\n        const containers = Util_1.Util.getContextValueContainer(await parsingContext.getContext(keys, 2), keys[depth - 1]);\n        for (const containerName in EntryHandlerContainer.CONTAINER_HANDLERS) {\n            if (containers[containerName]) {\n                return {\n                    containers,\n                    handler: EntryHandlerContainer.CONTAINER_HANDLERS[containerName],\n                };\n            }\n        }\n        return null;\n    }\n    async handle(parsingContext, util, key, keys, value, depth, testResult) {\n        return testResult.handler.handle(testResult.containers, parsingContext, util, keys, value, depth);\n    }\n}\nexports.EntryHandlerContainer = EntryHandlerContainer;\nEntryHandlerContainer.CONTAINER_HANDLERS = {\n    '@id': new ContainerHandlerIdentifier_1.ContainerHandlerIdentifier(),\n    '@index': new ContainerHandlerIndex_1.ContainerHandlerIndex(),\n    '@language': new ContainerHandlerLanguage_1.ContainerHandlerLanguage(),\n    '@type': new ContainerHandlerType_1.ContainerHandlerType(),\n};\n//# sourceMappingURL=EntryHandlerContainer.js.map","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.EntryHandlerKeywordUnknownFallback = void 0;\nconst jsonld_context_parser_1 = require(\"jsonld-context-parser\");\n/**\n * A catch-all for keywords, that will either emit an error or ignore,\n * depending on whether or not the `strictValues` property is set.\n */\nclass EntryHandlerKeywordUnknownFallback {\n    isPropertyHandler() {\n        return false;\n    }\n    isStackProcessor() {\n        return true;\n    }\n    async validate(parsingContext, util, keys, depth, inProperty) {\n        const key = await util.unaliasKeyword(keys[depth], keys, depth);\n        if (jsonld_context_parser_1.Util.isPotentialKeyword(key)) {\n            // Don't emit anything inside free-floating lists\n            if (!inProperty) {\n                if (key === '@list') {\n                    return false;\n                }\n            }\n            return true;\n        }\n        return false;\n    }\n    async test(parsingContext, util, key, keys, depth) {\n        return jsonld_context_parser_1.Util.isPotentialKeyword(key);\n    }\n    async handle(parsingContext, util, key, keys, value, depth) {\n        const keywordType = EntryHandlerKeywordUnknownFallback.VALID_KEYWORDS_TYPES[key];\n        if (keywordType !== undefined) {\n            if (keywordType && typeof value !== keywordType.type) {\n                parsingContext.emitError(new jsonld_context_parser_1.ErrorCoded(`Invalid value type for '${key}' with value '${value}'`, keywordType.errorCode));\n            }\n        }\n        else if (parsingContext.strictValues) {\n            parsingContext.emitError(new Error(`Unknown keyword '${key}' with value '${value}'`));\n        }\n        parsingContext.emittedStack[depth] = false;\n    }\n}\nexports.EntryHandlerKeywordUnknownFallback = EntryHandlerKeywordUnknownFallback;\nEntryHandlerKeywordUnknownFallback.VALID_KEYWORDS_TYPES = {\n    '@index': { type: 'string', errorCode: jsonld_context_parser_1.ERROR_CODES.INVALID_INDEX_VALUE },\n    '@list': null,\n    '@reverse': { type: 'object', errorCode: jsonld_context_parser_1.ERROR_CODES.INVALID_REVERSE_VALUE },\n    '@set': null,\n    '@value': null,\n};\n//# sourceMappingURL=EntryHandlerKeywordUnknownFallback.js.map","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.ContainerHandlerIdentifier = void 0;\n/**\n * Container handler for @id.\n *\n * It assumes that the current key is the identifier of the current value.\n * This will add this value to the parent node.\n */\nclass ContainerHandlerIdentifier {\n    canCombineWithGraph() {\n        return true;\n    }\n    async handle(containers, parsingContext, util, keys, value, depth) {\n        let id;\n        // First check if the child node already has a defined id.\n        if (parsingContext.emittedStack[depth + 1] && parsingContext.idStack[depth + 1]) {\n            // Use the existing identifier\n            id = parsingContext.idStack[depth + 1][0];\n        }\n        else {\n            // Create the identifier\n            const keyUnaliased = await util.getContainerKey(keys[depth], keys, depth);\n            const maybeId = keyUnaliased !== null\n                ? await util.resourceToTerm(await parsingContext.getContext(keys), keys[depth])\n                : util.dataFactory.blankNode();\n            // Do nothing if the id is invalid\n            if (!maybeId) {\n                parsingContext.emittedStack[depth] = false; // Don't emit the predicate owning this container.\n                return;\n            }\n            id = maybeId;\n            // Insert the id into the stack so that buffered children can make us of it.\n            parsingContext.idStack[depth + 1] = [id];\n        }\n        // Insert the id into the stack so that parents can make use of it.\n        // Insert it as an array because multiple id container entries may exist\n        let ids = parsingContext.idStack[depth];\n        if (!ids) {\n            ids = parsingContext.idStack[depth] = [];\n        }\n        // Only insert the term if it does not exist yet in the array.\n        if (!ids.some((term) => term.equals(id))) {\n            ids.push(id);\n        }\n        // Flush any pending flush buffers\n        if (!await parsingContext.handlePendingContainerFlushBuffers()) {\n            parsingContext.emittedStack[depth] = false; // Don't emit the predicate owning this container.\n        }\n    }\n}\nexports.ContainerHandlerIdentifier = ContainerHandlerIdentifier;\n//# sourceMappingURL=ContainerHandlerIdentifier.js.map","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.EntryHandlerKeywordType = void 0;\nconst jsonld_context_parser_1 = require(\"jsonld-context-parser\");\nconst Util_1 = require(\"../../Util\");\nconst EntryHandlerPredicate_1 = require(\"../EntryHandlerPredicate\");\nconst EntryHandlerKeyword_1 = require(\"./EntryHandlerKeyword\");\n/**\n * Handles @graph entries.\n */\nclass EntryHandlerKeywordType extends EntryHandlerKeyword_1.EntryHandlerKeyword {\n    constructor() {\n        super('@type');\n    }\n    isStackProcessor() {\n        return false;\n    }\n    async handle(parsingContext, util, key, keys, value, depth) {\n        const keyOriginal = keys[depth];\n        // The current identifier identifies an rdf:type predicate.\n        // But we only emit it once the node closes,\n        // as it's possible that the @type is used to identify the datatype of a literal, which we ignore here.\n        const context = await parsingContext.getContext(keys);\n        const predicate = util.rdfType;\n        const parentKey = await util.unaliasKeywordParent(keys, depth);\n        const reverse = Util_1.Util.isPropertyReverse(context, keyOriginal, parentKey);\n        const isEmbedded = Util_1.Util.isPropertyInEmbeddedNode(parentKey);\n        util.validateReverseInEmbeddedNode(key, reverse, isEmbedded);\n        const isAnnotation = Util_1.Util.isPropertyInAnnotationObject(parentKey);\n        // Handle multiple values if the value is an array\n        const elements = Array.isArray(value) ? value : [value];\n        for (const element of elements) {\n            if (typeof element !== 'string') {\n                parsingContext.emitError(new jsonld_context_parser_1.ErrorCoded(`Found illegal @type '${element}'`, jsonld_context_parser_1.ERROR_CODES.INVALID_TYPE_VALUE));\n            }\n            const type = util.createVocabOrBaseTerm(context, element);\n            if (type) {\n                await EntryHandlerPredicate_1.EntryHandlerPredicate.handlePredicateObject(parsingContext, util, keys, depth, predicate, type, reverse, isEmbedded, isAnnotation);\n            }\n        }\n        // Collect type-scoped contexts if they exist\n        let scopedContext = Promise.resolve(context);\n        let hasTypedScopedContext = false;\n        for (const element of elements.sort()) { // Spec requires lexicographical ordering\n            const typeContext = Util_1.Util.getContextValue(context, '@context', element, null);\n            if (typeContext) {\n                hasTypedScopedContext = true;\n                scopedContext = scopedContext.then((c) => parsingContext.parseContext(typeContext, c.getContextRaw()));\n            }\n        }\n        // Error if an out-of-order type-scoped context was found when support is not enabled.\n        if (parsingContext.streamingProfile\n            && (hasTypedScopedContext || !parsingContext.streamingProfileAllowOutOfOrderPlainType)\n            && (parsingContext.processingStack[depth] || parsingContext.idStack[depth])) {\n            parsingContext.emitError(new jsonld_context_parser_1.ErrorCoded('Found an out-of-order type-scoped context, while streaming is enabled.' +\n                '(disable `streamingProfile`)', jsonld_context_parser_1.ERROR_CODES.INVALID_STREAMING_KEY_ORDER));\n        }\n        // If at least least one type-scoped context applies, set them in the tree.\n        if (hasTypedScopedContext) {\n            // Do not propagate by default\n            scopedContext = scopedContext.then((c) => {\n                // Set the original context at this depth as a fallback\n                // This is needed when a context was already defined at the given depth,\n                // and this context needs to remain accessible from child nodes when propagation is disabled.\n                if (c.getContextRaw()['@propagate'] !== true) {\n                    return new jsonld_context_parser_1.JsonLdContextNormalized(Object.assign(Object.assign({}, c.getContextRaw()), { '@propagate': false, '@__propagateFallback': context.getContextRaw() }));\n                }\n                return c;\n            });\n            // Set the new context in the context tree\n            parsingContext.contextTree.setContext(keys.slice(0, keys.length - 1), scopedContext);\n        }\n        // Flag that type has been processed at this depth\n        parsingContext.processingType[depth] = true;\n    }\n}\nexports.EntryHandlerKeywordType = EntryHandlerKeywordType;\n//# sourceMappingURL=EntryHandlerKeywordType.js.map","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.ContextParser = void 0;\nconst relative_to_absolute_iri_1 = require(\"relative-to-absolute-iri\");\nconst ErrorCoded_1 = require(\"./ErrorCoded\");\nconst FetchDocumentLoader_1 = require(\"./FetchDocumentLoader\");\nconst JsonLdContextNormalized_1 = require(\"./JsonLdContextNormalized\");\nconst Util_1 = require(\"./Util\");\n/**\n * Parses JSON-LD contexts.\n */\nclass ContextParser {\n    constructor(options) {\n        options = options || {};\n        this.documentLoader = options.documentLoader || new FetchDocumentLoader_1.FetchDocumentLoader();\n        this.documentCache = {};\n        this.validateContext = !options.skipValidation;\n        this.expandContentTypeToBase = !!options.expandContentTypeToBase;\n        this.remoteContextsDepthLimit = options.remoteContextsDepthLimit || 32;\n        this.redirectSchemaOrgHttps = 'redirectSchemaOrgHttps' in options ? !!options.redirectSchemaOrgHttps : true;\n    }\n    /**\n     * Validate the given @language value.\n     * An error will be thrown if it is invalid.\n     * @param value An @language value.\n     * @param {boolean} strictRange If the string value should be strictly checked against a regex.\n     * @param {string} errorCode The error code to emit on errors.\n     * @return {boolean} If validation passed.\n     *                   Can only be false if strictRange is false and the string value did not pass the regex.\n     */\n    static validateLanguage(value, strictRange, errorCode) {\n        if (typeof value !== 'string') {\n            throw new ErrorCoded_1.ErrorCoded(`The value of an '@language' must be a string, got '${JSON.stringify(value)}'`, errorCode);\n        }\n        if (!Util_1.Util.REGEX_LANGUAGE_TAG.test(value)) {\n            if (strictRange) {\n                throw new ErrorCoded_1.ErrorCoded(`The value of an '@language' must be a valid language tag, got '${JSON.stringify(value)}'`, errorCode);\n            }\n            else {\n                return false;\n            }\n        }\n        return true;\n    }\n    /**\n     * Validate the given @direction value.\n     * An error will be thrown if it is invalid.\n     * @param value An @direction value.\n     * @param {boolean} strictValues If the string value should be strictly checked against a regex.\n     * @return {boolean} If validation passed.\n     *                   Can only be false if strictRange is false and the string value did not pass the regex.\n     */\n    static validateDirection(value, strictValues) {\n        if (typeof value !== 'string') {\n            throw new ErrorCoded_1.ErrorCoded(`The value of an '@direction' must be a string, got '${JSON.stringify(value)}'`, ErrorCoded_1.ERROR_CODES.INVALID_BASE_DIRECTION);\n        }\n        if (!Util_1.Util.REGEX_DIRECTION_TAG.test(value)) {\n            if (strictValues) {\n                throw new ErrorCoded_1.ErrorCoded(`The value of an '@direction' must be 'ltr' or 'rtl', got '${JSON.stringify(value)}'`, ErrorCoded_1.ERROR_CODES.INVALID_BASE_DIRECTION);\n            }\n            else {\n                return false;\n            }\n        }\n        return true;\n    }\n    /**\n     * Add an @id term for all @reverse terms.\n     * @param {IJsonLdContextNormalizedRaw} context A context.\n     * @return {IJsonLdContextNormalizedRaw} The mutated input context.\n     */\n    idifyReverseTerms(context) {\n        for (const key of Object.keys(context)) {\n            let value = context[key];\n            if (value && typeof value === 'object') {\n                if (value['@reverse'] && !value['@id']) {\n                    if (typeof value['@reverse'] !== 'string' || Util_1.Util.isValidKeyword(value['@reverse'])) {\n                        throw new ErrorCoded_1.ErrorCoded(`Invalid @reverse value, must be absolute IRI or blank node: '${value['@reverse']}'`, ErrorCoded_1.ERROR_CODES.INVALID_IRI_MAPPING);\n                    }\n                    value = context[key] = Object.assign(Object.assign({}, value), { '@id': value['@reverse'] });\n                    value['@id'] = value['@reverse'];\n                    if (Util_1.Util.isPotentialKeyword(value['@reverse'])) {\n                        delete value['@reverse'];\n                    }\n                    else {\n                        value['@reverse'] = true;\n                    }\n                }\n            }\n        }\n        return context;\n    }\n    /**\n     * Expand all prefixed terms in the given context.\n     * @param {IJsonLdContextNormalizedRaw} context A context.\n     * @param {boolean} expandContentTypeToBase If @type inside the context may be expanded\n     *                                          via @base if @vocab is set to null.\n     * @param {string[]} keys Optional set of keys from the context to expand. If left undefined, all\n     * keys in the context will be expanded.\n     */\n    expandPrefixedTerms(context, expandContentTypeToBase, keys) {\n        const contextRaw = context.getContextRaw();\n        for (const key of (keys || Object.keys(contextRaw))) {\n            // Only expand allowed keys\n            if (Util_1.Util.EXPAND_KEYS_BLACKLIST.indexOf(key) < 0 && !Util_1.Util.isReservedInternalKeyword(key)) {\n                // Error if we try to alias a keyword to something else.\n                const keyValue = contextRaw[key];\n                if (Util_1.Util.isPotentialKeyword(key) && Util_1.Util.ALIAS_DOMAIN_BLACKLIST.indexOf(key) >= 0) {\n                    if (key !== '@type' || typeof contextRaw[key] === 'object'\n                        && !(contextRaw[key]['@protected'] || contextRaw[key]['@container'] === '@set')) {\n                        throw new ErrorCoded_1.ErrorCoded(`Keywords can not be aliased to something else.\nTried mapping ${key} to ${JSON.stringify(keyValue)}`, ErrorCoded_1.ERROR_CODES.KEYWORD_REDEFINITION);\n                    }\n                }\n                // Error if we try to alias to an illegal keyword\n                if (Util_1.Util.ALIAS_RANGE_BLACKLIST.indexOf(Util_1.Util.getContextValueId(keyValue)) >= 0) {\n                    throw new ErrorCoded_1.ErrorCoded(`Aliasing to certain keywords is not allowed.\nTried mapping ${key} to ${JSON.stringify(keyValue)}`, ErrorCoded_1.ERROR_CODES.INVALID_KEYWORD_ALIAS);\n                }\n                // Error if this term was marked as prefix as well\n                if (keyValue && Util_1.Util.isPotentialKeyword(Util_1.Util.getContextValueId(keyValue))\n                    && keyValue['@prefix'] === true) {\n                    throw new ErrorCoded_1.ErrorCoded(`Tried to use keyword aliases as prefix: '${key}': '${JSON.stringify(keyValue)}'`, ErrorCoded_1.ERROR_CODES.INVALID_TERM_DEFINITION);\n                }\n                // Loop because prefixes might be nested\n                while (Util_1.Util.isPrefixValue(contextRaw[key])) {\n                    const value = contextRaw[key];\n                    let changed = false;\n                    if (typeof value === 'string') {\n                        contextRaw[key] = context.expandTerm(value, true);\n                        changed = changed || value !== contextRaw[key];\n                    }\n                    else {\n                        const id = value['@id'];\n                        const type = value['@type'];\n                        // If @id is missing, don't allow @id to be added if @prefix: true and key not being a valid IRI.\n                        const canAddIdEntry = !('@prefix' in value) || Util_1.Util.isValidIri(key);\n                        if ('@id' in value) {\n                            // Use @id value for expansion\n                            if (id !== undefined && id !== null && typeof id === 'string') {\n                                contextRaw[key] = Object.assign(Object.assign({}, contextRaw[key]), { '@id': context.expandTerm(id, true) });\n                                changed = changed || id !== contextRaw[key]['@id'];\n                            }\n                        }\n                        else if (!Util_1.Util.isPotentialKeyword(key) && canAddIdEntry) {\n                            // Add an explicit @id value based on the expanded key value\n                            const newId = context.expandTerm(key, true);\n                            if (newId !== key) {\n                                // Don't set @id if expansion failed\n                                contextRaw[key] = Object.assign(Object.assign({}, contextRaw[key]), { '@id': newId });\n                                changed = true;\n                            }\n                        }\n                        if (type && typeof type === 'string' && type !== '@vocab'\n                            && (!value['@container'] || !value['@container']['@type'])\n                            && canAddIdEntry) {\n                            // First check @vocab, then fallback to @base\n                            let expandedType = context.expandTerm(type, true);\n                            if (expandContentTypeToBase && type === expandedType) {\n                                expandedType = context.expandTerm(type, false);\n                            }\n                            if (expandedType !== type) {\n                                changed = true;\n                                contextRaw[key] = Object.assign(Object.assign({}, contextRaw[key]), { '@type': expandedType });\n                            }\n                        }\n                    }\n                    if (!changed) {\n                        break;\n                    }\n                }\n            }\n        }\n    }\n    /**\n     * Normalize the @language entries in the given context to lowercase.\n     * @param {IJsonLdContextNormalizedRaw} context A context.\n     * @param {IParseOptions} parseOptions The parsing options.\n     */\n    normalize(context, { processingMode, normalizeLanguageTags }) {\n        // Lowercase language keys in 1.0\n        if (normalizeLanguageTags || processingMode === 1.0) {\n            for (const key of Object.keys(context)) {\n                if (key === '@language' && typeof context[key] === 'string') {\n                    context[key] = context[key].toLowerCase();\n                }\n                else {\n                    const value = context[key];\n                    if (value && typeof value === 'object') {\n                        if (typeof value['@language'] === 'string') {\n                            const lowercase = value['@language'].toLowerCase();\n                            if (lowercase !== value['@language']) {\n                                context[key] = Object.assign(Object.assign({}, value), { '@language': lowercase });\n                            }\n                        }\n                    }\n                }\n            }\n        }\n    }\n    /**\n     * Convert all @container strings and array values to hash-based values.\n     * @param {IJsonLdContextNormalizedRaw} context A context.\n     */\n    containersToHash(context) {\n        for (const key of Object.keys(context)) {\n            const value = context[key];\n            if (value && typeof value === 'object') {\n                if (typeof value['@container'] === 'string') {\n                    context[key] = Object.assign(Object.assign({}, value), { '@container': { [value['@container']]: true } });\n                }\n                else if (Array.isArray(value['@container'])) {\n                    const newValue = {};\n                    for (const containerValue of value['@container']) {\n                        newValue[containerValue] = true;\n                    }\n                    context[key] = Object.assign(Object.assign({}, value), { '@container': newValue });\n                }\n            }\n        }\n    }\n    /**\n     * Normalize and apply context-level @protected terms onto each term separately.\n     * @param {IJsonLdContextNormalizedRaw} context A context.\n     * @param {number} processingMode The processing mode.\n     */\n    applyScopedProtected(context, { processingMode }, expandOptions) {\n        if (processingMode && processingMode >= 1.1) {\n            if (context['@protected']) {\n                for (const key of Object.keys(context)) {\n                    if (Util_1.Util.isReservedInternalKeyword(key)) {\n                        continue;\n                    }\n                    if (!Util_1.Util.isPotentialKeyword(key) && !Util_1.Util.isTermProtected(context, key)) {\n                        const value = context[key];\n                        if (value && typeof value === 'object') {\n                            if (!('@protected' in context[key])) {\n                                // Mark terms with object values as protected if they don't have an @protected: false annotation\n                                context[key] = Object.assign(Object.assign({}, context[key]), { '@protected': true });\n                            }\n                        }\n                        else {\n                            // Convert string-based term values to object-based values with @protected: true\n                            context[key] = {\n                                '@id': value,\n                                '@protected': true,\n                            };\n                            if (Util_1.Util.isSimpleTermDefinitionPrefix(value, expandOptions)) {\n                                context[key] = Object.assign(Object.assign({}, context[key]), { '@prefix': true });\n                            }\n                        }\n                    }\n                }\n                delete context['@protected'];\n            }\n        }\n    }\n    /**\n     * Check if the given context inheritance does not contain any overrides of protected terms.\n     * @param {IJsonLdContextNormalizedRaw} contextBefore The context that may contain some protected terms.\n     * @param {IJsonLdContextNormalizedRaw} contextAfter A new context that is being applied on the first one.\n     * @param {IExpandOptions} expandOptions Options that are needed for any expansions during this validation.\n     * @param {string[]} keys Optional set of keys from the context to validate. If left undefined, all\n     * keys defined in contextAfter will be checked.\n     */\n    validateKeywordRedefinitions(contextBefore, contextAfter, expandOptions, keys) {\n        for (const key of (keys !== null && keys !== void 0 ? keys : Object.keys(contextAfter))) {\n            if (Util_1.Util.isTermProtected(contextBefore, key)) {\n                // The entry in the context before will always be in object-mode\n                // If the new entry is in string-mode, convert it to object-mode\n                // before checking if it is identical.\n                if (typeof contextAfter[key] === 'string') {\n                    contextAfter[key] = { '@id': contextAfter[key], '@protected': true };\n                }\n                else {\n                    // We modify this deliberately,\n                    // as we need it for the value comparison (they must be identical modulo '@protected')),\n                    // and for the fact that this new value will override the first one.\n                    contextAfter[key] = Object.assign(Object.assign({}, contextAfter[key]), { '@protected': true });\n                }\n                // Error if they are not identical\n                if (!Util_1.Util.deepEqual(contextBefore[key], contextAfter[key])) {\n                    throw new ErrorCoded_1.ErrorCoded(`Attempted to override the protected keyword ${key} from ${JSON.stringify(Util_1.Util.getContextValueId(contextBefore[key]))} to ${JSON.stringify(Util_1.Util.getContextValueId(contextAfter[key]))}`, ErrorCoded_1.ERROR_CODES.PROTECTED_TERM_REDEFINITION);\n                }\n            }\n        }\n    }\n    /**\n     * Validate the entries of the given context.\n     * @param {IJsonLdContextNormalizedRaw} context A context.\n     * @param {IParseOptions} options The parse options.\n     */\n    validate(context, { processingMode }) {\n        for (const key of Object.keys(context)) {\n            // Ignore reserved internal keywords.\n            if (Util_1.Util.isReservedInternalKeyword(key)) {\n                continue;\n            }\n            // Do not allow empty term\n            if (key === '') {\n                throw new ErrorCoded_1.ErrorCoded(`The empty term is not allowed, got: '${key}': '${JSON.stringify(context[key])}'`, ErrorCoded_1.ERROR_CODES.INVALID_TERM_DEFINITION);\n            }\n            const value = context[key];\n            const valueType = typeof value;\n            // First check if the key is a keyword\n            if (Util_1.Util.isPotentialKeyword(key)) {\n                switch (key.substr(1)) {\n                    case 'vocab':\n                        if (value !== null && valueType !== 'string') {\n                            throw new ErrorCoded_1.ErrorCoded(`Found an invalid @vocab IRI: ${value}`, ErrorCoded_1.ERROR_CODES.INVALID_VOCAB_MAPPING);\n                        }\n                        break;\n                    case 'base':\n                        if (value !== null && valueType !== 'string') {\n                            throw new ErrorCoded_1.ErrorCoded(`Found an invalid @base IRI: ${context[key]}`, ErrorCoded_1.ERROR_CODES.INVALID_BASE_IRI);\n                        }\n                        break;\n                    case 'language':\n                        if (value !== null) {\n                            ContextParser.validateLanguage(value, true, ErrorCoded_1.ERROR_CODES.INVALID_DEFAULT_LANGUAGE);\n                        }\n                        break;\n                    case 'version':\n                        if (value !== null && valueType !== 'number') {\n                            throw new ErrorCoded_1.ErrorCoded(`Found an invalid @version number: ${value}`, ErrorCoded_1.ERROR_CODES.INVALID_VERSION_VALUE);\n                        }\n                        break;\n                    case 'direction':\n                        if (value !== null) {\n                            ContextParser.validateDirection(value, true);\n                        }\n                        break;\n                    case 'propagate':\n                        if (processingMode === 1.0) {\n                            throw new ErrorCoded_1.ErrorCoded(`Found an illegal @propagate keyword: ${value}`, ErrorCoded_1.ERROR_CODES.INVALID_CONTEXT_ENTRY);\n                        }\n                        if (value !== null && valueType !== 'boolean') {\n                            throw new ErrorCoded_1.ErrorCoded(`Found an invalid @propagate value: ${value}`, ErrorCoded_1.ERROR_CODES.INVALID_PROPAGATE_VALUE);\n                        }\n                        break;\n                }\n                // Don't allow keywords to be overridden\n                if (Util_1.Util.isValidKeyword(key) && Util_1.Util.isValidKeyword(Util_1.Util.getContextValueId(value))) {\n                    throw new ErrorCoded_1.ErrorCoded(`Illegal keyword alias in term value, found: '${key}': '${Util_1.Util\n                        .getContextValueId(value)}'`, ErrorCoded_1.ERROR_CODES.KEYWORD_REDEFINITION);\n                }\n                continue;\n            }\n            // Otherwise, consider the key a term\n            if (value !== null) {\n                switch (valueType) {\n                    case 'string':\n                        if (Util_1.Util.getPrefix(value, context) === key) {\n                            throw new ErrorCoded_1.ErrorCoded(`Detected cyclical IRI mapping in context entry: '${key}': '${JSON\n                                .stringify(value)}'`, ErrorCoded_1.ERROR_CODES.CYCLIC_IRI_MAPPING);\n                        }\n                        if (Util_1.Util.isValidIriWeak(key)) {\n                            if (value === '@type') {\n                                throw new ErrorCoded_1.ErrorCoded(`IRIs can not be mapped to @type, found: '${key}': '${value}'`, ErrorCoded_1.ERROR_CODES.INVALID_IRI_MAPPING);\n                            }\n                            else if (Util_1.Util.isValidIri(value) && value !== new JsonLdContextNormalized_1.JsonLdContextNormalized(context).expandTerm(key)) {\n                                throw new ErrorCoded_1.ErrorCoded(`IRIs can not be mapped to other IRIs, found: '${key}': '${value}'`, ErrorCoded_1.ERROR_CODES.INVALID_IRI_MAPPING);\n                            }\n                        }\n                        break;\n                    case 'object':\n                        if (!Util_1.Util.isCompactIri(key) && !('@id' in value)\n                            && (value['@type'] === '@id' ? !context['@base'] : !context['@vocab'])) {\n                            throw new ErrorCoded_1.ErrorCoded(`Missing @id in context entry: '${key}': '${JSON.stringify(value)}'`, ErrorCoded_1.ERROR_CODES.INVALID_IRI_MAPPING);\n                        }\n                        for (const objectKey of Object.keys(value)) {\n                            const objectValue = value[objectKey];\n                            if (!objectValue) {\n                                continue;\n                            }\n                            switch (objectKey) {\n                                case '@id':\n                                    if (Util_1.Util.isValidKeyword(objectValue)\n                                        && objectValue !== '@type' && objectValue !== '@id' && objectValue !== '@graph' && objectValue !== '@nest') {\n                                        throw new ErrorCoded_1.ErrorCoded(`Illegal keyword alias in term value, found: '${key}': '${JSON.stringify(value)}'`, ErrorCoded_1.ERROR_CODES.INVALID_IRI_MAPPING);\n                                    }\n                                    if (Util_1.Util.isValidIriWeak(key)) {\n                                        if (objectValue === '@type') {\n                                            throw new ErrorCoded_1.ErrorCoded(`IRIs can not be mapped to @type, found: '${key}': '${JSON.stringify(value)}'`, ErrorCoded_1.ERROR_CODES.INVALID_IRI_MAPPING);\n                                        }\n                                        else if (Util_1.Util.isValidIri(objectValue)\n                                            && objectValue !== new JsonLdContextNormalized_1.JsonLdContextNormalized(context).expandTerm(key)) {\n                                            throw new ErrorCoded_1.ErrorCoded(`IRIs can not be mapped to other IRIs, found: '${key}': '${JSON.stringify(value)}'`, ErrorCoded_1.ERROR_CODES.INVALID_IRI_MAPPING);\n                                        }\n                                    }\n                                    if (typeof objectValue !== 'string') {\n                                        throw new ErrorCoded_1.ErrorCoded(`Detected non-string @id in context entry: '${key}': '${JSON.stringify(value)}'`, ErrorCoded_1.ERROR_CODES.INVALID_IRI_MAPPING);\n                                    }\n                                    if (Util_1.Util.getPrefix(objectValue, context) === key) {\n                                        throw new ErrorCoded_1.ErrorCoded(`Detected cyclical IRI mapping in context entry: '${key}': '${JSON\n                                            .stringify(value)}'`, ErrorCoded_1.ERROR_CODES.CYCLIC_IRI_MAPPING);\n                                    }\n                                    break;\n                                case '@type':\n                                    if (value['@container'] === '@type' && objectValue !== '@id' && objectValue !== '@vocab') {\n                                        throw new ErrorCoded_1.ErrorCoded(`@container: @type only allows @type: @id or @vocab, but got: '${key}': '${objectValue}'`, ErrorCoded_1.ERROR_CODES.INVALID_TYPE_MAPPING);\n                                    }\n                                    if (typeof objectValue !== 'string') {\n                                        throw new ErrorCoded_1.ErrorCoded(`The value of an '@type' must be a string, got '${JSON.stringify(valueType)}'`, ErrorCoded_1.ERROR_CODES.INVALID_TYPE_MAPPING);\n                                    }\n                                    if (objectValue !== '@id' && objectValue !== '@vocab'\n                                        && (processingMode === 1.0 || objectValue !== '@json')\n                                        && (processingMode === 1.0 || objectValue !== '@none')\n                                        && (objectValue[0] === '_' || !Util_1.Util.isValidIri(objectValue))) {\n                                        throw new ErrorCoded_1.ErrorCoded(`A context @type must be an absolute IRI, found: '${key}': '${objectValue}'`, ErrorCoded_1.ERROR_CODES.INVALID_TYPE_MAPPING);\n                                    }\n                                    break;\n                                case '@reverse':\n                                    if (typeof objectValue === 'string' && value['@id'] && value['@id'] !== objectValue) {\n                                        throw new ErrorCoded_1.ErrorCoded(`Found non-matching @id and @reverse term values in '${key}':\\\n'${objectValue}' and '${value['@id']}'`, ErrorCoded_1.ERROR_CODES.INVALID_REVERSE_PROPERTY);\n                                    }\n                                    if ('@nest' in value) {\n                                        throw new ErrorCoded_1.ErrorCoded(`@nest is not allowed in the reverse property '${key}'`, ErrorCoded_1.ERROR_CODES.INVALID_REVERSE_PROPERTY);\n                                    }\n                                    break;\n                                case '@container':\n                                    if (processingMode === 1.0) {\n                                        if (Object.keys(objectValue).length > 1\n                                            || Util_1.Util.CONTAINERS_1_0.indexOf(Object.keys(objectValue)[0]) < 0) {\n                                            throw new ErrorCoded_1.ErrorCoded(`Invalid term @container for '${key}' ('${Object.keys(objectValue)}') in 1.0, \\\nmust be only one of ${Util_1.Util.CONTAINERS_1_0.join(', ')}`, ErrorCoded_1.ERROR_CODES.INVALID_CONTAINER_MAPPING);\n                                        }\n                                    }\n                                    for (const containerValue of Object.keys(objectValue)) {\n                                        if (containerValue === '@list' && value['@reverse']) {\n                                            throw new ErrorCoded_1.ErrorCoded(`Term value can not be @container: @list and @reverse at the same time on '${key}'`, ErrorCoded_1.ERROR_CODES.INVALID_REVERSE_PROPERTY);\n                                        }\n                                        if (Util_1.Util.CONTAINERS.indexOf(containerValue) < 0) {\n                                            throw new ErrorCoded_1.ErrorCoded(`Invalid term @container for '${key}' ('${containerValue}'), \\\nmust be one of ${Util_1.Util.CONTAINERS.join(', ')}`, ErrorCoded_1.ERROR_CODES.INVALID_CONTAINER_MAPPING);\n                                        }\n                                    }\n                                    break;\n                                case '@language':\n                                    ContextParser.validateLanguage(objectValue, true, ErrorCoded_1.ERROR_CODES.INVALID_LANGUAGE_MAPPING);\n                                    break;\n                                case '@direction':\n                                    ContextParser.validateDirection(objectValue, true);\n                                    break;\n                                case '@prefix':\n                                    if (objectValue !== null && typeof objectValue !== 'boolean') {\n                                        throw new ErrorCoded_1.ErrorCoded(`Found an invalid term @prefix boolean in: '${key}': '${JSON.stringify(value)}'`, ErrorCoded_1.ERROR_CODES.INVALID_PREFIX_VALUE);\n                                    }\n                                    if (!('@id' in value) && !Util_1.Util.isValidIri(key)) {\n                                        throw new ErrorCoded_1.ErrorCoded(`Invalid @prefix definition for '${key}' ('${JSON.stringify(value)}'`, ErrorCoded_1.ERROR_CODES.INVALID_TERM_DEFINITION);\n                                    }\n                                    break;\n                                case '@index':\n                                    if (processingMode === 1.0 || !value['@container'] || !value['@container']['@index']) {\n                                        throw new ErrorCoded_1.ErrorCoded(`Attempt to add illegal key to value object: '${key}': '${JSON.stringify(value)}'`, ErrorCoded_1.ERROR_CODES.INVALID_TERM_DEFINITION);\n                                    }\n                                    break;\n                                case '@nest':\n                                    if (Util_1.Util.isPotentialKeyword(objectValue) && objectValue !== '@nest') {\n                                        throw new ErrorCoded_1.ErrorCoded(`Found an invalid term @nest value in: '${key}': '${JSON.stringify(value)}'`, ErrorCoded_1.ERROR_CODES.INVALID_NEST_VALUE);\n                                    }\n                            }\n                        }\n                        break;\n                    default:\n                        throw new ErrorCoded_1.ErrorCoded(`Found an invalid term value: '${key}': '${value}'`, ErrorCoded_1.ERROR_CODES.INVALID_TERM_DEFINITION);\n                }\n            }\n        }\n    }\n    /**\n     * Apply the @base context entry to the given context under certain circumstances.\n     * @param context A context.\n     * @param options Parsing options.\n     * @param inheritFromParent If the @base value from the parent context can be inherited.\n     * @return The given context.\n     */\n    applyBaseEntry(context, options, inheritFromParent) {\n        // In some special cases, this can be a string, so ignore those.\n        if (typeof context === 'string') {\n            return context;\n        }\n        // Give priority to @base in the parent context\n        if (inheritFromParent && !('@base' in context) && options.parentContext\n            && typeof options.parentContext === 'object' && '@base' in options.parentContext) {\n            context['@base'] = options.parentContext['@base'];\n            if (options.parentContext['@__baseDocument']) {\n                context['@__baseDocument'] = true;\n            }\n        }\n        // Override the base IRI if provided.\n        if (options.baseIRI && !options.external) {\n            if (!('@base' in context)) {\n                // The context base is the document base\n                context['@base'] = options.baseIRI;\n                context['@__baseDocument'] = true;\n            }\n            else if (context['@base'] !== null && typeof context['@base'] === 'string'\n                && !Util_1.Util.isValidIri(context['@base'])) {\n                // The context base is relative to the document base\n                context['@base'] = (0, relative_to_absolute_iri_1.resolve)(context['@base'], options.parentContext && options.parentContext['@base'] || options.baseIRI);\n            }\n        }\n        return context;\n    }\n    /**\n     * Resolve relative context IRIs, or return full IRIs as-is.\n     * @param {string} contextIri A context IRI.\n     * @param {string} baseIRI A base IRI.\n     * @return {string} The normalized context IRI.\n     */\n    normalizeContextIri(contextIri, baseIRI) {\n        if (!Util_1.Util.isValidIri(contextIri)) {\n            try {\n                contextIri = (0, relative_to_absolute_iri_1.resolve)(contextIri, baseIRI);\n            }\n            catch (_a) {\n                throw new Error(`Invalid context IRI: ${contextIri}`);\n            }\n        }\n        // TODO: Temporary workaround for fixing schema.org CORS issues (https://github.com/schemaorg/schemaorg/issues/2578#issuecomment-652324465)\n        if (this.redirectSchemaOrgHttps && contextIri.startsWith('http://schema.org')) {\n            contextIri = 'https://schema.org/';\n        }\n        return contextIri;\n    }\n    /**\n     * Parse scoped contexts in the given context.\n     * @param {IJsonLdContextNormalizedRaw} context A context.\n     * @param {IParseOptions} options Parsing options.\n     * @return {IJsonLdContextNormalizedRaw} The mutated input context.\n     * @param {string[]} keys Optional set of keys from the context to parseInnerContexts of. If left undefined, all\n     * keys in the context will be iterated over.\n     */\n    async parseInnerContexts(context, options, keys) {\n        for (const key of (keys !== null && keys !== void 0 ? keys : Object.keys(context))) {\n            const value = context[key];\n            if (value && typeof value === 'object') {\n                if ('@context' in value && value['@context'] !== null && !options.ignoreScopedContexts) {\n                    // Simulate a processing based on the parent context to check if there are any (potential errors).\n                    // Honestly, I find it a bit weird to do this here, as the context may be unused,\n                    // and the final effective context may differ based on any other embedded/scoped contexts.\n                    // But hey, it's part of the spec, so we have no choice...\n                    // https://w3c.github.io/json-ld-api/#h-note-10\n                    if (this.validateContext) {\n                        try {\n                            const parentContext = Object.assign(Object.assign({}, context), { [key]: Object.assign({}, context[key]) });\n                            delete parentContext[key]['@context'];\n                            await this.parse(value['@context'], Object.assign(Object.assign({}, options), { external: false, parentContext, ignoreProtection: true, ignoreRemoteScopedContexts: true, ignoreScopedContexts: true }));\n                        }\n                        catch (e) {\n                            throw new ErrorCoded_1.ErrorCoded(e.message, ErrorCoded_1.ERROR_CODES.INVALID_SCOPED_CONTEXT);\n                        }\n                    }\n                    context[key] = Object.assign(Object.assign({}, value), { '@context': (await this.parse(value['@context'], Object.assign(Object.assign({}, options), { external: false, minimalProcessing: true, ignoreRemoteScopedContexts: true, parentContext: context })))\n                            .getContextRaw() });\n                }\n            }\n        }\n        return context;\n    }\n    async parse(context, options = {}, \n    // These options are only for internal use on recursive calls and should not be used by\n    // libraries consuming this function\n    internalOptions = {}) {\n        const { baseIRI, parentContext, external, processingMode = ContextParser.DEFAULT_PROCESSING_MODE, normalizeLanguageTags, ignoreProtection, minimalProcessing, } = options;\n        const remoteContexts = options.remoteContexts || {};\n        // Avoid remote context overflows\n        if (Object.keys(remoteContexts).length >= this.remoteContextsDepthLimit) {\n            throw new ErrorCoded_1.ErrorCoded('Detected an overflow in remote context inclusions: ' + Object.keys(remoteContexts), ErrorCoded_1.ERROR_CODES.CONTEXT_OVERFLOW);\n        }\n        if (context === null || context === undefined) {\n            // Don't allow context nullification and there are protected terms\n            if (!ignoreProtection && parentContext && Util_1.Util.hasProtectedTerms(parentContext)) {\n                throw new ErrorCoded_1.ErrorCoded('Illegal context nullification when terms are protected', ErrorCoded_1.ERROR_CODES.INVALID_CONTEXT_NULLIFICATION);\n            }\n            // Context that are explicitly set to null are empty.\n            return new JsonLdContextNormalized_1.JsonLdContextNormalized(this.applyBaseEntry({}, options, false));\n        }\n        else if (typeof context === 'string') {\n            const contextIri = this.normalizeContextIri(context, baseIRI);\n            const overriddenLoad = this.getOverriddenLoad(contextIri, options);\n            if (overriddenLoad) {\n                return new JsonLdContextNormalized_1.JsonLdContextNormalized(overriddenLoad);\n            }\n            const parsedStringContext = await this.parse(await this.load(contextIri), Object.assign(Object.assign({}, options), { baseIRI: contextIri, external: true, remoteContexts: Object.assign(Object.assign({}, remoteContexts), { [contextIri]: true }) }));\n            this.applyBaseEntry(parsedStringContext.getContextRaw(), options, true);\n            return parsedStringContext;\n        }\n        else if (Array.isArray(context)) {\n            // As a performance consideration, first load all external contexts in parallel.\n            const contextIris = [];\n            const contexts = await Promise.all(context.map((subContext, i) => {\n                if (typeof subContext === 'string') {\n                    const contextIri = this.normalizeContextIri(subContext, baseIRI);\n                    contextIris[i] = contextIri;\n                    const overriddenLoad = this.getOverriddenLoad(contextIri, options);\n                    if (overriddenLoad) {\n                        return overriddenLoad;\n                    }\n                    return this.load(contextIri);\n                }\n                else {\n                    return subContext;\n                }\n            }));\n            // Don't apply inheritance logic on minimal processing\n            if (minimalProcessing) {\n                return new JsonLdContextNormalized_1.JsonLdContextNormalized(contexts);\n            }\n            const reducedContexts = await contexts.reduce((accContextPromise, contextEntry, i) => accContextPromise\n                .then((accContext) => this.parse(contextEntry, Object.assign(Object.assign({}, options), { baseIRI: contextIris[i] || options.baseIRI, external: !!contextIris[i] || options.external, parentContext: accContext.getContextRaw(), remoteContexts: contextIris[i] ? Object.assign(Object.assign({}, remoteContexts), { [contextIris[i]]: true }) : remoteContexts }), \n            // @ts-expect-error: This third argument causes a type error because we have hidden it from consumers\n            {\n                skipValidation: i < contexts.length - 1,\n            })), Promise.resolve(new JsonLdContextNormalized_1.JsonLdContextNormalized(parentContext || {})));\n            // Override the base IRI if provided.\n            this.applyBaseEntry(reducedContexts.getContextRaw(), options, true);\n            return reducedContexts;\n        }\n        else if (typeof context === 'object') {\n            if ('@context' in context) {\n                return await this.parse(context['@context'], options);\n            }\n            // Make a deep clone of the given context, to avoid modifying it.\n            context = Object.assign({}, context);\n            // According to the JSON-LD spec, @base must be ignored from external contexts.\n            if (external) {\n                delete context['@base'];\n            }\n            // Override the base IRI if provided.\n            this.applyBaseEntry(context, options, true);\n            // Hashify container entries\n            // Do this before protected term validation as that influences term format\n            this.containersToHash(context);\n            // Don't perform any other modifications if only minimal processing is needed.\n            if (minimalProcessing) {\n                return new JsonLdContextNormalized_1.JsonLdContextNormalized(context);\n            }\n            // In JSON-LD 1.1, load @import'ed context prior to processing.\n            let importContext = {};\n            if ('@import' in context) {\n                if (processingMode >= 1.1) {\n                    // Only accept string values\n                    if (typeof context['@import'] !== 'string') {\n                        throw new ErrorCoded_1.ErrorCoded('An @import value must be a string, but got ' + typeof context['@import'], ErrorCoded_1.ERROR_CODES.INVALID_IMPORT_VALUE);\n                    }\n                    // Load context\n                    importContext = await this.loadImportContext(this.normalizeContextIri(context['@import'], baseIRI));\n                    delete context['@import'];\n                }\n                else {\n                    throw new ErrorCoded_1.ErrorCoded('Context importing is not supported in JSON-LD 1.0', ErrorCoded_1.ERROR_CODES.INVALID_CONTEXT_ENTRY);\n                }\n            }\n            this.applyScopedProtected(importContext, { processingMode }, JsonLdContextNormalized_1.defaultExpandOptions);\n            const newContext = Object.assign(importContext, context);\n            // Handle terms (before protection checks)\n            this.idifyReverseTerms(newContext);\n            this.normalize(newContext, { processingMode, normalizeLanguageTags });\n            this.applyScopedProtected(newContext, { processingMode }, JsonLdContextNormalized_1.defaultExpandOptions);\n            const keys = Object.keys(newContext);\n            const overlappingKeys = [];\n            if (typeof parentContext === 'object') {\n                // Merge different parts of the final context in order\n                for (const key in parentContext) {\n                    if (key in newContext) {\n                        overlappingKeys.push(key);\n                    }\n                    else {\n                        newContext[key] = parentContext[key];\n                    }\n                }\n            }\n            // Parse inner contexts with minimal processing\n            await this.parseInnerContexts(newContext, options, keys);\n            const newContextWrapped = new JsonLdContextNormalized_1.JsonLdContextNormalized(newContext);\n            // In JSON-LD 1.1, @vocab can be relative to @vocab in the parent context, or a compact IRI.\n            if ((newContext && newContext['@version'] || ContextParser.DEFAULT_PROCESSING_MODE) >= 1.1\n                && ((context['@vocab'] && typeof context['@vocab'] === 'string') || context['@vocab'] === '')) {\n                if (parentContext && '@vocab' in parentContext && context['@vocab'].indexOf(':') < 0) {\n                    newContext['@vocab'] = parentContext['@vocab'] + context['@vocab'];\n                }\n                else if (Util_1.Util.isCompactIri(context['@vocab']) || context['@vocab'] in newContext) {\n                    // @vocab is a compact IRI or refers exactly to a prefix\n                    newContext['@vocab'] = newContextWrapped.expandTerm(context['@vocab'], true);\n                }\n            }\n            this.expandPrefixedTerms(newContextWrapped, this.expandContentTypeToBase, keys);\n            // In JSON-LD 1.1, check if we are not redefining any protected keywords\n            if (!ignoreProtection && parentContext && processingMode >= 1.1) {\n                this.validateKeywordRedefinitions(parentContext, newContext, JsonLdContextNormalized_1.defaultExpandOptions, overlappingKeys);\n            }\n            if (this.validateContext && !internalOptions.skipValidation) {\n                this.validate(newContext, { processingMode });\n            }\n            return newContextWrapped;\n        }\n        else {\n            throw new ErrorCoded_1.ErrorCoded(`Tried parsing a context that is not a string, array or object, but got ${context}`, ErrorCoded_1.ERROR_CODES.INVALID_LOCAL_CONTEXT);\n        }\n    }\n    /**\n     * Fetch the given URL as a raw JSON-LD context.\n     * @param url An URL.\n     * @return A promise resolving to a raw JSON-LD context.\n     */\n    async load(url) {\n        // First try to retrieve the context from cache\n        const cached = this.documentCache[url];\n        if (cached) {\n            return cached;\n        }\n        // If not in cache, load it\n        let document;\n        try {\n            document = await this.documentLoader.load(url);\n        }\n        catch (e) {\n            throw new ErrorCoded_1.ErrorCoded(`Failed to load remote context ${url}: ${e.message}`, ErrorCoded_1.ERROR_CODES.LOADING_REMOTE_CONTEXT_FAILED);\n        }\n        // Validate the context\n        if (!('@context' in document)) {\n            throw new ErrorCoded_1.ErrorCoded(`Missing @context in remote context at ${url}`, ErrorCoded_1.ERROR_CODES.INVALID_REMOTE_CONTEXT);\n        }\n        return this.documentCache[url] = document['@context'];\n    }\n    /**\n     * Override the given context that may be loaded.\n     *\n     * This will check whether or not the url is recursively being loaded.\n     * @param url An URL.\n     * @param options Parsing options.\n     * @return An overridden context, or null.\n     *         Optionally an error can be thrown if a cyclic context is detected.\n     */\n    getOverriddenLoad(url, options) {\n        if (url in (options.remoteContexts || {})) {\n            if (options.ignoreRemoteScopedContexts) {\n                return url;\n            }\n            else {\n                throw new ErrorCoded_1.ErrorCoded('Detected a cyclic context inclusion of ' + url, ErrorCoded_1.ERROR_CODES.RECURSIVE_CONTEXT_INCLUSION);\n            }\n        }\n        return null;\n    }\n    /**\n     * Load an @import'ed context.\n     * @param importContextIri The full URI of an @import value.\n     */\n    async loadImportContext(importContextIri) {\n        // Load the context - and do a deep clone since we are about to mutate it\n        let importContext = await this.load(importContextIri);\n        // Require the context to be a non-array object\n        if (typeof importContext !== 'object' || Array.isArray(importContext)) {\n            throw new ErrorCoded_1.ErrorCoded('An imported context must be a single object: ' + importContextIri, ErrorCoded_1.ERROR_CODES.INVALID_REMOTE_CONTEXT);\n        }\n        // Error if the context contains another @import\n        if ('@import' in importContext) {\n            throw new ErrorCoded_1.ErrorCoded('An imported context can not import another context: ' + importContextIri, ErrorCoded_1.ERROR_CODES.INVALID_CONTEXT_ENTRY);\n        }\n        importContext = Object.assign({}, importContext);\n        // Containers have to be converted into hash values the same way as for the importing context\n        // Otherwise context validation will fail for container values\n        this.containersToHash(importContext);\n        return importContext;\n    }\n}\nContextParser.DEFAULT_PROCESSING_MODE = 1.1;\nexports.ContextParser = ContextParser;\n//# sourceMappingURL=ContextParser.js.map","/* jshint esversion: 6 */\n/* jslint node: true */\n'use strict';\n\nmodule.exports = function serialize (object) {\n  if (object === null || typeof object !== 'object' || object.toJSON != null) {\n    return JSON.stringify(object);\n  }\n\n  if (Array.isArray(object)) {\n    return '[' + object.reduce((t, cv, ci) => {\n      const comma = ci === 0 ? '' : ',';\n      const value = cv === undefined || typeof cv === 'symbol' ? null : cv;\n      return t + comma + serialize(value);\n    }, '') + ']';\n  }\n\n  return '{' + Object.keys(object).sort().reduce((t, cv, ci) => {\n    if (object[cv] === undefined ||\n        typeof object[cv] === 'symbol') {\n      return t;\n    }\n    const comma = t.length === 0 ? '' : ',';\n    return t + comma + serialize(cv) + ':' + serialize(object[cv]);\n  }, '') + '}';\n};\n","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.EntryHandlerKeywordIncluded = void 0;\nconst jsonld_context_parser_1 = require(\"jsonld-context-parser\");\nconst EntryHandlerKeyword_1 = require(\"./EntryHandlerKeyword\");\n/**\n * Handles @included entries.\n */\nclass EntryHandlerKeywordIncluded extends EntryHandlerKeyword_1.EntryHandlerKeyword {\n    constructor() {\n        super('@included');\n    }\n    async handle(parsingContext, util, key, keys, value, depth) {\n        if (typeof value !== 'object') {\n            parsingContext.emitError(new jsonld_context_parser_1.ErrorCoded(`Found illegal @included '${value}'`, jsonld_context_parser_1.ERROR_CODES.INVALID_INCLUDED_VALUE));\n        }\n        const valueUnliased = await util.unaliasKeywords(value, keys, depth, await parsingContext.getContext(keys));\n        if ('@value' in valueUnliased) {\n            parsingContext.emitError(new jsonld_context_parser_1.ErrorCoded(`Found an illegal @included @value node '${JSON.stringify(value)}'`, jsonld_context_parser_1.ERROR_CODES.INVALID_INCLUDED_VALUE));\n        }\n        if ('@list' in valueUnliased) {\n            parsingContext.emitError(new jsonld_context_parser_1.ErrorCoded(`Found an illegal @included @list node '${JSON.stringify(value)}'`, jsonld_context_parser_1.ERROR_CODES.INVALID_INCLUDED_VALUE));\n        }\n        parsingContext.emittedStack[depth] = false;\n    }\n}\nexports.EntryHandlerKeywordIncluded = EntryHandlerKeywordIncluded;\n//# sourceMappingURL=EntryHandlerKeywordIncluded.js.map","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.EntryHandlerKeyword = void 0;\n/**\n * An abstract keyword entry handler.\n */\nclass EntryHandlerKeyword {\n    constructor(keyword) {\n        this.keyword = keyword;\n    }\n    isPropertyHandler() {\n        return false;\n    }\n    isStackProcessor() {\n        return true;\n    }\n    async validate(parsingContext, util, keys, depth, inProperty) {\n        return false;\n    }\n    async test(parsingContext, util, key, keys, depth) {\n        return key === this.keyword;\n    }\n}\nexports.EntryHandlerKeyword = EntryHandlerKeyword;\n//# sourceMappingURL=EntryHandlerKeyword.js.map","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.JsonLdParser = void 0;\n// tslint:disable-next-line:no-var-requires\nconst Parser = require('@bergos/jsonparse');\nconst jsonld_context_parser_1 = require(\"jsonld-context-parser\");\nconst readable_stream_1 = require(\"readable-stream\");\nconst EntryHandlerArrayValue_1 = require(\"./entryhandler/EntryHandlerArrayValue\");\nconst EntryHandlerContainer_1 = require(\"./entryhandler/EntryHandlerContainer\");\nconst EntryHandlerInvalidFallback_1 = require(\"./entryhandler/EntryHandlerInvalidFallback\");\nconst EntryHandlerPredicate_1 = require(\"./entryhandler/EntryHandlerPredicate\");\nconst EntryHandlerKeywordContext_1 = require(\"./entryhandler/keyword/EntryHandlerKeywordContext\");\nconst EntryHandlerKeywordGraph_1 = require(\"./entryhandler/keyword/EntryHandlerKeywordGraph\");\nconst EntryHandlerKeywordId_1 = require(\"./entryhandler/keyword/EntryHandlerKeywordId\");\nconst EntryHandlerKeywordIncluded_1 = require(\"./entryhandler/keyword/EntryHandlerKeywordIncluded\");\nconst EntryHandlerKeywordNest_1 = require(\"./entryhandler/keyword/EntryHandlerKeywordNest\");\nconst EntryHandlerKeywordType_1 = require(\"./entryhandler/keyword/EntryHandlerKeywordType\");\nconst EntryHandlerKeywordUnknownFallback_1 = require(\"./entryhandler/keyword/EntryHandlerKeywordUnknownFallback\");\nconst EntryHandlerKeywordValue_1 = require(\"./entryhandler/keyword/EntryHandlerKeywordValue\");\nconst ParsingContext_1 = require(\"./ParsingContext\");\nconst Util_1 = require(\"./Util\");\nconst http_link_header_1 = require(\"http-link-header\");\nconst EntryHandlerKeywordAnnotation_1 = require(\"./entryhandler/keyword/EntryHandlerKeywordAnnotation\");\n/**\n * A stream transformer that parses JSON-LD (text) streams to an {@link RDF.Stream}.\n */\nclass JsonLdParser extends readable_stream_1.Transform {\n    constructor(options) {\n        super({ readableObjectMode: true });\n        options = options || {};\n        this.options = options;\n        this.parsingContext = new ParsingContext_1.ParsingContext(Object.assign({ parser: this }, options));\n        this.util = new Util_1.Util({ dataFactory: options.dataFactory, parsingContext: this.parsingContext });\n        this.jsonParser = new Parser();\n        this.contextJobs = [];\n        this.typeJobs = [];\n        this.contextAwaitingJobs = [];\n        this.lastDepth = 0;\n        this.lastKeys = [];\n        this.lastOnValueJob = Promise.resolve();\n        this.attachJsonParserListeners();\n        this.on('end', () => {\n            if (typeof this.jsonParser.mode !== 'undefined') {\n                this.emit('error', new Error('Unclosed document'));\n            }\n        });\n    }\n    /**\n     * Construct a JsonLdParser from the given HTTP response.\n     *\n     * This will throw an error if no valid JSON response is received\n     * (application/ld+json, application/json, or something+json).\n     *\n     * For raw JSON responses, exactly one link header pointing to a JSON-LD context is required.\n     *\n     * This method is not responsible for handling redirects.\n     *\n     * @param baseIRI The URI of the received response.\n     * @param mediaType The received content type.\n     * @param headers Optional HTTP headers.\n     * @param options Optional parser options.\n     */\n    static fromHttpResponse(baseIRI, mediaType, headers, options) {\n        let context;\n        let wellKnownMediaTypes = ['application/activity+json'];\n        if (options && options.wellKnownMediaTypes) {\n            wellKnownMediaTypes = options.wellKnownMediaTypes;\n        }\n        // Special cases when receiving something else than the JSON-LD media type or the wellKnownMediaTypes\n        if (mediaType !== 'application/ld+json' && !wellKnownMediaTypes.includes(mediaType)) {\n            // Only accept JSON or JSON extension types\n            if (mediaType !== 'application/json' && !mediaType.endsWith('+json')) {\n                throw new jsonld_context_parser_1.ErrorCoded(`Unsupported JSON-LD media type ${mediaType}`, jsonld_context_parser_1.ERROR_CODES.LOADING_DOCUMENT_FAILED);\n            }\n            // We need exactly one JSON-LD context in the link header\n            if (headers && headers.has('Link')) {\n                headers.forEach((value, key) => {\n                    if (key === 'link') {\n                        const linkHeader = (0, http_link_header_1.parse)(value);\n                        for (const link of linkHeader.get('rel', 'http://www.w3.org/ns/json-ld#context')) {\n                            if (context) {\n                                throw new jsonld_context_parser_1.ErrorCoded('Multiple JSON-LD context link headers were found on ' + baseIRI, jsonld_context_parser_1.ERROR_CODES.MULTIPLE_CONTEXT_LINK_HEADERS);\n                            }\n                            context = link.uri;\n                        }\n                    }\n                });\n            }\n            if (!context && !(options === null || options === void 0 ? void 0 : options.ignoreMissingContextLinkHeader)) {\n                throw new jsonld_context_parser_1.ErrorCoded(`Missing context link header for media type ${mediaType} on ${baseIRI}`, jsonld_context_parser_1.ERROR_CODES.LOADING_DOCUMENT_FAILED);\n            }\n        }\n        // Check if the streaming profile is present\n        let streamingProfile;\n        if (headers && headers.has('Content-Type')) {\n            const contentType = headers.get('Content-Type');\n            const match = /; *profile=([^\"]*)/.exec(contentType);\n            if (match && match[1] === 'http://www.w3.org/ns/json-ld#streaming') {\n                streamingProfile = true;\n            }\n        }\n        return new JsonLdParser(Object.assign({ baseIRI,\n            context,\n            streamingProfile }, options ? options : {}));\n    }\n    /**\n     * Parses the given text stream into a quad stream.\n     * @param {NodeJS.EventEmitter} stream A text stream.\n     * @return {RDF.Stream} A quad stream.\n     */\n    import(stream) {\n        if ('pipe' in stream) {\n            stream.on('error', (error) => parsed.emit('error', error));\n            const parsed = stream.pipe(new JsonLdParser(this.options));\n            return parsed;\n        }\n        else {\n            const output = new readable_stream_1.PassThrough({ readableObjectMode: true });\n            stream.on('error', (error) => parsed.emit('error', error));\n            stream.on('data', (data) => output.push(data));\n            stream.on('end', () => output.push(null));\n            const parsed = output.pipe(new JsonLdParser(this.options));\n            return parsed;\n        }\n    }\n    _transform(chunk, encoding, callback) {\n        this.jsonParser.write(chunk);\n        this.lastOnValueJob\n            .then(() => callback(), (error) => callback(error));\n    }\n    /**\n     * Start a new job for parsing the given value.\n     *\n     * This will let the first valid {@link IEntryHandler} handle the entry.\n     *\n     * @param {any[]} keys The stack of keys.\n     * @param value The value to parse.\n     * @param {number} depth The depth to parse at.\n     * @param {boolean} lastDepthCheck If the lastDepth check should be done for buffer draining.\n     * @return {Promise<void>} A promise resolving when the job is done.\n     */\n    async newOnValueJob(keys, value, depth, lastDepthCheck) {\n        let flushStacks = true;\n        // When we go up the stack, emit all unidentified values\n        // We need to do this before the new job, because the new job may require determined values from the flushed jobs.\n        if (lastDepthCheck && depth < this.lastDepth) {\n            // Check if we had any RDF lists that need to be terminated with an rdf:nil\n            const listPointer = this.parsingContext.listPointerStack[this.lastDepth];\n            if (listPointer) {\n                // Terminate the list if the had at least one value\n                if (listPointer.value) {\n                    this.push(this.util.dataFactory.quad(listPointer.value, this.util.rdfRest, this.util.rdfNil, this.util.getDefaultGraph()));\n                }\n                // Add the list id to the id stack, so it can be used higher up in the stack\n                listPointer.listId.listHead = true;\n                this.parsingContext.idStack[listPointer.listRootDepth + 1] = [listPointer.listId];\n                this.parsingContext.listPointerStack.splice(this.lastDepth, 1);\n            }\n            // Flush the buffer for lastDepth\n            // If the parent key is a special type of container, postpone flushing until that parent is handled.\n            if (await EntryHandlerContainer_1.EntryHandlerContainer.isBufferableContainerHandler(this.parsingContext, this.lastKeys, this.lastDepth)) {\n                this.parsingContext.pendingContainerFlushBuffers\n                    .push({ depth: this.lastDepth, keys: this.lastKeys.slice(0, this.lastKeys.length) });\n                flushStacks = false;\n            }\n            else {\n                await this.flushBuffer(this.lastDepth, this.lastKeys);\n            }\n        }\n        const key = await this.util.unaliasKeyword(keys[depth], keys, depth);\n        const parentKey = await this.util.unaliasKeywordParent(keys, depth);\n        this.parsingContext.emittedStack[depth] = true;\n        let handleKey = true;\n        // Keywords inside @reverse is not allowed apart from @context\n        if (jsonld_context_parser_1.Util.isValidKeyword(key) && parentKey === '@reverse' && key !== '@context') {\n            this.emit('error', new jsonld_context_parser_1.ErrorCoded(`Found the @id '${value}' inside an @reverse property`, jsonld_context_parser_1.ERROR_CODES.INVALID_REVERSE_PROPERTY_MAP));\n        }\n        // Skip further processing if one of the parent nodes are invalid.\n        // We use the validationStack to reuse validation results that were produced before with common key stacks.\n        let inProperty = false;\n        if (this.parsingContext.validationStack.length > 1) {\n            inProperty = this.parsingContext.validationStack[this.parsingContext.validationStack.length - 1].property;\n        }\n        for (let i = Math.max(1, this.parsingContext.validationStack.length - 1); i < keys.length - 1; i++) {\n            const validationResult = this.parsingContext.validationStack[i]\n                || (this.parsingContext.validationStack[i] = await this.validateKey(keys.slice(0, i + 1), i, inProperty));\n            if (!validationResult.valid) {\n                this.parsingContext.emittedStack[depth] = false;\n                handleKey = false;\n                break;\n            }\n            else if (!inProperty && validationResult.property) {\n                inProperty = true;\n            }\n        }\n        // Skip further processing if this node is part of a literal\n        if (await this.util.isLiteral(keys, depth)) {\n            handleKey = false;\n        }\n        // Get handler\n        if (handleKey) {\n            for (const entryHandler of JsonLdParser.ENTRY_HANDLERS) {\n                const testResult = await entryHandler.test(this.parsingContext, this.util, key, keys, depth);\n                if (testResult) {\n                    // Pass processing over to the handler\n                    await entryHandler.handle(this.parsingContext, this.util, key, keys, value, depth, testResult);\n                    // Flag that this depth is processed\n                    if (entryHandler.isStackProcessor()) {\n                        this.parsingContext.processingStack[depth] = true;\n                    }\n                    break;\n                }\n            }\n        }\n        // Validate value indexes on the root.\n        if (depth === 0 && Array.isArray(value)) {\n            await this.util.validateValueIndexes(value);\n        }\n        // When we go up the stack, flush the old stack\n        if (flushStacks && depth < this.lastDepth) {\n            // Reset our stacks\n            this.flushStacks(this.lastDepth);\n        }\n        this.lastDepth = depth;\n        this.lastKeys = keys;\n        // Clear the keyword cache at this depth, and everything underneath.\n        this.parsingContext.unaliasedKeywordCacheStack.splice(depth - 1);\n    }\n    /**\n     * Flush the processing stacks at the given depth.\n     * @param {number} depth A depth.\n     */\n    flushStacks(depth) {\n        this.parsingContext.processingStack.splice(depth, 1);\n        this.parsingContext.processingType.splice(depth, 1);\n        this.parsingContext.emittedStack.splice(depth, 1);\n        this.parsingContext.idStack.splice(depth, 1);\n        this.parsingContext.graphStack.splice(depth + 1, 1);\n        this.parsingContext.graphContainerTermStack.splice(depth, 1);\n        this.parsingContext.jsonLiteralStack.splice(depth, 1);\n        this.parsingContext.validationStack.splice(depth - 1, 2);\n        this.parsingContext.literalStack.splice(depth, this.parsingContext.literalStack.length - depth);\n        this.parsingContext.annotationsBuffer.splice(depth, 1);\n        // TODO: just like the literal stack, splice all other stack until the end as well?\n    }\n    /**\n     * Flush buffers for the given depth.\n     *\n     * This should be called after the last entry at a given depth was processed.\n     *\n     * @param {number} depth A depth.\n     * @param {any[]} keys A stack of keys.\n     * @return {Promise<void>} A promise resolving if flushing is done.\n     */\n    async flushBuffer(depth, keys) {\n        let subjects = this.parsingContext.idStack[depth];\n        const subjectsWasDefined = !!subjects;\n        if (!subjectsWasDefined) {\n            subjects = this.parsingContext.idStack[depth] = [this.util.dataFactory.blankNode()];\n        }\n        // Flush values at this level\n        const valueBuffer = this.parsingContext.unidentifiedValuesBuffer[depth];\n        if (valueBuffer) {\n            for (const subject of subjects) {\n                const depthOffsetGraph = await this.util.getDepthOffsetGraph(depth, keys);\n                const graphs = (this.parsingContext.graphStack[depth] || depthOffsetGraph >= 0)\n                    ? this.parsingContext.idStack[depth - depthOffsetGraph - 1]\n                    : [await this.util.getGraphContainerValue(keys, depth)];\n                if (graphs) {\n                    for (const graph of graphs) {\n                        // Flush values to stream if the graph @id is known\n                        this.parsingContext.emittedStack[depth] = true;\n                        for (const bufferedValue of valueBuffer) {\n                            this.util.emitQuadChecked(depth, subject, bufferedValue.predicate, bufferedValue.object, graph, bufferedValue.reverse, bufferedValue.isEmbedded);\n                        }\n                    }\n                }\n                else {\n                    // Place the values in the graphs buffer if the graph @id is not yet known\n                    const subGraphBuffer = this.parsingContext.getUnidentifiedGraphBufferSafe(depth - await this.util.getDepthOffsetGraph(depth, keys) - 1);\n                    for (const bufferedValue of valueBuffer) {\n                        if (bufferedValue.reverse) {\n                            subGraphBuffer.push({\n                                object: subject,\n                                predicate: bufferedValue.predicate,\n                                subject: bufferedValue.object,\n                                isEmbedded: bufferedValue.isEmbedded,\n                            });\n                        }\n                        else {\n                            subGraphBuffer.push({\n                                object: bufferedValue.object,\n                                predicate: bufferedValue.predicate,\n                                subject,\n                                isEmbedded: bufferedValue.isEmbedded,\n                            });\n                        }\n                    }\n                }\n            }\n            this.parsingContext.unidentifiedValuesBuffer.splice(depth, 1);\n            this.parsingContext.literalStack.splice(depth, 1);\n            this.parsingContext.jsonLiteralStack.splice(depth, 1);\n        }\n        // Flush graphs at this level\n        const graphBuffer = this.parsingContext.unidentifiedGraphsBuffer[depth];\n        if (graphBuffer) {\n            for (const subject of subjects) {\n                // A @graph statement at the root without @id relates to the default graph,\n                // unless there are top-level properties,\n                // others relate to blank nodes.\n                const graph = depth === 1 && subject.termType === 'BlankNode'\n                    && !this.parsingContext.topLevelProperties ? this.util.getDefaultGraph() : subject;\n                this.parsingContext.emittedStack[depth] = true;\n                for (const bufferedValue of graphBuffer) {\n                    this.parsingContext.emitQuad(depth, this.util.dataFactory.quad(bufferedValue.subject, bufferedValue.predicate, bufferedValue.object, graph));\n                }\n            }\n            this.parsingContext.unidentifiedGraphsBuffer.splice(depth, 1);\n        }\n        // Push unhandled annotations up the stack as nested annotations\n        const annotationsBuffer = this.parsingContext.annotationsBuffer[depth];\n        if (annotationsBuffer) {\n            // Throw an error if we reach the top, and still have annotations\n            if (annotationsBuffer.length > 0 && depth === 1) {\n                this.parsingContext.emitError(new jsonld_context_parser_1.ErrorCoded(`Annotations can not be made on top-level nodes`, jsonld_context_parser_1.ERROR_CODES.INVALID_ANNOTATION));\n            }\n            // Pass the annotations buffer up one level in the stack\n            const annotationsBufferParent = this.parsingContext.getAnnotationsBufferSafe(depth - 1);\n            for (const annotation of annotationsBuffer) {\n                annotationsBufferParent.push(annotation);\n            }\n            delete this.parsingContext.annotationsBuffer[depth];\n        }\n    }\n    /**\n     * Check if at least one {@link IEntryHandler} validates the entry to true.\n     * @param {any[]} keys A stack of keys.\n     * @param {number} depth A depth.\n     * @param {boolean} inProperty If the current depth is part of a valid property node.\n     * @return {Promise<{ valid: boolean, property: boolean }>} A promise resolving to true or false.\n     */\n    async validateKey(keys, depth, inProperty) {\n        for (const entryHandler of JsonLdParser.ENTRY_HANDLERS) {\n            if (await entryHandler.validate(this.parsingContext, this.util, keys, depth, inProperty)) {\n                return { valid: true, property: inProperty || entryHandler.isPropertyHandler() };\n            }\n        }\n        return { valid: false, property: false };\n    }\n    /**\n     * Attach all required listeners to the JSON parser.\n     *\n     * This should only be called once.\n     */\n    attachJsonParserListeners() {\n        // Listen to json parser events\n        this.jsonParser.onValue = (value) => {\n            const depth = this.jsonParser.stack.length;\n            const keys = (new Array(depth + 1).fill(0)).map((v, i) => {\n                return i === depth ? this.jsonParser.key : this.jsonParser.stack[i].key;\n            });\n            if (!this.isParsingContextInner(depth)) { // Don't parse inner nodes inside @context\n                const valueJobCb = () => this.newOnValueJob(keys, value, depth, true);\n                if (!this.parsingContext.streamingProfile\n                    && !this.parsingContext.contextTree.getContext(keys.slice(0, -1))) {\n                    // If an out-of-order context is allowed,\n                    // we have to buffer everything.\n                    // We store jobs for @context's and @type's separately,\n                    // because at the end, we have to process them first.\n                    // We also handle @type because these *could* introduce a type-scoped context.\n                    if (keys[depth] === '@context') {\n                        let jobs = this.contextJobs[depth];\n                        if (!jobs) {\n                            jobs = this.contextJobs[depth] = [];\n                        }\n                        jobs.push(valueJobCb);\n                    }\n                    else {\n                        this.contextAwaitingJobs.push({ job: valueJobCb, keys, depth });\n                    }\n                }\n                else {\n                    // Make sure that our value jobs are chained synchronously\n                    this.lastOnValueJob = this.lastOnValueJob.then(valueJobCb);\n                }\n                // Execute all buffered jobs on deeper levels\n                if (!this.parsingContext.streamingProfile && depth === 0) {\n                    this.lastOnValueJob = this.lastOnValueJob\n                        .then(() => this.executeBufferedJobs());\n                }\n            }\n        };\n        this.jsonParser.onError = (error) => {\n            this.emit('error', error);\n        };\n    }\n    /**\n     * Check if the parser is currently parsing an element that is part of an @context entry.\n     * @param {number} depth A depth.\n     * @return {boolean} A boolean.\n     */\n    isParsingContextInner(depth) {\n        for (let i = depth; i > 0; i--) {\n            if (this.jsonParser.stack[i - 1].key === '@context') {\n                return true;\n            }\n        }\n        return false;\n    }\n    /**\n     * Execute all buffered jobs.\n     * @return {Promise<void>} A promise resolving if all jobs are finished.\n     */\n    async executeBufferedJobs() {\n        // Handle context jobs\n        for (const jobs of this.contextJobs) {\n            if (jobs) {\n                for (const job of jobs) {\n                    await job();\n                }\n            }\n        }\n        // Clear the keyword cache.\n        this.parsingContext.unaliasedKeywordCacheStack.splice(0);\n        const contextAwaitingJobs = [];\n        for (const job of this.contextAwaitingJobs) {\n            if ((await this.util.unaliasKeyword(job.keys[job.depth], job.keys, job.depth, true)) === '@type'\n                || typeof job.keys[job.depth] === 'number' && (await this.util.unaliasKeyword(job.keys[job.depth - 1], job.keys, job.depth - 1, true)) === '@type') { // Also capture @type with array values\n                // Remove @type from keys, because we want it to apply to parent later on\n                this.typeJobs.push({ job: job.job, keys: job.keys.slice(0, job.keys.length - 1) });\n            }\n            else {\n                contextAwaitingJobs.push(job);\n            }\n        }\n        // Handle non-context jobs\n        for (const job of contextAwaitingJobs) {\n            // Check if we have a type (with possible type-scoped context) that should be handled before.\n            // We check all possible parent nodes for the current job, from root to leaves.\n            if (this.typeJobs.length > 0) {\n                // First collect all applicable type jobs\n                const applicableTypeJobs = [];\n                const applicableTypeJobIds = [];\n                for (let i = 0; i < this.typeJobs.length; i++) {\n                    const typeJob = this.typeJobs[i];\n                    if (Util_1.Util.isPrefixArray(typeJob.keys, job.keys)) {\n                        applicableTypeJobs.push(typeJob);\n                        applicableTypeJobIds.push(i);\n                    }\n                }\n                // Next, sort the jobs from short to long key length (to ensure types higher up in the tree to be handled first)\n                const sortedTypeJobs = applicableTypeJobs.sort((job1, job2) => job1.keys.length - job2.keys.length);\n                // Finally, execute the jobs in order\n                for (const typeJob of sortedTypeJobs) {\n                    await typeJob.job();\n                }\n                // Remove the executed type jobs\n                // Sort first, so we can efficiently splice\n                const sortedApplicableTypeJobIds = applicableTypeJobIds.sort().reverse();\n                for (const jobId of sortedApplicableTypeJobIds) {\n                    this.typeJobs.splice(jobId, 1);\n                }\n            }\n            await job.job();\n        }\n    }\n}\nexports.JsonLdParser = JsonLdParser;\nJsonLdParser.DEFAULT_PROCESSING_MODE = '1.1';\nJsonLdParser.ENTRY_HANDLERS = [\n    new EntryHandlerArrayValue_1.EntryHandlerArrayValue(),\n    new EntryHandlerKeywordContext_1.EntryHandlerKeywordContext(),\n    new EntryHandlerKeywordId_1.EntryHandlerKeywordId(),\n    new EntryHandlerKeywordIncluded_1.EntryHandlerKeywordIncluded(),\n    new EntryHandlerKeywordGraph_1.EntryHandlerKeywordGraph(),\n    new EntryHandlerKeywordNest_1.EntryHandlerKeywordNest(),\n    new EntryHandlerKeywordType_1.EntryHandlerKeywordType(),\n    new EntryHandlerKeywordValue_1.EntryHandlerKeywordValue(),\n    new EntryHandlerKeywordAnnotation_1.EntryHandlerKeywordAnnotation(),\n    new EntryHandlerContainer_1.EntryHandlerContainer(),\n    new EntryHandlerKeywordUnknownFallback_1.EntryHandlerKeywordUnknownFallback(),\n    new EntryHandlerPredicate_1.EntryHandlerPredicate(),\n    new EntryHandlerInvalidFallback_1.EntryHandlerInvalidFallback(),\n];\n//# sourceMappingURL=JsonLdParser.js.map","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.Util = void 0;\nclass Util {\n    /**\n     * Check if the given term is a valid compact IRI.\n     * Otherwise, it may be an IRI.\n     * @param {string} term A term.\n     * @return {boolean} If it is a compact IRI.\n     */\n    static isCompactIri(term) {\n        return term.indexOf(':') > 0 && !(term && term[0] === '#');\n    }\n    /**\n     * Get the prefix from the given term.\n     * @see https://json-ld.org/spec/latest/json-ld/#compact-iris\n     * @param {string} term A term that is an URL or a prefixed URL.\n     * @param {IJsonLdContextNormalizedRaw} context A context.\n     * @return {string} The prefix or null.\n     */\n    static getPrefix(term, context) {\n        // Do not consider relative IRIs starting with a hash as compact IRIs\n        if (term && term[0] === '#') {\n            return null;\n        }\n        const separatorPos = term.indexOf(':');\n        if (separatorPos >= 0) {\n            // Suffix can not begin with two slashes\n            if (term.length > separatorPos + 1\n                && term.charAt(separatorPos + 1) === '/'\n                && term.charAt(separatorPos + 2) === '/') {\n                return null;\n            }\n            const prefix = term.substr(0, separatorPos);\n            // Prefix can not be an underscore (this is a blank node)\n            if (prefix === '_') {\n                return null;\n            }\n            // Prefix must match a term in the active context\n            if (context[prefix]) {\n                return prefix;\n            }\n        }\n        return null;\n    }\n    /**\n     * From a given context entry value, get the string value, or the @id field.\n     * @param contextValue A value for a term in a context.\n     * @return {string} The id value, or null.\n     */\n    static getContextValueId(contextValue) {\n        if (contextValue === null || typeof contextValue === 'string') {\n            return contextValue;\n        }\n        const id = contextValue['@id'];\n        return id ? id : null;\n    }\n    /**\n     * Check if the given simple term definition (string-based value of a context term)\n     * should be considered a prefix.\n     * @param value A simple term definition value.\n     * @param options Options that define the way how expansion must be done.\n     */\n    static isSimpleTermDefinitionPrefix(value, options) {\n        return !Util.isPotentialKeyword(value)\n            && (options.allowPrefixNonGenDelims || (typeof value === 'string' && (value[0] === '_' || Util.isPrefixIriEndingWithGenDelim(value))));\n    }\n    /**\n     * Check if the given keyword is of the keyword format \"@\"1*ALPHA.\n     * @param {string} keyword A potential keyword.\n     * @return {boolean} If the given keyword is of the keyword format.\n     */\n    static isPotentialKeyword(keyword) {\n        return typeof keyword === 'string' && Util.KEYWORD_REGEX.test(keyword);\n    }\n    /**\n     * Check if the given prefix ends with a gen-delim character.\n     * @param {string} prefixIri A prefix IRI.\n     * @return {boolean} If the given prefix IRI is valid.\n     */\n    static isPrefixIriEndingWithGenDelim(prefixIri) {\n        return Util.ENDS_WITH_GEN_DELIM.test(prefixIri);\n    }\n    /**\n     * Check if the given context value can be a prefix value.\n     * @param value A context value.\n     * @return {boolean} If it can be a prefix value.\n     */\n    static isPrefixValue(value) {\n        return value && (typeof value === 'string' || (value && typeof value === 'object'));\n    }\n    /**\n     * Check if the given IRI is valid.\n     * @param {string} iri A potential IRI.\n     * @return {boolean} If the given IRI is valid.\n     */\n    static isValidIri(iri) {\n        return Boolean(iri && Util.IRI_REGEX.test(iri));\n    }\n    /**\n     * Check if the given IRI is valid, this includes the possibility of being a relative IRI.\n     * @param {string} iri A potential IRI.\n     * @return {boolean} If the given IRI is valid.\n     */\n    static isValidIriWeak(iri) {\n        return !!iri && iri[0] !== ':' && Util.IRI_REGEX_WEAK.test(iri);\n    }\n    /**\n     * Check if the given keyword is a defined according to the JSON-LD specification.\n     * @param {string} keyword A potential keyword.\n     * @return {boolean} If the given keyword is valid.\n     */\n    static isValidKeyword(keyword) {\n        return Util.VALID_KEYWORDS[keyword];\n    }\n    /**\n     * Check if the given term is protected in the context.\n     * @param {IJsonLdContextNormalizedRaw} context A context.\n     * @param {string} key A context term.\n     * @return {boolean} If the given term has an @protected flag.\n     */\n    static isTermProtected(context, key) {\n        const value = context[key];\n        return !(typeof value === 'string') && value && value['@protected'];\n    }\n    /**\n     * Check if the given context has at least one protected term.\n     * @param context A context.\n     * @return If the context has a protected term.\n     */\n    static hasProtectedTerms(context) {\n        for (const key of Object.keys(context)) {\n            if (Util.isTermProtected(context, key)) {\n                return true;\n            }\n        }\n        return false;\n    }\n    /**\n     * Check if the given key is an internal reserved keyword.\n     * @param key A context key.\n     */\n    static isReservedInternalKeyword(key) {\n        return key.startsWith('@__');\n    }\n    /**\n     * Check if two objects are deepEqual to on another.\n     * @param object1 The first object to test.\n     * @param object2 The second object to test.\n     */\n    static deepEqual(object1, object2) {\n        const objKeys1 = Object.keys(object1);\n        const objKeys2 = Object.keys(object2);\n        if (objKeys1.length !== objKeys2.length)\n            return false;\n        return objKeys1.every((key) => {\n            const value1 = object1[key];\n            const value2 = object2[key];\n            return (value1 === value2) || (value1 !== null &&\n                value2 !== null &&\n                typeof value1 === \"object\" &&\n                typeof value2 === \"object\" &&\n                this.deepEqual(value1, value2));\n        });\n    }\n    ;\n}\n// Regex for valid IRIs\nUtil.IRI_REGEX = /^([A-Za-z][A-Za-z0-9+-.]*|_):[^ \"<>{}|\\\\\\[\\]`#]*(#[^#]*)?$/;\n// Weaker regex for valid IRIs, this includes relative IRIs\nUtil.IRI_REGEX_WEAK = /(?::[^:])|\\//;\n// Regex for keyword form\nUtil.KEYWORD_REGEX = /^@[a-z]+$/i;\n// Regex to see if an IRI ends with a gen-delim character (see RFC 3986)\nUtil.ENDS_WITH_GEN_DELIM = /[:/?#\\[\\]@]$/;\n// Regex for language tags\nUtil.REGEX_LANGUAGE_TAG = /^[a-zA-Z]+(-[a-zA-Z0-9]+)*$/;\n// Regex for base directions\nUtil.REGEX_DIRECTION_TAG = /^(ltr)|(rtl)$/;\n// All known valid JSON-LD keywords\n// @see https://www.w3.org/TR/json-ld11/#keywords\nUtil.VALID_KEYWORDS = {\n    '@annotation': true,\n    '@base': true,\n    '@container': true,\n    '@context': true,\n    '@direction': true,\n    '@graph': true,\n    '@id': true,\n    '@import': true,\n    '@included': true,\n    '@index': true,\n    '@json': true,\n    '@language': true,\n    '@list': true,\n    '@nest': true,\n    '@none': true,\n    '@prefix': true,\n    '@propagate': true,\n    '@protected': true,\n    '@reverse': true,\n    '@set': true,\n    '@type': true,\n    '@value': true,\n    '@version': true,\n    '@vocab': true,\n};\n// Keys in the contexts that will not be expanded based on the base IRI\nUtil.EXPAND_KEYS_BLACKLIST = [\n    '@base',\n    '@vocab',\n    '@language',\n    '@version',\n    '@direction',\n];\n// Keys in the contexts that may not be aliased from\nUtil.ALIAS_DOMAIN_BLACKLIST = [\n    '@container',\n    '@graph',\n    '@id',\n    '@index',\n    '@list',\n    '@nest',\n    '@none',\n    '@prefix',\n    '@reverse',\n    '@set',\n    '@type',\n    '@value',\n    '@version',\n];\n// Keys in the contexts that may not be aliased to\nUtil.ALIAS_RANGE_BLACKLIST = [\n    '@context',\n    '@preserve',\n];\n// All valid @container values\nUtil.CONTAINERS = [\n    '@list',\n    '@set',\n    '@index',\n    '@language',\n    '@graph',\n    '@id',\n    '@type',\n];\n// All valid @container values under processing mode 1.0\nUtil.CONTAINERS_1_0 = [\n    '@list',\n    '@set',\n    '@index',\n];\nexports.Util = Util;\n//# sourceMappingURL=Util.js.map","\"use strict\";\nvar __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    var desc = Object.getOwnPropertyDescriptor(m, k);\n    if (!desc || (\"get\" in desc ? !m.__esModule : desc.writable || desc.configurable)) {\n      desc = { enumerable: true, get: function() { return m[k]; } };\n    }\n    Object.defineProperty(o, k2, desc);\n}) : (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    o[k2] = m[k];\n}));\nvar __exportStar = (this && this.__exportStar) || function(m, exports) {\n    for (var p in m) if (p !== \"default\" && !Object.prototype.hasOwnProperty.call(exports, p)) __createBinding(exports, m, p);\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\n__exportStar(require(\"./lib/ContextParser\"), exports);\n__exportStar(require(\"./lib/ErrorCoded\"), exports);\n__exportStar(require(\"./lib/FetchDocumentLoader\"), exports);\n__exportStar(require(\"./lib/IDocumentLoader\"), exports);\n__exportStar(require(\"./lib/JsonLdContext\"), exports);\n__exportStar(require(\"./lib/JsonLdContextNormalized\"), exports);\n__exportStar(require(\"./lib/Util\"), exports);\n//# sourceMappingURL=index.js.map","const blackList = new Set(['_write', '_writableState', 'writable'])\n\nfunction readable (duplex) {\n  return new Proxy(duplex, {\n    has (target, key) {\n      if (blackList.has(key)) {\n        return false\n      }\n\n      return Reflect.has(...arguments)\n    },\n    get (target, key) {\n      if (blackList.has(key)) {\n        return undefined\n      }\n\n      const result = Reflect.get(...arguments)\n\n      if (result && typeof result.bind === 'function') {\n        return result.bind(target)\n      }\n\n      return result\n    },\n    set (target, key, value) {\n      if (blackList.has(key)) {\n        return undefined\n      }\n\n      return Reflect.set(...arguments)\n    }\n  })\n}\n\nexport default readable\n","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\n//# sourceMappingURL=IDocumentLoader.js.map","var { Buffer } = require('buffer')\n// Named constants with unique integer values\nvar C = {};\n// Tokens\nvar LEFT_BRACE    = C.LEFT_BRACE    = 0x1;\nvar RIGHT_BRACE   = C.RIGHT_BRACE   = 0x2;\nvar LEFT_BRACKET  = C.LEFT_BRACKET  = 0x3;\nvar RIGHT_BRACKET = C.RIGHT_BRACKET = 0x4;\nvar COLON         = C.COLON         = 0x5;\nvar COMMA         = C.COMMA         = 0x6;\nvar TRUE          = C.TRUE          = 0x7;\nvar FALSE         = C.FALSE         = 0x8;\nvar NULL          = C.NULL          = 0x9;\nvar STRING        = C.STRING        = 0xa;\nvar NUMBER        = C.NUMBER        = 0xb;\n// Tokenizer States\nvar START   = C.START   = 0x11;\nvar STOP    = C.STOP    = 0x12;\nvar TRUE1   = C.TRUE1   = 0x21;\nvar TRUE2   = C.TRUE2   = 0x22;\nvar TRUE3   = C.TRUE3   = 0x23;\nvar FALSE1  = C.FALSE1  = 0x31;\nvar FALSE2  = C.FALSE2  = 0x32;\nvar FALSE3  = C.FALSE3  = 0x33;\nvar FALSE4  = C.FALSE4  = 0x34;\nvar NULL1   = C.NULL1   = 0x41;\nvar NULL2   = C.NULL2   = 0x42;\nvar NULL3   = C.NULL3   = 0x43;\nvar NUMBER1 = C.NUMBER1 = 0x51;\nvar NUMBER3 = C.NUMBER3 = 0x53;\nvar STRING1 = C.STRING1 = 0x61;\nvar STRING2 = C.STRING2 = 0x62;\nvar STRING3 = C.STRING3 = 0x63;\nvar STRING4 = C.STRING4 = 0x64;\nvar STRING5 = C.STRING5 = 0x65;\nvar STRING6 = C.STRING6 = 0x66;\n// Parser States\nvar VALUE   = C.VALUE   = 0x71;\nvar KEY     = C.KEY     = 0x72;\n// Parser Modes\nvar OBJECT  = C.OBJECT  = 0x81;\nvar ARRAY   = C.ARRAY   = 0x82;\n// Character constants\nvar BACK_SLASH =      \"\\\\\".charCodeAt(0);\nvar FORWARD_SLASH =   \"\\/\".charCodeAt(0);\nvar BACKSPACE =       \"\\b\".charCodeAt(0);\nvar FORM_FEED =       \"\\f\".charCodeAt(0);\nvar NEWLINE =         \"\\n\".charCodeAt(0);\nvar CARRIAGE_RETURN = \"\\r\".charCodeAt(0);\nvar TAB =             \"\\t\".charCodeAt(0);\n\nvar STRING_BUFFER_SIZE = 64 * 1024;\n\nfunction alloc(size) {\n  return Buffer.alloc ? Buffer.alloc(size) : new Buffer(size);\n}\n\nfunction Parser() {\n  this.tState = START;\n  this.value = undefined;\n\n  this.string = undefined; // string data\n  this.stringBuffer = alloc(STRING_BUFFER_SIZE);\n  this.stringBufferOffset = 0;\n  this.unicode = undefined; // unicode escapes\n  this.highSurrogate = undefined;\n\n  this.key = undefined;\n  this.mode = undefined;\n  this.stack = [];\n  this.state = VALUE;\n  this.bytes_remaining = 0; // number of bytes remaining in multi byte utf8 char to read after split boundary\n  this.bytes_in_sequence = 0; // bytes in multi byte utf8 char to read\n  this.temp_buffs = { \"2\": alloc(2), \"3\": alloc(3), \"4\": alloc(4) }; // for rebuilding chars split before boundary is reached\n\n  // Stream offset\n  this.offset = -1;\n}\n\n// Slow code to string converter (only used when throwing syntax errors)\nParser.toknam = function (code) {\n  var keys = Object.keys(C);\n  for (var i = 0, l = keys.length; i < l; i++) {\n    var key = keys[i];\n    if (C[key] === code) { return key; }\n  }\n  return code && (\"0x\" + code.toString(16));\n};\n\nvar proto = Parser.prototype;\nproto.onError = function (err) { throw err; };\nproto.charError = function (buffer, i) {\n  this.tState = STOP;\n  this.onError(new Error(\"Unexpected \" + JSON.stringify(String.fromCharCode(buffer[i])) + \" at position \" + i + \" in state \" + Parser.toknam(this.tState)));\n};\nproto.appendStringChar = function (char) {\n  if (this.stringBufferOffset >= STRING_BUFFER_SIZE) {\n    this.string += this.stringBuffer.toString('utf8');\n    this.stringBufferOffset = 0;\n  }\n\n  this.stringBuffer[this.stringBufferOffset++] = char;\n};\nproto.appendStringBuf = function (buf, start, end) {\n  var size = buf.length;\n  if (typeof start === 'number') {\n    if (typeof end === 'number') {\n      if (end < 0) {\n        // adding a negative end decreeses the size\n        size = buf.length - start + end;\n      } else {\n        size = end - start;\n      }\n    } else {\n      size = buf.length - start;\n    }\n  }\n\n  if (size < 0) {\n    size = 0;\n  }\n\n  if (this.stringBufferOffset + size > STRING_BUFFER_SIZE) {\n    this.string += this.stringBuffer.toString('utf8', 0, this.stringBufferOffset);\n    this.stringBufferOffset = 0;\n  }\n\n  buf.copy(this.stringBuffer, this.stringBufferOffset, start, end);\n  this.stringBufferOffset += size;\n};\nproto.write = function (buffer) {\n  if (typeof buffer === \"string\") buffer = new Buffer(buffer);\n  var n;\n  for (var i = 0, l = buffer.length; i < l; i++) {\n    if (this.tState === START){\n      n = buffer[i];\n      this.offset++;\n      if(n === 0x7b){ this.onToken(LEFT_BRACE, \"{\"); // {\n      }else if(n === 0x7d){ this.onToken(RIGHT_BRACE, \"}\"); // }\n      }else if(n === 0x5b){ this.onToken(LEFT_BRACKET, \"[\"); // [\n      }else if(n === 0x5d){ this.onToken(RIGHT_BRACKET, \"]\"); // ]\n      }else if(n === 0x3a){ this.onToken(COLON, \":\");  // :\n      }else if(n === 0x2c){ this.onToken(COMMA, \",\"); // ,\n      }else if(n === 0x74){ this.tState = TRUE1;  // t\n      }else if(n === 0x66){ this.tState = FALSE1;  // f\n      }else if(n === 0x6e){ this.tState = NULL1; // n\n      }else if(n === 0x22){ // \"\n        this.string = \"\";\n        this.stringBufferOffset = 0;\n        this.tState = STRING1;\n      }else if(n === 0x2d){ this.string = \"-\"; this.tState = NUMBER1; // -\n      }else{\n        if (n >= 0x30 && n < 0x40) { // 1-9\n          this.string = String.fromCharCode(n); this.tState = NUMBER3;\n        } else if (n === 0x20 || n === 0x09 || n === 0x0a || n === 0x0d) {\n          // whitespace\n        } else {\n          return this.charError(buffer, i);\n        }\n      }\n    }else if (this.tState === STRING1){ // After open quote\n      n = buffer[i]; // get current byte from buffer\n      // check for carry over of a multi byte char split between data chunks\n      // & fill temp buffer it with start of this data chunk up to the boundary limit set in the last iteration\n      if (this.bytes_remaining > 0) {\n        for (var j = 0; j < this.bytes_remaining; j++) {\n          this.temp_buffs[this.bytes_in_sequence][this.bytes_in_sequence - this.bytes_remaining + j] = buffer[j];\n        }\n\n        this.appendStringBuf(this.temp_buffs[this.bytes_in_sequence]);\n        this.bytes_in_sequence = this.bytes_remaining = 0;\n        i = i + j - 1;\n      } else if (this.bytes_remaining === 0 && n >= 128) { // else if no remainder bytes carried over, parse multi byte (>=128) chars one at a time\n        if (n <= 193 || n > 244) {\n          return this.onError(new Error(\"Invalid UTF-8 character at position \" + i + \" in state \" + Parser.toknam(this.tState)));\n        }\n        if ((n >= 194) && (n <= 223)) this.bytes_in_sequence = 2;\n        if ((n >= 224) && (n <= 239)) this.bytes_in_sequence = 3;\n        if ((n >= 240) && (n <= 244)) this.bytes_in_sequence = 4;\n        if ((this.bytes_in_sequence + i) > buffer.length) { // if bytes needed to complete char fall outside buffer length, we have a boundary split\n          for (var k = 0; k <= (buffer.length - 1 - i); k++) {\n            this.temp_buffs[this.bytes_in_sequence][k] = buffer[i + k]; // fill temp buffer of correct size with bytes available in this chunk\n          }\n          this.bytes_remaining = (i + this.bytes_in_sequence) - buffer.length;\n          i = buffer.length - 1;\n        } else {\n          this.appendStringBuf(buffer, i, i + this.bytes_in_sequence);\n          i = i + this.bytes_in_sequence - 1;\n        }\n      } else if (n === 0x22) {\n        this.tState = START;\n        this.string += this.stringBuffer.toString('utf8', 0, this.stringBufferOffset);\n        this.stringBufferOffset = 0;\n        this.onToken(STRING, this.string);\n        this.offset += Buffer.byteLength(this.string, 'utf8') + 1;\n        this.string = undefined;\n      }\n      else if (n === 0x5c) {\n        this.tState = STRING2;\n      }\n      else if (n >= 0x20) { this.appendStringChar(n); }\n      else {\n          return this.charError(buffer, i);\n      }\n    }else if (this.tState === STRING2){ // After backslash\n      n = buffer[i];\n      if(n === 0x22){ this.appendStringChar(n); this.tState = STRING1;\n      }else if(n === 0x5c){ this.appendStringChar(BACK_SLASH); this.tState = STRING1;\n      }else if(n === 0x2f){ this.appendStringChar(FORWARD_SLASH); this.tState = STRING1;\n      }else if(n === 0x62){ this.appendStringChar(BACKSPACE); this.tState = STRING1;\n      }else if(n === 0x66){ this.appendStringChar(FORM_FEED); this.tState = STRING1;\n      }else if(n === 0x6e){ this.appendStringChar(NEWLINE); this.tState = STRING1;\n      }else if(n === 0x72){ this.appendStringChar(CARRIAGE_RETURN); this.tState = STRING1;\n      }else if(n === 0x74){ this.appendStringChar(TAB); this.tState = STRING1;\n      }else if(n === 0x75){ this.unicode = \"\"; this.tState = STRING3;\n      }else{\n        return this.charError(buffer, i);\n      }\n    }else if (this.tState === STRING3 || this.tState === STRING4 || this.tState === STRING5 || this.tState === STRING6){ // unicode hex codes\n      n = buffer[i];\n      // 0-9 A-F a-f\n      if ((n >= 0x30 && n < 0x40) || (n > 0x40 && n <= 0x46) || (n > 0x60 && n <= 0x66)) {\n        this.unicode += String.fromCharCode(n);\n        if (this.tState++ === STRING6) {\n          var intVal = parseInt(this.unicode, 16);\n          this.unicode = undefined;\n          if (this.highSurrogate !== undefined && intVal >= 0xDC00 && intVal < (0xDFFF + 1)) { //<56320,57343> - lowSurrogate\n            this.appendStringBuf(new Buffer(String.fromCharCode(this.highSurrogate, intVal)));\n            this.highSurrogate = undefined;\n          } else if (this.highSurrogate === undefined && intVal >= 0xD800 && intVal < (0xDBFF + 1)) { //<55296,56319> - highSurrogate\n            this.highSurrogate = intVal;\n          } else {\n            if (this.highSurrogate !== undefined) {\n              this.appendStringBuf(new Buffer(String.fromCharCode(this.highSurrogate)));\n              this.highSurrogate = undefined;\n            }\n            this.appendStringBuf(new Buffer(String.fromCharCode(intVal)));\n          }\n          this.tState = STRING1;\n        }\n      } else {\n        return this.charError(buffer, i);\n      }\n    } else if (this.tState === NUMBER1 || this.tState === NUMBER3) {\n        n = buffer[i];\n\n        switch (n) {\n          case 0x30: // 0\n          case 0x31: // 1\n          case 0x32: // 2\n          case 0x33: // 3\n          case 0x34: // 4\n          case 0x35: // 5\n          case 0x36: // 6\n          case 0x37: // 7\n          case 0x38: // 8\n          case 0x39: // 9\n          case 0x2e: // .\n          case 0x65: // e\n          case 0x45: // E\n          case 0x2b: // +\n          case 0x2d: // -\n            this.string += String.fromCharCode(n);\n            this.tState = NUMBER3;\n            break;\n          default:\n            this.tState = START;\n            var error = this.numberReviver(this.string, buffer, i);\n            if (error){\n              return error;\n            }\n\n            this.offset += this.string.length - 1;\n            this.string = undefined;\n            i--;\n            break;\n        }\n    }else if (this.tState === TRUE1){ // r\n      if (buffer[i] === 0x72) { this.tState = TRUE2; }\n      else { return this.charError(buffer, i); }\n    }else if (this.tState === TRUE2){ // u\n      if (buffer[i] === 0x75) { this.tState = TRUE3; }\n      else { return this.charError(buffer, i); }\n    }else if (this.tState === TRUE3){ // e\n      if (buffer[i] === 0x65) { this.tState = START; this.onToken(TRUE, true); this.offset+= 3; }\n      else { return this.charError(buffer, i); }\n    }else if (this.tState === FALSE1){ // a\n      if (buffer[i] === 0x61) { this.tState = FALSE2; }\n      else { return this.charError(buffer, i); }\n    }else if (this.tState === FALSE2){ // l\n      if (buffer[i] === 0x6c) { this.tState = FALSE3; }\n      else { return this.charError(buffer, i); }\n    }else if (this.tState === FALSE3){ // s\n      if (buffer[i] === 0x73) { this.tState = FALSE4; }\n      else { return this.charError(buffer, i); }\n    }else if (this.tState === FALSE4){ // e\n      if (buffer[i] === 0x65) { this.tState = START; this.onToken(FALSE, false); this.offset+= 4; }\n      else { return this.charError(buffer, i); }\n    }else if (this.tState === NULL1){ // u\n      if (buffer[i] === 0x75) { this.tState = NULL2; }\n      else { return this.charError(buffer, i); }\n    }else if (this.tState === NULL2){ // l\n      if (buffer[i] === 0x6c) { this.tState = NULL3; }\n      else { return this.charError(buffer, i); }\n    }else if (this.tState === NULL3){ // l\n      if (buffer[i] === 0x6c) { this.tState = START; this.onToken(NULL, null); this.offset += 3; }\n      else { return this.charError(buffer, i); }\n    }\n  }\n};\nproto.onToken = function (token, value) {\n  // Override this to get events\n};\n\nproto.parseError = function (token, value) {\n  this.tState = STOP;\n  this.onError(new Error(\"Unexpected \" + Parser.toknam(token) + (value ? (\"(\" + JSON.stringify(value) + \")\") : \"\") + \" in state \" + Parser.toknam(this.state)));\n};\nproto.push = function () {\n  this.stack.push({value: this.value, key: this.key, mode: this.mode});\n};\nproto.pop = function () {\n  var value = this.value;\n  var parent = this.stack.pop();\n  this.value = parent.value;\n  this.key = parent.key;\n  this.mode = parent.mode;\n  this.emit(value);\n  if (!this.mode) { this.state = VALUE; }\n};\nproto.emit = function (value) {\n  if (this.mode) { this.state = COMMA; }\n  this.onValue(value);\n};\nproto.onValue = function (value) {\n  // Override me\n};\nproto.onToken = function (token, value) {\n  if(this.state === VALUE){\n    if(token === STRING || token === NUMBER || token === TRUE || token === FALSE || token === NULL){\n      if (this.value) {\n        this.value[this.key] = value;\n      }\n      this.emit(value);\n    }else if(token === LEFT_BRACE){\n      this.push();\n      if (this.value) {\n        this.value = this.value[this.key] = {};\n      } else {\n        this.value = {};\n      }\n      this.key = undefined;\n      this.state = KEY;\n      this.mode = OBJECT;\n    }else if(token === LEFT_BRACKET){\n      this.push();\n      if (this.value) {\n        this.value = this.value[this.key] = [];\n      } else {\n        this.value = [];\n      }\n      this.key = 0;\n      this.mode = ARRAY;\n      this.state = VALUE;\n    }else if(token === RIGHT_BRACE){\n      if (this.mode === OBJECT) {\n        this.pop();\n      } else {\n        return this.parseError(token, value);\n      }\n    }else if(token === RIGHT_BRACKET){\n      if (this.mode === ARRAY) {\n        this.pop();\n      } else {\n        return this.parseError(token, value);\n      }\n    }else{\n      return this.parseError(token, value);\n    }\n  }else if(this.state === KEY){\n    if (token === STRING) {\n      this.key = value;\n      this.state = COLON;\n    } else if (token === RIGHT_BRACE) {\n      this.pop();\n    } else {\n      return this.parseError(token, value);\n    }\n  }else if(this.state === COLON){\n    if (token === COLON) { this.state = VALUE; }\n    else { return this.parseError(token, value); }\n  }else if(this.state === COMMA){\n    if (token === COMMA) {\n      if (this.mode === ARRAY) { this.key++; this.state = VALUE; }\n      else if (this.mode === OBJECT) { this.state = KEY; }\n\n    } else if (token === RIGHT_BRACKET && this.mode === ARRAY || token === RIGHT_BRACE && this.mode === OBJECT) {\n      this.pop();\n    } else {\n      return this.parseError(token, value);\n    }\n  }else{\n    return this.parseError(token, value);\n  }\n};\n\n// Override to implement your own number reviver.\n// Any value returned is treated as error and will interrupt parsing.\nproto.numberReviver = function (text, buffer, i) {\n  var result = Number(text);\n\n  if (isNaN(result)) {\n    return this.charError(buffer, i);\n  }\n\n  if ((text.match(/[0-9]+/) == text) && (result.toString() != text)) {\n    // Long string of digits which is an ID string and not valid and/or safe JavaScript integer Number\n    this.onToken(STRING, text);\n  } else {\n    this.onToken(NUMBER, result);\n  }\n}\n\nParser.C = C;\n\nmodule.exports = Parser;\n","\"use strict\";\nvar __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    var desc = Object.getOwnPropertyDescriptor(m, k);\n    if (!desc || (\"get\" in desc ? !m.__esModule : desc.writable || desc.configurable)) {\n      desc = { enumerable: true, get: function() { return m[k]; } };\n    }\n    Object.defineProperty(o, k2, desc);\n}) : (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    o[k2] = m[k];\n}));\nvar __exportStar = (this && this.__exportStar) || function(m, exports) {\n    for (var p in m) if (p !== \"default\" && !Object.prototype.hasOwnProperty.call(exports, p)) __createBinding(exports, m, p);\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\n__exportStar(require(\"./lib/JsonLdParser\"), exports);\n//# sourceMappingURL=index.js.map","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.defaultExpandOptions = exports.JsonLdContextNormalized = void 0;\nconst relative_to_absolute_iri_1 = require(\"relative-to-absolute-iri\");\nconst ErrorCoded_1 = require(\"./ErrorCoded\");\nconst Util_1 = require(\"./Util\");\n/**\n * A class exposing operations over a normalized JSON-LD context.\n */\nclass JsonLdContextNormalized {\n    constructor(contextRaw) {\n        this.contextRaw = contextRaw;\n    }\n    /**\n     * @return The raw inner context.\n     */\n    getContextRaw() {\n        return this.contextRaw;\n    }\n    /**\n     * Expand the term or prefix of the given term if it has one,\n     * otherwise return the term as-is.\n     *\n     * This will try to expand the IRI as much as possible.\n     *\n     * Iff in vocab-mode, then other references to other terms in the context can be used,\n     * such as to `myTerm`:\n     * ```\n     * {\n     *   \"myTerm\": \"http://example.org/myLongTerm\"\n     * }\n     * ```\n     *\n     * @param {string} term A term that is an URL or a prefixed URL.\n     * @param {boolean} expandVocab If the term is a predicate or type and should be expanded based on @vocab,\n     *                              otherwise it is considered a regular term that is expanded based on @base.\n     * @param {IExpandOptions} options Options that define the way how expansion must be done.\n     * @return {string} The expanded term, the term as-is, or null if it was explicitly disabled in the context.\n     * @throws If the term is aliased to an invalid value (not a string, IRI or keyword).\n     */\n    expandTerm(term, expandVocab, options = exports.defaultExpandOptions) {\n        const contextValue = this.contextRaw[term];\n        // Immediately return if the term was disabled in the context\n        if (contextValue === null || (contextValue && contextValue['@id'] === null)) {\n            return null;\n        }\n        // Check the @id\n        let validIriMapping = true;\n        if (contextValue && expandVocab) {\n            const value = Util_1.Util.getContextValueId(contextValue);\n            if (value && value !== term) {\n                if (typeof value !== 'string' || (!Util_1.Util.isValidIri(value) && !Util_1.Util.isValidKeyword(value))) {\n                    // Don't mark this mapping as invalid if we have an unknown keyword, but of the correct form.\n                    if (!Util_1.Util.isPotentialKeyword(value)) {\n                        validIriMapping = false;\n                    }\n                }\n                else {\n                    return value;\n                }\n            }\n        }\n        // Check if the term is prefixed\n        const prefix = Util_1.Util.getPrefix(term, this.contextRaw);\n        const vocab = this.contextRaw['@vocab'];\n        const vocabRelative = (!!vocab || vocab === '') && vocab.indexOf(':') < 0;\n        const base = this.contextRaw['@base'];\n        const potentialKeyword = Util_1.Util.isPotentialKeyword(term);\n        if (prefix) {\n            const contextPrefixValue = this.contextRaw[prefix];\n            const value = Util_1.Util.getContextValueId(contextPrefixValue);\n            if (value) {\n                if (typeof contextPrefixValue === 'string' || !options.allowPrefixForcing) {\n                    // If we have a simple term definition,\n                    // check the last character of the prefix to determine whether or not it is a prefix.\n                    // Validate that prefix ends with gen-delim character, unless @prefix is true\n                    if (!Util_1.Util.isSimpleTermDefinitionPrefix(value, options)) {\n                        // Treat the term as an absolute IRI\n                        return term;\n                    }\n                }\n                else {\n                    // If we have an expanded term definition, default to @prefix: false\n                    if (value[0] !== '_' && !potentialKeyword && !contextPrefixValue['@prefix'] && !(term in this.contextRaw)) {\n                        // Treat the term as an absolute IRI\n                        return term;\n                    }\n                }\n                return value + term.substr(prefix.length + 1);\n            }\n        }\n        else if (expandVocab && ((vocab || vocab === '') || (options.allowVocabRelativeToBase && (base && vocabRelative)))\n            && !potentialKeyword && !Util_1.Util.isCompactIri(term)) {\n            if (vocabRelative) {\n                if (options.allowVocabRelativeToBase) {\n                    return ((vocab || base) ? (0, relative_to_absolute_iri_1.resolve)(vocab, base) : '') + term;\n                }\n                else {\n                    throw new ErrorCoded_1.ErrorCoded(`Relative vocab expansion for term '${term}' with vocab '${vocab}' is not allowed.`, ErrorCoded_1.ERROR_CODES.INVALID_VOCAB_MAPPING);\n                }\n            }\n            else {\n                return vocab + term;\n            }\n        }\n        else if (!expandVocab && base && !potentialKeyword && !Util_1.Util.isCompactIri(term)) {\n            return (0, relative_to_absolute_iri_1.resolve)(term, base);\n        }\n        // Return the term as-is, unless we discovered an invalid IRI mapping for this term in the context earlier.\n        if (validIriMapping) {\n            return term;\n        }\n        else {\n            throw new ErrorCoded_1.ErrorCoded(`Invalid IRI mapping found for context entry '${term}': '${JSON.stringify(contextValue)}'`, ErrorCoded_1.ERROR_CODES.INVALID_IRI_MAPPING);\n        }\n    }\n    /**\n     * Compact the given term using @base, @vocab, an aliased term, or a prefixed term.\n     *\n     * This will try to compact the IRI as much as possible.\n     *\n     * @param {string} iri An IRI to compact.\n     * @param {boolean} vocab If the term is a predicate or type and should be compacted based on @vocab,\n     *                        otherwise it is considered a regular term that is compacted based on @base.\n     * @return {string} The compacted term or the IRI as-is.\n     */\n    compactIri(iri, vocab) {\n        // Try @vocab compacting\n        if (vocab && this.contextRaw['@vocab'] && iri.startsWith(this.contextRaw['@vocab'])) {\n            return iri.substr(this.contextRaw['@vocab'].length);\n        }\n        // Try @base compacting\n        if (!vocab && this.contextRaw['@base'] && iri.startsWith(this.contextRaw['@base'])) {\n            return iri.substr(this.contextRaw['@base'].length);\n        }\n        // Loop over all terms in the context\n        // This will try to prefix as short as possible.\n        // Once a fully compacted alias is found, return immediately, as we can not go any shorter.\n        const shortestPrefixing = { prefix: '', suffix: iri };\n        for (const key in this.contextRaw) {\n            const value = this.contextRaw[key];\n            if (value && !Util_1.Util.isPotentialKeyword(key)) {\n                const contextIri = Util_1.Util.getContextValueId(value);\n                if (iri.startsWith(contextIri)) {\n                    const suffix = iri.substr(contextIri.length);\n                    if (!suffix) {\n                        if (vocab) {\n                            // Immediately return on compacted alias\n                            return key;\n                        }\n                    }\n                    else if (suffix.length < shortestPrefixing.suffix.length) {\n                        // Overwrite the shortest prefix\n                        shortestPrefixing.prefix = key;\n                        shortestPrefixing.suffix = suffix;\n                    }\n                }\n            }\n        }\n        // Return the shortest prefix\n        if (shortestPrefixing.prefix) {\n            return shortestPrefixing.prefix + ':' + shortestPrefixing.suffix;\n        }\n        return iri;\n    }\n}\nexports.JsonLdContextNormalized = JsonLdContextNormalized;\nexports.defaultExpandOptions = {\n    allowPrefixForcing: true,\n    allowPrefixNonGenDelims: false,\n    allowVocabRelativeToBase: true,\n};\n//# sourceMappingURL=JsonLdContextNormalized.js.map","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.FetchDocumentLoader = void 0;\nconst ErrorCoded_1 = require(\"./ErrorCoded\");\nconst http_link_header_1 = require(\"http-link-header\");\nconst relative_to_absolute_iri_1 = require(\"relative-to-absolute-iri\");\n/**\n * Loads documents via the fetch API.\n */\nclass FetchDocumentLoader {\n    constructor(fetcher) {\n        this.fetcher = fetcher;\n    }\n    async load(url) {\n        const response = await (this.fetcher || fetch)(url, { headers: new Headers({ accept: 'application/ld+json' }) });\n        if (response.ok && response.headers) {\n            let mediaType = response.headers.get('Content-Type');\n            if (mediaType) {\n                const colonPos = mediaType.indexOf(';');\n                if (colonPos > 0) {\n                    mediaType = mediaType.substr(0, colonPos);\n                }\n            }\n            if (mediaType === 'application/ld+json') {\n                // Return JSON-LD if proper content type was returned\n                return (await response.json());\n            }\n            else {\n                // Check for alternate link for a non-JSON-LD response\n                if (response.headers.has('Link')) {\n                    let alternateUrl;\n                    response.headers.forEach((value, key) => {\n                        if (key === 'link') {\n                            const linkHeader = (0, http_link_header_1.parse)(value);\n                            for (const link of linkHeader.get('type', 'application/ld+json')) {\n                                if (link.rel === 'alternate') {\n                                    if (alternateUrl) {\n                                        throw new Error('Multiple JSON-LD alternate links were found on ' + url);\n                                    }\n                                    alternateUrl = (0, relative_to_absolute_iri_1.resolve)(link.uri, url);\n                                }\n                            }\n                        }\n                    });\n                    if (alternateUrl) {\n                        return this.load(alternateUrl);\n                    }\n                }\n                throw new ErrorCoded_1.ErrorCoded(`Unsupported JSON-LD media type ${mediaType}`, ErrorCoded_1.ERROR_CODES.LOADING_DOCUMENT_FAILED);\n            }\n        }\n        else {\n            throw new Error(response.statusText || `Status code: ${response.status}`);\n        }\n    }\n}\nexports.FetchDocumentLoader = FetchDocumentLoader;\n//# sourceMappingURL=FetchDocumentLoader.js.map","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.ParsingContext = void 0;\nconst jsonld_context_parser_1 = require(\"jsonld-context-parser\");\nconst ErrorCoded_1 = require(\"jsonld-context-parser/lib/ErrorCoded\");\nconst ContextTree_1 = require(\"./ContextTree\");\nconst JsonLdParser_1 = require(\"./JsonLdParser\");\n/**\n * Data holder for parsing information.\n */\nclass ParsingContext {\n    constructor(options) {\n        // Initialize settings\n        this.contextParser = new jsonld_context_parser_1.ContextParser({ documentLoader: options.documentLoader, skipValidation: options.skipContextValidation });\n        this.streamingProfile = !!options.streamingProfile;\n        this.baseIRI = options.baseIRI;\n        this.produceGeneralizedRdf = !!options.produceGeneralizedRdf;\n        this.allowSubjectList = !!options.allowSubjectList;\n        this.processingMode = options.processingMode || JsonLdParser_1.JsonLdParser.DEFAULT_PROCESSING_MODE;\n        this.strictValues = !!options.strictValues;\n        this.validateValueIndexes = !!options.validateValueIndexes;\n        this.defaultGraph = options.defaultGraph;\n        this.rdfDirection = options.rdfDirection;\n        this.normalizeLanguageTags = options.normalizeLanguageTags;\n        this.streamingProfileAllowOutOfOrderPlainType = options.streamingProfileAllowOutOfOrderPlainType;\n        this.rdfstar = options.rdfstar !== false;\n        this.rdfstarReverseInEmbedded = options.rdfstarReverseInEmbedded;\n        this.topLevelProperties = false;\n        this.activeProcessingMode = parseFloat(this.processingMode);\n        // Initialize stacks\n        this.processingStack = [];\n        this.processingType = [];\n        this.emittedStack = [];\n        this.idStack = [];\n        this.graphStack = [];\n        this.graphContainerTermStack = [];\n        this.listPointerStack = [];\n        this.contextTree = new ContextTree_1.ContextTree();\n        this.literalStack = [];\n        this.validationStack = [];\n        this.unaliasedKeywordCacheStack = [];\n        this.jsonLiteralStack = [];\n        this.unidentifiedValuesBuffer = [];\n        this.unidentifiedGraphsBuffer = [];\n        this.annotationsBuffer = [];\n        this.pendingContainerFlushBuffers = [];\n        this.parser = options.parser;\n        if (options.context) {\n            this.rootContext = this.parseContext(options.context);\n            this.rootContext.then((context) => this.validateContext(context));\n        }\n        else {\n            this.rootContext = Promise.resolve(new jsonld_context_parser_1.JsonLdContextNormalized(this.baseIRI ? { '@base': this.baseIRI, '@__baseDocument': true } : {}));\n        }\n    }\n    /**\n     * Parse the given context with the configured options.\n     * @param {JsonLdContext} context A context to parse.\n     * @param {JsonLdContextNormalized} parentContext An optional parent context.\n     * @param {boolean} ignoreProtection If @protected term checks should be ignored.\n     * @return {Promise<JsonLdContextNormalized>} A promise resolving to the parsed context.\n     */\n    async parseContext(context, parentContext, ignoreProtection) {\n        return this.contextParser.parse(context, {\n            baseIRI: this.baseIRI,\n            ignoreProtection,\n            normalizeLanguageTags: this.normalizeLanguageTags,\n            parentContext,\n            processingMode: this.activeProcessingMode,\n        });\n    }\n    /**\n     * Check if the given context is valid.\n     * If not, an error will be thrown.\n     * @param {JsonLdContextNormalized} context A context.\n     */\n    validateContext(context) {\n        const activeVersion = context.getContextRaw()['@version'];\n        if (activeVersion) {\n            if (this.activeProcessingMode && activeVersion > this.activeProcessingMode) {\n                throw new ErrorCoded_1.ErrorCoded(`Unsupported JSON-LD version '${activeVersion}' under active processing mode ${this.activeProcessingMode}.`, ErrorCoded_1.ERROR_CODES.PROCESSING_MODE_CONFLICT);\n            }\n            else {\n                if (this.activeProcessingMode && activeVersion < this.activeProcessingMode) {\n                    throw new ErrorCoded_1.ErrorCoded(`Invalid JSON-LD version ${activeVersion} under active processing mode ${this.activeProcessingMode}.`, ErrorCoded_1.ERROR_CODES.INVALID_VERSION_VALUE);\n                }\n                this.activeProcessingMode = activeVersion;\n            }\n        }\n    }\n    /**\n     * Get the context at the given path.\n     * @param {keys} keys The path of keys to get the context at.\n     * @param {number} offset The path offset, defaults to 1.\n     * @return {Promise<JsonLdContextNormalized>} A promise resolving to a context.\n     */\n    async getContext(keys, offset = 1) {\n        const keysOriginal = keys;\n        // Ignore array keys at the end\n        while (typeof keys[keys.length - 1] === 'number') {\n            keys = keys.slice(0, keys.length - 1);\n        }\n        // Handle offset on keys\n        if (offset) {\n            keys = keys.slice(0, -offset);\n        }\n        // Determine the closest context\n        const contextData = await this.getContextPropagationAware(keys);\n        const context = contextData.context;\n        // Process property-scoped contexts (high-to-low)\n        let contextRaw = context.getContextRaw();\n        for (let i = contextData.depth; i < keysOriginal.length - offset; i++) {\n            const key = keysOriginal[i];\n            const contextKeyEntry = contextRaw[key];\n            if (contextKeyEntry && typeof contextKeyEntry === 'object' && '@context' in contextKeyEntry) {\n                const scopedContext = (await this.parseContext(contextKeyEntry, contextRaw, true)).getContextRaw();\n                const propagate = !(key in scopedContext)\n                    || scopedContext[key]['@context']['@propagate']; // Propagation is true by default\n                if (propagate !== false || i === keysOriginal.length - 1 - offset) {\n                    contextRaw = Object.assign({}, scopedContext);\n                    // Clean up final context\n                    delete contextRaw['@propagate'];\n                    contextRaw[key] = Object.assign({}, contextRaw[key]);\n                    if ('@id' in contextKeyEntry) {\n                        contextRaw[key]['@id'] = contextKeyEntry['@id'];\n                    }\n                    delete contextRaw[key]['@context'];\n                    if (propagate !== false) {\n                        this.contextTree.setContext(keysOriginal.slice(0, i + offset), Promise.resolve(new jsonld_context_parser_1.JsonLdContextNormalized(contextRaw)));\n                    }\n                }\n            }\n        }\n        return new jsonld_context_parser_1.JsonLdContextNormalized(contextRaw);\n    }\n    /**\n     * Get the context at the given path.\n     * Non-propagating contexts will be skipped,\n     * unless the context at that exact depth is retrieved.\n     *\n     * This ONLY takes into account context propagation logic,\n     * so this should usually not be called directly,\n     * call {@link #getContext} instead.\n     *\n     * @param keys The path of keys to get the context at.\n     * @return {Promise<{ context: JsonLdContextNormalized, depth: number }>} A context and its depth.\n     */\n    async getContextPropagationAware(keys) {\n        const originalDepth = keys.length;\n        let contextData = null;\n        let hasApplicablePropertyScopedContext;\n        do {\n            hasApplicablePropertyScopedContext = false;\n            if (contextData && '@__propagateFallback' in contextData.context.getContextRaw()) {\n                // If a propagation fallback context has been set,\n                // fallback to that context and retry for the same depth.\n                contextData.context = new jsonld_context_parser_1.JsonLdContextNormalized(contextData.context.getContextRaw()['@__propagateFallback']);\n            }\n            else {\n                if (contextData) {\n                    // If we had a previous iteration, jump to the parent of context depth.\n                    // We must do this because once we get here, last context had propagation disabled,\n                    // so we check its first parent instead.\n                    keys = keys.slice(0, contextData.depth - 1);\n                }\n                contextData = await this.contextTree.getContext(keys) || { context: await this.rootContext, depth: 0 };\n            }\n            // Allow non-propagating contexts to propagate one level deeper\n            // if it defines a property-scoped context that is applicable for the current key.\n            // @see https://w3c.github.io/json-ld-api/tests/toRdf-manifest#tc012\n            const lastKey = keys[keys.length - 1];\n            if (lastKey in contextData.context.getContextRaw()) {\n                const lastKeyValue = contextData.context.getContextRaw()[lastKey];\n                if (lastKeyValue && typeof lastKeyValue === 'object' && '@context' in lastKeyValue) {\n                    hasApplicablePropertyScopedContext = true;\n                }\n            }\n        } while (contextData.depth > 0 // Root context has a special case\n            && contextData.context.getContextRaw()['@propagate'] === false // Stop loop if propagation is true\n            && contextData.depth !== originalDepth // Stop loop if requesting exact depth of non-propagating\n            && !hasApplicablePropertyScopedContext);\n        // Special case for root context that does not allow propagation.\n        // Fallback to empty context in that case.\n        if (contextData.depth === 0\n            && contextData.context.getContextRaw()['@propagate'] === false\n            && contextData.depth !== originalDepth) {\n            contextData.context = new jsonld_context_parser_1.JsonLdContextNormalized({});\n        }\n        return contextData;\n    }\n    /**\n     * Start a new job for parsing the given value.\n     * @param {any[]} keys The stack of keys.\n     * @param value The value to parse.\n     * @param {number} depth The depth to parse at.\n     * @param {boolean} lastDepthCheck If the lastDepth check should be done for buffer draining.\n     * @return {Promise<void>} A promise resolving when the job is done.\n     */\n    async newOnValueJob(keys, value, depth, lastDepthCheck) {\n        await this.parser.newOnValueJob(keys, value, depth, lastDepthCheck);\n    }\n    /**\n     * Flush the pending container flush buffers\n     * @return {boolean} If any pending buffers were flushed.\n     */\n    async handlePendingContainerFlushBuffers() {\n        if (this.pendingContainerFlushBuffers.length > 0) {\n            for (const pendingFlushBuffer of this.pendingContainerFlushBuffers) {\n                await this.parser.flushBuffer(pendingFlushBuffer.depth, pendingFlushBuffer.keys);\n                this.parser.flushStacks(pendingFlushBuffer.depth);\n            }\n            this.pendingContainerFlushBuffers.splice(0, this.pendingContainerFlushBuffers.length);\n            return true;\n        }\n        else {\n            return false;\n        }\n    }\n    /**\n     * Emit the given quad into the output stream.\n     * @param {number} depth The depth the quad was generated at.\n     * @param {Quad} quad A quad to emit.\n     */\n    emitQuad(depth, quad) {\n        if (depth === 1) {\n            this.topLevelProperties = true;\n        }\n        this.parser.push(quad);\n    }\n    /**\n     * Emit the given error into the output stream.\n     * @param {Error} error An error to emit.\n     */\n    emitError(error) {\n        this.parser.emit('error', error);\n    }\n    /**\n     * Emit the given context into the output stream under the 'context' event.\n     * @param {JsonLdContext} context A context to emit.\n     */\n    emitContext(context) {\n        this.parser.emit('context', context);\n    }\n    /**\n     * Safely get or create the depth value of {@link ParsingContext.unidentifiedValuesBuffer}.\n     * @param {number} depth A depth.\n     * @return {{predicate: Term; object: Term; reverse: boolean}[]} An element of\n     *                                                               {@link ParsingContext.unidentifiedValuesBuffer}.\n     */\n    getUnidentifiedValueBufferSafe(depth) {\n        let buffer = this.unidentifiedValuesBuffer[depth];\n        if (!buffer) {\n            buffer = [];\n            this.unidentifiedValuesBuffer[depth] = buffer;\n        }\n        return buffer;\n    }\n    /**\n     * Safely get or create the depth value of {@link ParsingContext.unidentifiedGraphsBuffer}.\n     * @param {number} depth A depth.\n     * @return {{predicate: Term; object: Term; reverse: boolean}[]} An element of\n     *                                                               {@link ParsingContext.unidentifiedGraphsBuffer}.\n     */\n    getUnidentifiedGraphBufferSafe(depth) {\n        let buffer = this.unidentifiedGraphsBuffer[depth];\n        if (!buffer) {\n            buffer = [];\n            this.unidentifiedGraphsBuffer[depth] = buffer;\n        }\n        return buffer;\n    }\n    /**\n     * Safely get or create the depth value of {@link ParsingContext.annotationsBuffer}.\n     * @param {number} depth A depth.\n     * @return {} An element of {@link ParsingContext.annotationsBuffer}.\n     */\n    getAnnotationsBufferSafe(depth) {\n        let buffer = this.annotationsBuffer[depth];\n        if (!buffer) {\n            buffer = [];\n            this.annotationsBuffer[depth] = buffer;\n        }\n        return buffer;\n    }\n    /**\n     * @return IExpandOptions The expand options for the active processing mode.\n     */\n    getExpandOptions() {\n        return ParsingContext.EXPAND_OPTIONS[this.activeProcessingMode];\n    }\n    /**\n     * Shift the stack at the given offset to the given depth.\n     *\n     * This will override anything in the stack at `depth`,\n     * and this will remove anything at `depth + depthOffset`\n     *\n     * @param depth The target depth.\n     * @param depthOffset The origin depth, relative to `depth`.\n     */\n    shiftStack(depth, depthOffset) {\n        // Copy the id stack value up one level so that the next job can access the id.\n        const deeperIdStack = this.idStack[depth + depthOffset];\n        if (deeperIdStack) {\n            this.idStack[depth] = deeperIdStack;\n            this.emittedStack[depth] = true;\n            delete this.idStack[depth + depthOffset];\n        }\n        // Shorten key stack\n        if (this.pendingContainerFlushBuffers.length) {\n            for (const buffer of this.pendingContainerFlushBuffers) {\n                if (buffer.depth >= depth + depthOffset) {\n                    buffer.depth -= depthOffset;\n                    buffer.keys.splice(depth, depthOffset);\n                }\n            }\n        }\n        // Splice stacks\n        if (this.unidentifiedValuesBuffer[depth + depthOffset]) {\n            this.unidentifiedValuesBuffer[depth] = this.unidentifiedValuesBuffer[depth + depthOffset];\n            delete this.unidentifiedValuesBuffer[depth + depthOffset];\n        }\n        if (this.annotationsBuffer[depth + depthOffset - 1]) {\n            if (!this.annotationsBuffer[depth - 1]) {\n                this.annotationsBuffer[depth - 1] = [];\n            }\n            this.annotationsBuffer[depth - 1] = [\n                ...this.annotationsBuffer[depth - 1],\n                ...this.annotationsBuffer[depth + depthOffset - 1],\n            ];\n            delete this.annotationsBuffer[depth + depthOffset - 1];\n        }\n        // TODO: also do the same for other stacks\n    }\n}\nexports.ParsingContext = ParsingContext;\nParsingContext.EXPAND_OPTIONS = {\n    1.0: {\n        allowPrefixForcing: false,\n        allowPrefixNonGenDelims: false,\n        allowVocabRelativeToBase: false,\n    },\n    1.1: {\n        allowPrefixForcing: true,\n        allowPrefixNonGenDelims: false,\n        allowVocabRelativeToBase: true,\n    },\n};\n//# sourceMappingURL=ParsingContext.js.map","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.Util = void 0;\nconst jsonld_context_parser_1 = require(\"jsonld-context-parser\");\nconst rdf_data_factory_1 = require(\"rdf-data-factory\");\nconst EntryHandlerContainer_1 = require(\"./entryhandler/EntryHandlerContainer\");\n// tslint:disable-next-line:no-var-requires\nconst canonicalizeJson = require('canonicalize');\n/**\n * Utility functions and methods.\n */\nclass Util {\n    constructor(options) {\n        this.parsingContext = options.parsingContext;\n        this.dataFactory = options.dataFactory || new rdf_data_factory_1.DataFactory();\n        this.rdfFirst = this.dataFactory.namedNode(Util.RDF + 'first');\n        this.rdfRest = this.dataFactory.namedNode(Util.RDF + 'rest');\n        this.rdfNil = this.dataFactory.namedNode(Util.RDF + 'nil');\n        this.rdfType = this.dataFactory.namedNode(Util.RDF + 'type');\n        this.rdfJson = this.dataFactory.namedNode(Util.RDF + 'JSON');\n    }\n    /**\n     * Helper function to get the value of a context entry,\n     * or fallback to a certain value.\n     * @param {JsonLdContextNormalized} context A JSON-LD context.\n     * @param {string} contextKey A pre-defined JSON-LD key in context entries.\n     * @param {string} key A context entry key.\n     * @param {string} fallback A fallback value for when the given contextKey\n     *                          could not be found in the value with the given key.\n     * @return {string} The value of the given contextKey in the entry behind key in the given context,\n     *                  or the given fallback value.\n     */\n    static getContextValue(context, contextKey, key, fallback) {\n        const entry = context.getContextRaw()[key];\n        if (!entry) {\n            return fallback;\n        }\n        const type = entry[contextKey];\n        return type === undefined ? fallback : type;\n    }\n    /**\n     * Get the container type of the given key in the context.\n     *\n     * Should any context-scoping bugs should occur related to this in the future,\n     * it may be required to increase the offset from the depth at which the context is retrieved by one (to 2).\n     * This is because containers act 2 levels deep.\n     *\n     * @param {JsonLdContextNormalized} context A JSON-LD context.\n     * @param {string} key A context entry key.\n     * @return {string} The container type.\n     */\n    static getContextValueContainer(context, key) {\n        return Util.getContextValue(context, '@container', key, { '@set': true });\n    }\n    /**\n     * Get the value type of the given key in the context.\n     * @param {JsonLdContextNormalized} context A JSON-LD context.\n     * @param {string} key A context entry key.\n     * @return {string} The node type.\n     */\n    static getContextValueType(context, key) {\n        const valueType = Util.getContextValue(context, '@type', key, null);\n        if (valueType === '@none') {\n            return null;\n        }\n        return valueType;\n    }\n    /**\n     * Get the language of the given key in the context.\n     * @param {JsonLdContextNormalized} context A JSON-LD context.\n     * @param {string} key A context entry key.\n     * @return {string} The node type.\n     */\n    static getContextValueLanguage(context, key) {\n        return Util.getContextValue(context, '@language', key, context.getContextRaw()['@language'] || null);\n    }\n    /**\n     * Get the direction of the given key in the context.\n     * @param {JsonLdContextNormalized} context A JSON-LD context.\n     * @param {string} key A context entry key.\n     * @return {string} The node type.\n     */\n    static getContextValueDirection(context, key) {\n        return Util.getContextValue(context, '@direction', key, context.getContextRaw()['@direction'] || null);\n    }\n    /**\n     * Check if the given key in the context is a reversed property.\n     * @param {JsonLdContextNormalized} context A JSON-LD context.\n     * @param {string} key A context entry key.\n     * @return {boolean} If the context value has a @reverse key.\n     */\n    static isContextValueReverse(context, key) {\n        return !!Util.getContextValue(context, '@reverse', key, null);\n    }\n    /**\n     * Get the @index of the given key in the context.\n     * @param {JsonLdContextNormalized} context A JSON-LD context.\n     * @param {string} key A context entry key.\n     * @return {string} The index.\n     */\n    static getContextValueIndex(context, key) {\n        return Util.getContextValue(context, '@index', key, context.getContextRaw()['@index'] || null);\n    }\n    /**\n     * Check if the given key refers to a reversed property.\n     * @param {JsonLdContextNormalized} context A JSON-LD context.\n     * @param {string} key The property key.\n     * @param {string} parentKey The parent key.\n     * @return {boolean} If the property must be reversed.\n     */\n    static isPropertyReverse(context, key, parentKey) {\n        // '!==' is needed because reversed properties in a @reverse container should cancel each other out.\n        return parentKey === '@reverse' !== Util.isContextValueReverse(context, key);\n    }\n    /**\n     * Check if the given key exists inside an embedded node as direct child.\n     * @param {string} parentKey The parent key.\n     * @return {boolean} If the property is embedded.\n     */\n    static isPropertyInEmbeddedNode(parentKey) {\n        return parentKey === '@id';\n    }\n    /**\n     * Check if the given key exists inside an annotation object as direct child.\n     * @param {string} parentKey The parent key.\n     * @return {boolean} If the property is an annotation.\n     */\n    static isPropertyInAnnotationObject(parentKey) {\n        return parentKey === '@annotation';\n    }\n    /**\n     * Check if the given IRI is valid.\n     * @param {string} iri A potential IRI.\n     * @return {boolean} If the given IRI is valid.\n     */\n    static isValidIri(iri) {\n        return iri !== null && jsonld_context_parser_1.Util.isValidIri(iri);\n    }\n    /**\n     * Check if the given first array (needle) is a prefix of the given second array (haystack).\n     * @param needle An array to check if it is a prefix.\n     * @param haystack An array to look in.\n     */\n    static isPrefixArray(needle, haystack) {\n        if (needle.length > haystack.length) {\n            return false;\n        }\n        for (let i = 0; i < needle.length; i++) {\n            if (needle[i] !== haystack[i]) {\n                return false;\n            }\n        }\n        return true;\n    }\n    /**\n     * Make sure that @id-@index pairs are equal over all array values.\n     * Reject otherwise.\n     * @param {any[]} value An array value.\n     * @return {Promise<void>} A promise rejecting if conflicts are present.\n     */\n    async validateValueIndexes(value) {\n        if (this.parsingContext.validateValueIndexes) {\n            const indexHashes = {};\n            for (const entry of value) {\n                if (entry && typeof entry === 'object') {\n                    const id = entry['@id'];\n                    const index = entry['@index'];\n                    if (id && index) {\n                        const existingIndexValue = indexHashes[id];\n                        if (existingIndexValue && existingIndexValue !== index) {\n                            throw new jsonld_context_parser_1.ErrorCoded(`Conflicting @index value for ${id}`, jsonld_context_parser_1.ERROR_CODES.CONFLICTING_INDEXES);\n                        }\n                        indexHashes[id] = index;\n                    }\n                }\n            }\n        }\n    }\n    /**\n     * Convert a given JSON value to an RDF term.\n     * @param {JsonLdContextNormalized} context A JSON-LD context.\n     * @param {string} key The current JSON key.\n     * @param value A JSON value.\n     * @param {number} depth The depth the value is at.\n     * @param {string[]} keys The path of keys.\n     * @return {Promise<RDF.Term[]>} An RDF term array.\n     */\n    async valueToTerm(context, key, value, depth, keys) {\n        // Skip further processing if we have an @type: @json\n        if (Util.getContextValueType(context, key) === '@json') {\n            return [this.dataFactory.literal(this.valueToJsonString(value), this.rdfJson)];\n        }\n        const type = typeof value;\n        switch (type) {\n            case 'object':\n                // Skip if we have a null or undefined object\n                if (value === null || value === undefined) {\n                    return [];\n                }\n                // Special case for arrays\n                if (Array.isArray(value)) {\n                    // We handle arrays at value level so we can emit earlier, so this is handled already when we get here.\n                    // Empty context-based lists are emitted at this place, because our streaming algorithm doesn't detect those.\n                    if ('@list' in Util.getContextValueContainer(context, key)) {\n                        if (value.length === 0) {\n                            return [this.rdfNil];\n                        }\n                        else {\n                            return this.parsingContext.idStack[depth + 1] || [];\n                        }\n                    }\n                    await this.validateValueIndexes(value);\n                    return [];\n                }\n                // Handle property-scoped contexts\n                context = await this.getContextSelfOrPropertyScoped(context, key);\n                // Handle local context in the value\n                if ('@context' in value) {\n                    context = await this.parsingContext.parseContext(value['@context'], (await this.parsingContext.getContext(keys, 0)).getContextRaw());\n                }\n                // In all other cases, we have a hash\n                value = await this.unaliasKeywords(value, keys, depth, context); // Un-alias potential keywords in this hash\n                if ('@value' in value) {\n                    let val;\n                    let valueLanguage;\n                    let valueDirection;\n                    let valueType;\n                    let valueIndex; // We don't use the index, but we need to check its type for spec-compliance\n                    for (key in value) {\n                        const subValue = value[key];\n                        switch (key) {\n                            case '@value':\n                                val = subValue;\n                                break;\n                            case '@language':\n                                valueLanguage = subValue;\n                                break;\n                            case '@direction':\n                                valueDirection = subValue;\n                                break;\n                            case '@type':\n                                valueType = subValue;\n                                break;\n                            case '@index':\n                                valueIndex = subValue;\n                                break;\n                            case '@annotation':\n                                // This keyword is allowed, but is processed like normal nodes\n                                break;\n                            default:\n                                throw new jsonld_context_parser_1.ErrorCoded(`Unknown value entry '${key}' in @value: ${JSON.stringify(value)}`, jsonld_context_parser_1.ERROR_CODES.INVALID_VALUE_OBJECT);\n                        }\n                    }\n                    // Skip further processing if we have an @type: @json\n                    if (await this.unaliasKeyword(valueType, keys, depth, true, context) === '@json') {\n                        return [this.dataFactory.literal(this.valueToJsonString(val), this.rdfJson)];\n                    }\n                    // Validate @value\n                    if (val === null) {\n                        return [];\n                    }\n                    if (typeof val === 'object') {\n                        throw new jsonld_context_parser_1.ErrorCoded(`The value of an '@value' can not be an object, got '${JSON.stringify(val)}'`, jsonld_context_parser_1.ERROR_CODES.INVALID_VALUE_OBJECT_VALUE);\n                    }\n                    // Validate @index\n                    if (this.parsingContext.validateValueIndexes && valueIndex && typeof valueIndex !== 'string') {\n                        throw new jsonld_context_parser_1.ErrorCoded(`The value of an '@index' must be a string, got '${JSON.stringify(valueIndex)}'`, jsonld_context_parser_1.ERROR_CODES.INVALID_INDEX_VALUE);\n                    }\n                    // Validate @language and @direction\n                    if (valueLanguage) {\n                        if (typeof val !== 'string') {\n                            throw new jsonld_context_parser_1.ErrorCoded(`When an '@language' is set, the value of '@value' must be a string, got '${JSON.stringify(val)}'`, jsonld_context_parser_1.ERROR_CODES.INVALID_LANGUAGE_TAGGED_VALUE);\n                        }\n                        if (!jsonld_context_parser_1.ContextParser.validateLanguage(valueLanguage, this.parsingContext.strictValues, jsonld_context_parser_1.ERROR_CODES.INVALID_LANGUAGE_TAGGED_STRING)) {\n                            return [];\n                        }\n                        // Language tags are always normalized to lowercase in 1.0.\n                        if (this.parsingContext.normalizeLanguageTags || this.parsingContext.activeProcessingMode === 1.0) {\n                            valueLanguage = valueLanguage.toLowerCase();\n                        }\n                    }\n                    if (valueDirection) {\n                        if (typeof val !== 'string') {\n                            throw new Error(`When an '@direction' is set, the value of '@value' must be a string, got '${JSON.stringify(val)}'`);\n                        }\n                        if (!jsonld_context_parser_1.ContextParser.validateDirection(valueDirection, this.parsingContext.strictValues)) {\n                            return [];\n                        }\n                    }\n                    // Check @language and @direction\n                    if (valueLanguage && valueDirection) {\n                        if (valueType) {\n                            throw new jsonld_context_parser_1.ErrorCoded(`Can not have '@language', '@direction' and '@type' in a value: '${JSON\n                                .stringify(value)}'`, jsonld_context_parser_1.ERROR_CODES.INVALID_VALUE_OBJECT);\n                        }\n                        return this.nullableTermToArray(this\n                            .createLanguageDirectionLiteral(depth, val, valueLanguage, valueDirection));\n                    }\n                    else if (valueLanguage) { // Check @language\n                        if (valueType) {\n                            throw new jsonld_context_parser_1.ErrorCoded(`Can not have both '@language' and '@type' in a value: '${JSON.stringify(value)}'`, jsonld_context_parser_1.ERROR_CODES.INVALID_VALUE_OBJECT);\n                        }\n                        return [this.dataFactory.literal(val, valueLanguage)];\n                    }\n                    else if (valueDirection) { // Check @direction\n                        if (valueType) {\n                            throw new jsonld_context_parser_1.ErrorCoded(`Can not have both '@direction' and '@type' in a value: '${JSON.stringify(value)}'`, jsonld_context_parser_1.ERROR_CODES.INVALID_VALUE_OBJECT);\n                        }\n                        return this.nullableTermToArray(this\n                            .createLanguageDirectionLiteral(depth, val, valueLanguage, valueDirection));\n                    }\n                    else if (valueType) { // Validate @type\n                        if (typeof valueType !== 'string') {\n                            throw new jsonld_context_parser_1.ErrorCoded(`The value of an '@type' must be a string, got '${JSON.stringify(valueType)}'`, jsonld_context_parser_1.ERROR_CODES.INVALID_TYPED_VALUE);\n                        }\n                        const typeTerm = this.createVocabOrBaseTerm(context, valueType);\n                        if (!typeTerm) {\n                            throw new jsonld_context_parser_1.ErrorCoded(`Invalid '@type' value, got '${JSON.stringify(valueType)}'`, jsonld_context_parser_1.ERROR_CODES.INVALID_TYPED_VALUE);\n                        }\n                        if (typeTerm.termType !== 'NamedNode') {\n                            throw new jsonld_context_parser_1.ErrorCoded(`Illegal value type (${typeTerm.termType}): ${valueType}`, jsonld_context_parser_1.ERROR_CODES.INVALID_TYPED_VALUE);\n                        }\n                        return [this.dataFactory.literal(val, typeTerm)];\n                    }\n                    // We don't pass the context, because context-based things like @language should be ignored\n                    return await this.valueToTerm(new jsonld_context_parser_1.JsonLdContextNormalized({}), key, val, depth, keys);\n                }\n                else if ('@set' in value) {\n                    // No other entries are allow in this value\n                    if (Object.keys(value).length > 1) {\n                        throw new jsonld_context_parser_1.ErrorCoded(`Found illegal neighbouring entries next to @set for key: '${key}'`, jsonld_context_parser_1.ERROR_CODES.INVALID_SET_OR_LIST_OBJECT);\n                    }\n                    // No need to do anything here, this is handled at the deeper level.\n                    return [];\n                }\n                else if ('@list' in value) {\n                    // No other entries are allowed in this value\n                    if (Object.keys(value).length > 1) {\n                        throw new jsonld_context_parser_1.ErrorCoded(`Found illegal neighbouring entries next to @list for key: '${key}'`, jsonld_context_parser_1.ERROR_CODES.INVALID_SET_OR_LIST_OBJECT);\n                    }\n                    const listValue = value[\"@list\"];\n                    // We handle lists at value level so we can emit earlier, so this is handled already when we get here.\n                    // Empty anonymous lists are emitted at this place, because our streaming algorithm doesn't detect those.\n                    if (Array.isArray(listValue)) {\n                        if (listValue.length === 0) {\n                            return [this.rdfNil];\n                        }\n                        else {\n                            return this.parsingContext.idStack[depth + 1] || [];\n                        }\n                    }\n                    else {\n                        // We only have a single list element here, so emit this directly as single element\n                        return await this.valueToTerm(await this.parsingContext.getContext(keys), key, listValue, depth - 1, keys.slice(0, -1));\n                    }\n                }\n                else if ('@reverse' in value && typeof value['@reverse'] === 'boolean') {\n                    // We handle reverse properties at value level so we can emit earlier,\n                    // so this is handled already when we get here.\n                    return [];\n                }\n                else if ('@graph' in Util.getContextValueContainer(await this.parsingContext.getContext(keys), key)) {\n                    // We are processing a graph container\n                    const graphContainerEntries = this.parsingContext.graphContainerTermStack[depth + 1];\n                    return graphContainerEntries ? Object.values(graphContainerEntries) : [this.dataFactory.blankNode()];\n                }\n                else if (\"@id\" in value) {\n                    // Use deeper context if the value node contains other properties next to @id.\n                    if (Object.keys(value).length > 1) {\n                        context = await this.parsingContext.getContext(keys, 0);\n                    }\n                    // Handle local context in the value\n                    if ('@context' in value) {\n                        context = await this.parsingContext.parseContext(value['@context'], context.getContextRaw());\n                    }\n                    if (value[\"@type\"] === '@vocab') {\n                        return this.nullableTermToArray(this.createVocabOrBaseTerm(context, value[\"@id\"]));\n                    }\n                    else {\n                        const valueId = value[\"@id\"];\n                        let valueTerm;\n                        if (typeof valueId === 'object') {\n                            if (this.parsingContext.rdfstar) {\n                                valueTerm = this.parsingContext.idStack[depth + 1][0];\n                            }\n                            else {\n                                throw new jsonld_context_parser_1.ErrorCoded(`Found illegal @id '${value}'`, jsonld_context_parser_1.ERROR_CODES.INVALID_ID_VALUE);\n                            }\n                        }\n                        else {\n                            valueTerm = this.resourceToTerm(context, valueId);\n                        }\n                        return this.nullableTermToArray(valueTerm);\n                    }\n                }\n                else {\n                    // Only make a blank node if at least one triple was emitted at the value's level.\n                    if (this.parsingContext.emittedStack[depth + 1]\n                        || (value && typeof value === 'object' && Object.keys(value).length === 0)) {\n                        return (this.parsingContext.idStack[depth + 1]\n                            || (this.parsingContext.idStack[depth + 1] = [this.dataFactory.blankNode()]));\n                    }\n                    else {\n                        return [];\n                    }\n                }\n            case 'string':\n                return this.nullableTermToArray(this.stringValueToTerm(depth, await this.getContextSelfOrPropertyScoped(context, key), key, value, null));\n            case 'boolean':\n                return this.nullableTermToArray(this.stringValueToTerm(depth, await this.getContextSelfOrPropertyScoped(context, key), key, Boolean(value).toString(), this.dataFactory.namedNode(Util.XSD_BOOLEAN)));\n            case 'number':\n                return this.nullableTermToArray(this.stringValueToTerm(depth, await this.getContextSelfOrPropertyScoped(context, key), key, value, this.dataFactory.namedNode(value % 1 === 0 && value < 1e21 ? Util.XSD_INTEGER : Util.XSD_DOUBLE)));\n            default:\n                this.parsingContext.emitError(new Error(`Could not determine the RDF type of a ${type}`));\n                return [];\n        }\n    }\n    /**\n     * If the context defines a property-scoped context for the given key,\n     * that context will be returned.\n     * Otherwise, the given context will be returned as-is.\n     *\n     * This should be used for valueToTerm cases that are not objects.\n     * @param context A context.\n     * @param key A JSON key.\n     */\n    async getContextSelfOrPropertyScoped(context, key) {\n        const contextKeyEntry = context.getContextRaw()[key];\n        if (contextKeyEntry && typeof contextKeyEntry === 'object' && '@context' in contextKeyEntry) {\n            context = await this.parsingContext.parseContext(contextKeyEntry, context.getContextRaw(), true);\n        }\n        return context;\n    }\n    /**\n     * If the given term is null, return an empty array, otherwise return an array with the single given term.\n     * @param term A term.\n     */\n    nullableTermToArray(term) {\n        return term ? [term] : [];\n    }\n    /**\n     * Convert a given JSON key to an RDF predicate term,\n     * based on @vocab.\n     * @param {JsonLdContextNormalized} context A JSON-LD context.\n     * @param key A JSON key.\n     * @return {RDF.NamedNode} An RDF named node.\n     */\n    predicateToTerm(context, key) {\n        const expanded = context.expandTerm(key, true, this.parsingContext.getExpandOptions());\n        // Immediately return if the predicate was disabled in the context\n        if (!expanded) {\n            return null;\n        }\n        // Check if the predicate is a blank node\n        if (expanded[0] === '_' && expanded[1] === ':') {\n            if (this.parsingContext.produceGeneralizedRdf) {\n                return this.dataFactory.blankNode(expanded.substr(2));\n            }\n            else {\n                return null;\n            }\n        }\n        // Check if the predicate is a valid IRI\n        if (Util.isValidIri(expanded)) {\n            return this.dataFactory.namedNode(expanded);\n        }\n        else {\n            if (expanded && this.parsingContext.strictValues) {\n                this.parsingContext.emitError(new jsonld_context_parser_1.ErrorCoded(`Invalid predicate IRI: ${expanded}`, jsonld_context_parser_1.ERROR_CODES.INVALID_IRI_MAPPING));\n            }\n            else {\n                return null;\n            }\n        }\n        return null;\n    }\n    /**\n     * Convert a given JSON key to an RDF resource term or blank node,\n     * based on @base.\n     * @param {JsonLdContextNormalized} context A JSON-LD context.\n     * @param key A JSON key.\n     * @return {RDF.NamedNode} An RDF named node or null.\n     */\n    resourceToTerm(context, key) {\n        if (key.startsWith('_:')) {\n            return this.dataFactory.blankNode(key.substr(2));\n        }\n        const iri = context.expandTerm(key, false, this.parsingContext.getExpandOptions());\n        if (!Util.isValidIri(iri)) {\n            if (iri && this.parsingContext.strictValues) {\n                this.parsingContext.emitError(new Error(`Invalid resource IRI: ${iri}`));\n            }\n            else {\n                return null;\n            }\n        }\n        return this.dataFactory.namedNode(iri);\n    }\n    /**\n     * Convert a given JSON key to an RDF resource term.\n     * It will do this based on the @vocab,\n     * and fallback to @base.\n     * @param {JsonLdContextNormalized} context A JSON-LD context.\n     * @param key A JSON key.\n     * @return {RDF.NamedNode} An RDF named node or null.\n     */\n    createVocabOrBaseTerm(context, key) {\n        if (key.startsWith('_:')) {\n            return this.dataFactory.blankNode(key.substr(2));\n        }\n        const expandOptions = this.parsingContext.getExpandOptions();\n        let expanded = context.expandTerm(key, true, expandOptions);\n        if (expanded === key) {\n            expanded = context.expandTerm(key, false, expandOptions);\n        }\n        if (!Util.isValidIri(expanded)) {\n            if (expanded && this.parsingContext.strictValues && !expanded.startsWith('@')) {\n                this.parsingContext.emitError(new Error(`Invalid term IRI: ${expanded}`));\n            }\n            else {\n                return null;\n            }\n        }\n        return this.dataFactory.namedNode(expanded);\n    }\n    /**\n     * Ensure that the given value becomes a string.\n     * @param {string | number} value A string or number.\n     * @param {NamedNode} datatype The intended datatype.\n     * @return {string} The returned string.\n     */\n    intToString(value, datatype) {\n        if (typeof value === 'number') {\n            if (Number.isFinite(value)) {\n                const isInteger = value % 1 === 0;\n                if (isInteger && (!datatype || datatype.value !== Util.XSD_DOUBLE)) {\n                    return Number(value).toString();\n                }\n                else {\n                    return value.toExponential(15).replace(/(\\d)0*e\\+?/, '$1E');\n                }\n            }\n            else {\n                return value > 0 ? 'INF' : '-INF';\n            }\n        }\n        else {\n            return value;\n        }\n    }\n    /**\n     * Convert a given JSON string value to an RDF term.\n     * @param {number} depth The current stack depth.\n     * @param {JsonLdContextNormalized} context A JSON-LD context.\n     * @param {string} key The current JSON key.\n     * @param {string} value A JSON value.\n     * @param {NamedNode} defaultDatatype The default datatype for the given value.\n     * @return {RDF.Term} An RDF term or null.\n     */\n    stringValueToTerm(depth, context, key, value, defaultDatatype) {\n        // Check the datatype from the context\n        const contextType = Util.getContextValueType(context, key);\n        if (contextType) {\n            if (contextType === '@id') {\n                if (!defaultDatatype) {\n                    return this.resourceToTerm(context, this.intToString(value, defaultDatatype));\n                }\n            }\n            else if (contextType === '@vocab') {\n                if (!defaultDatatype) {\n                    return this.createVocabOrBaseTerm(context, this.intToString(value, defaultDatatype));\n                }\n            }\n            else {\n                defaultDatatype = this.dataFactory.namedNode(contextType);\n            }\n        }\n        // If we don't find such a datatype, check the language from the context\n        if (!defaultDatatype) {\n            const contextLanguage = Util.getContextValueLanguage(context, key);\n            const contextDirection = Util.getContextValueDirection(context, key);\n            if (contextDirection) {\n                return this.createLanguageDirectionLiteral(depth, this.intToString(value, defaultDatatype), contextLanguage, contextDirection);\n            }\n            else {\n                return this.dataFactory.literal(this.intToString(value, defaultDatatype), contextLanguage);\n            }\n        }\n        // If all else fails, make a literal based on the default content type\n        return this.dataFactory.literal(this.intToString(value, defaultDatatype), defaultDatatype);\n    }\n    /**\n     * Create a literal for the given value with the given language and direction.\n     * Auxiliary quads may be emitted.\n     * @param {number} depth The current stack depth.\n     * @param {string} value A string value.\n     * @param {string} language A language tag.\n     * @param {string} direction A direction.\n     * @return {Term} An RDF term.\n     */\n    createLanguageDirectionLiteral(depth, value, language, direction) {\n        if (this.parsingContext.rdfDirection === 'i18n-datatype') {\n            // Create a datatyped literal, by encoding the language and direction into https://www.w3.org/ns/i18n#.\n            if (!language) {\n                language = '';\n            }\n            return this.dataFactory.literal(value, this.dataFactory.namedNode(`https://www.w3.org/ns/i18n#${language}_${direction}`));\n        }\n        else if (this.parsingContext.rdfDirection === 'compound-literal') {\n            // Reify the literal.\n            const valueNode = this.dataFactory.blankNode();\n            const graph = this.getDefaultGraph();\n            this.parsingContext.emitQuad(depth, this.dataFactory.quad(valueNode, this.dataFactory.namedNode(Util.RDF + 'value'), this.dataFactory.literal(value), graph));\n            if (language) {\n                this.parsingContext.emitQuad(depth, this.dataFactory.quad(valueNode, this.dataFactory.namedNode(Util.RDF + 'language'), this.dataFactory.literal(language), graph));\n            }\n            this.parsingContext.emitQuad(depth, this.dataFactory.quad(valueNode, this.dataFactory.namedNode(Util.RDF + 'direction'), this.dataFactory.literal(direction), graph));\n            return valueNode;\n        }\n        else {\n            return this.dataFactory.literal(value, { language: language || '', direction: direction });\n        }\n    }\n    /**\n     * Stringify the given JSON object to a canonical JSON string.\n     * @param value Any valid JSON value.\n     * @return {string} A canonical JSON string.\n     */\n    valueToJsonString(value) {\n        return canonicalizeJson(value);\n    }\n    /**\n     * If the key is not a keyword, try to check if it is an alias for a keyword,\n     * and if so, un-alias it.\n     * @param {string} key A key, can be falsy.\n     * @param {string[]} keys The path of keys.\n     * @param {number} depth The depth to\n     * @param {boolean} disableCache If the cache should be disabled\n     * @param {JsonLdContextNormalized} context A context to unalias with,\n     *                                           will fallback to retrieving the context for the given keys.\n     * @return {Promise<string>} A promise resolving to the key itself, or another key.\n     */\n    async unaliasKeyword(key, keys, depth, disableCache, context) {\n        // Numbers can not be an alias\n        if (Number.isInteger(key)) {\n            return key;\n        }\n        // Try to grab from cache if it was already un-aliased before.\n        if (!disableCache) {\n            const cachedUnaliasedKeyword = this.parsingContext.unaliasedKeywordCacheStack[depth];\n            if (cachedUnaliasedKeyword) {\n                return cachedUnaliasedKeyword;\n            }\n        }\n        if (!jsonld_context_parser_1.Util.isPotentialKeyword(key)) {\n            context = context || await this.parsingContext.getContext(keys);\n            let unliased = context.getContextRaw()[key];\n            if (unliased && typeof unliased === 'object') {\n                unliased = unliased['@id'];\n            }\n            if (jsonld_context_parser_1.Util.isValidKeyword(unliased)) {\n                key = unliased;\n            }\n        }\n        return disableCache ? key : (this.parsingContext.unaliasedKeywordCacheStack[depth] = key);\n    }\n    /**\n     * Unalias the keyword of the parent.\n     * This adds a safety check if no parent exist.\n     * @param {any[]} keys A stack of keys.\n     * @param {number} depth The current depth.\n     * @return {Promise<any>} A promise resolving to the parent key, or another key.\n     */\n    async unaliasKeywordParent(keys, depth) {\n        return await this.unaliasKeyword(depth > 0 && keys[depth - 1], keys, depth - 1);\n    }\n    /**\n     * Un-alias all keywords in the given hash.\n     * @param {{[p: string]: any}} hash A hash object.\n     * @param {string[]} keys The path of keys.\n     * @param {number} depth The depth.\n     * @param {JsonLdContextNormalized} context A context to unalias with,\n     *                                           will fallback to retrieving the context for the given keys.\n     * @return {Promise<{[p: string]: any}>} A promise resolving to the new hash.\n     */\n    async unaliasKeywords(hash, keys, depth, context) {\n        const newHash = {};\n        for (const key in hash) {\n            newHash[await this.unaliasKeyword(key, keys, depth + 1, true, context)] = hash[key];\n        }\n        return newHash;\n    }\n    /**\n     * Check if we are processing a literal (including JSON literals) at the given depth.\n     * This will also check higher levels,\n     * because if a parent is a literal,\n     * then the deeper levels are definitely a literal as well.\n     * @param {any[]} keys The keys.\n     * @param {number} depth The depth.\n     * @return {boolean} If we are processing a literal.\n     */\n    async isLiteral(keys, depth) {\n        for (let i = depth; i >= 0; i--) {\n            if (await this.unaliasKeyword(keys[i], keys, i) === '@annotation') {\n                // Literals may have annotations, which require processing of inner nodes.\n                return false;\n            }\n            if (this.parsingContext.literalStack[i] || this.parsingContext.jsonLiteralStack[i]) {\n                return true;\n            }\n        }\n        return false;\n    }\n    /**\n     * Check how many parents should be skipped for checking the @graph for the given node.\n     *\n     * @param {number} depth The depth of the node.\n     * @param {any[]} keys An array of keys.\n     * @return {number} The graph depth offset.\n     */\n    async getDepthOffsetGraph(depth, keys) {\n        for (let i = depth - 1; i > 0; i--) {\n            if (await this.unaliasKeyword(keys[i], keys, i) === '@graph') {\n                // Skip further processing if we are already in an @graph-@id or @graph-@index container\n                const containers = (await EntryHandlerContainer_1.EntryHandlerContainer.getContainerHandler(this.parsingContext, keys, i)).containers;\n                if (EntryHandlerContainer_1.EntryHandlerContainer.isComplexGraphContainer(containers)) {\n                    return -1;\n                }\n                return depth - i - 1;\n            }\n        }\n        return -1;\n    }\n    /**\n     * Check if the given subject is of a valid type.\n     * This should be called when applying @reverse'd properties.\n     * @param {Term} subject A subject.\n     */\n    validateReverseSubject(subject) {\n        if (subject.termType === 'Literal') {\n            throw new jsonld_context_parser_1.ErrorCoded(`Found illegal literal in subject position: ${subject.value}`, jsonld_context_parser_1.ERROR_CODES.INVALID_REVERSE_PROPERTY_VALUE);\n        }\n    }\n    /**\n     * Get the default graph.\n     * @return {Term} An RDF term.\n     */\n    getDefaultGraph() {\n        return this.parsingContext.defaultGraph || this.dataFactory.defaultGraph();\n    }\n    /**\n     * Get the current graph, while taking into account a graph that can be defined via @container: @graph.\n     * If not within a graph container, the default graph will be returned.\n     * @param keys The current keys.\n     * @param depth The current depth.\n     */\n    async getGraphContainerValue(keys, depth) {\n        // Default to default graph\n        let graph = this.getDefaultGraph();\n        // Check if we are in an @container: @graph.\n        const { containers, depth: depthContainer } = await EntryHandlerContainer_1.EntryHandlerContainer\n            .getContainerHandler(this.parsingContext, keys, depth);\n        if ('@graph' in containers) {\n            // Get the graph from the stack.\n            const graphContainerIndex = EntryHandlerContainer_1.EntryHandlerContainer.getContainerGraphIndex(containers, depthContainer, keys);\n            const entry = this.parsingContext.graphContainerTermStack[depthContainer];\n            graph = entry ? entry[graphContainerIndex] : null;\n            // Set the graph in the stack if none has been set yet.\n            if (!graph) {\n                let graphId = null;\n                if ('@id' in containers) {\n                    const keyUnaliased = await this.getContainerKey(keys[depthContainer], keys, depthContainer);\n                    if (keyUnaliased !== null) {\n                        graphId = await this.resourceToTerm(await this.parsingContext.getContext(keys), keyUnaliased);\n                    }\n                }\n                if (!graphId) {\n                    graphId = this.dataFactory.blankNode();\n                }\n                if (!this.parsingContext.graphContainerTermStack[depthContainer]) {\n                    this.parsingContext.graphContainerTermStack[depthContainer] = {};\n                }\n                graph = this.parsingContext.graphContainerTermStack[depthContainer][graphContainerIndex] = graphId;\n            }\n        }\n        return graph;\n    }\n    /**\n     * Get the properties depth for retrieving properties.\n     *\n     * Typically, the properties depth will be identical to the given depth.\n     *\n     * The following exceptions apply:\n     * * When the parent is @reverse, the depth is decremented by one.\n     * * When @nest parents are found, the depth is decremented by the number of @nest parents.\n     * If in combination with the exceptions above an intermediary array is discovered,\n     * the depth is also decremented by this number of arrays.\n     *\n     * @param keys The current key chain.\n     * @param depth The current depth.\n     */\n    async getPropertiesDepth(keys, depth) {\n        let lastValidDepth = depth;\n        for (let i = depth - 1; i > 0; i--) {\n            if (typeof keys[i] !== 'number') { // Skip array keys\n                const parentKey = await this.unaliasKeyword(keys[i], keys, i);\n                if (parentKey === '@reverse') {\n                    return i;\n                }\n                else if (parentKey === '@nest') {\n                    lastValidDepth = i;\n                }\n                else {\n                    return lastValidDepth;\n                }\n            }\n        }\n        return lastValidDepth;\n    }\n    /**\n     * Get the key for the current container entry.\n     * @param key A key, can be falsy.\n     * @param keys The key chain.\n     * @param depth The current depth to get the key from.\n     * @return Promise resolving to the key.\n     *         Null will be returned for @none entries, with aliasing taken into account.\n     */\n    async getContainerKey(key, keys, depth) {\n        const keyUnaliased = await this.unaliasKeyword(key, keys, depth);\n        return keyUnaliased === '@none' ? null : keyUnaliased;\n    }\n    /**\n     * Check if no reverse properties are present in embedded nodes.\n     * @param key The current key.\n     * @param reverse If a reverse property is active.\n     * @param isEmbedded If we're in an embedded node.\n     */\n    validateReverseInEmbeddedNode(key, reverse, isEmbedded) {\n        if (isEmbedded && reverse && !this.parsingContext.rdfstarReverseInEmbedded) {\n            throw new jsonld_context_parser_1.ErrorCoded(`Illegal reverse property in embedded node in ${key}`, jsonld_context_parser_1.ERROR_CODES.INVALID_EMBEDDED_NODE);\n        }\n    }\n    /**\n     * Emit a quad, with checks.\n     * @param depth The current depth.\n     * @param subject S\n     * @param predicate P\n     * @param object O\n     * @param graph G\n     * @param reverse If a reverse property is active.\n     * @param isEmbedded If we're in an embedded node.\n     */\n    emitQuadChecked(depth, subject, predicate, object, graph, reverse, isEmbedded) {\n        // Create a quad\n        let quad;\n        if (reverse) {\n            this.validateReverseSubject(object);\n            quad = this.dataFactory.quad(object, predicate, subject, graph);\n        }\n        else {\n            quad = this.dataFactory.quad(subject, predicate, object, graph);\n        }\n        // Emit the quad, unless it was created in an embedded node\n        if (isEmbedded) {\n            // Embedded nodes don't inherit the active graph\n            if (quad.graph.termType !== 'DefaultGraph') {\n                quad = this.dataFactory.quad(quad.subject, quad.predicate, quad.object);\n            }\n            // Multiple embedded nodes are not allowed\n            if (this.parsingContext.idStack[depth - 1]) {\n                throw new jsonld_context_parser_1.ErrorCoded(`Illegal multiple properties in an embedded node`, jsonld_context_parser_1.ERROR_CODES.INVALID_EMBEDDED_NODE);\n            }\n            this.parsingContext.idStack[depth - 1] = [quad];\n        }\n        else {\n            this.parsingContext.emitQuad(depth, quad);\n        }\n        // Flush annotations\n        const annotationsBuffer = this.parsingContext.annotationsBuffer[depth];\n        if (annotationsBuffer) {\n            for (const annotation of annotationsBuffer) {\n                this.emitAnnotation(depth, quad, annotation);\n            }\n            delete this.parsingContext.annotationsBuffer[depth];\n        }\n    }\n    // This is a separate function to enable recursion\n    emitAnnotation(depth, quad, annotation) {\n        // Construct annotation quad\n        let annotationQuad;\n        if (annotation.reverse) {\n            this.validateReverseSubject(annotation.object);\n            annotationQuad = this.dataFactory.quad(annotation.object, annotation.predicate, quad);\n        }\n        else {\n            annotationQuad = this.dataFactory.quad(quad, annotation.predicate, annotation.object);\n        }\n        // Emit annotated quad\n        this.parsingContext.emitQuad(depth, annotationQuad);\n        // Also emit nested annotations\n        for (const nestedAnnotation of annotation.nestedAnnotations) {\n            this.emitAnnotation(depth, annotationQuad, nestedAnnotation);\n        }\n    }\n}\nexports.Util = Util;\nUtil.XSD = 'http://www.w3.org/2001/XMLSchema#';\nUtil.XSD_BOOLEAN = Util.XSD + 'boolean';\nUtil.XSD_INTEGER = Util.XSD + 'integer';\nUtil.XSD_DOUBLE = Util.XSD + 'double';\nUtil.RDF = 'http://www.w3.org/1999/02/22-rdf-syntax-ns#';\n//# sourceMappingURL=Util.js.map","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.EntryHandlerPredicate = void 0;\nconst jsonld_context_parser_1 = require(\"jsonld-context-parser\");\nconst Util_1 = require(\"../Util\");\n/**\n * Interprets keys as predicates.\n * The most common case in JSON-LD processing.\n */\nclass EntryHandlerPredicate {\n    /**\n     * Handle the given predicate-object by either emitting it,\n     * or by placing it in the appropriate stack for later emission when no @graph and/or @id has been defined.\n     * @param {ParsingContext} parsingContext A parsing context.\n     * @param {Util} util A utility instance.\n     * @param {any[]} keys A stack of keys.\n     * @param {number} depth The current depth.\n     * @param {Term} predicate The predicate.\n     * @param {Term} object The object.\n     * @param {boolean} reverse If the property is reversed.\n     * @param {boolean} isEmbedded If the property exists in an embedded node as direct child.\n     * @param {boolean} isAnnotation If the property exists in an annotation object.\n     * @return {Promise<void>} A promise resolving when handling is done.\n     */\n    static async handlePredicateObject(parsingContext, util, keys, depth, predicate, object, reverse, isEmbedded, isAnnotation) {\n        const depthProperties = await util.getPropertiesDepth(keys, depth);\n        const depthOffsetGraph = await util.getDepthOffsetGraph(depth, keys);\n        const depthPropertiesGraph = depth - depthOffsetGraph;\n        const subjects = parsingContext.idStack[depthProperties];\n        if (subjects && !isAnnotation) {\n            // Emit directly if the @id was already defined\n            for (const subject of subjects) {\n                // Check if we're in a @graph context\n                const atGraph = depthOffsetGraph >= 0;\n                if (atGraph) {\n                    const graphs = parsingContext.idStack[depthPropertiesGraph - 1];\n                    if (graphs) {\n                        for (const graph of graphs) {\n                            // Emit our quad if graph @id is known\n                            util.emitQuadChecked(depth, subject, predicate, object, graph, reverse, isEmbedded);\n                        }\n                    }\n                    else {\n                        // Buffer our triple if graph @id is not known yet.\n                        if (reverse) {\n                            util.validateReverseSubject(object);\n                            parsingContext.getUnidentifiedGraphBufferSafe(depthPropertiesGraph - 1).push({ subject: object, predicate, object: subject, isEmbedded });\n                        }\n                        else {\n                            parsingContext.getUnidentifiedGraphBufferSafe(depthPropertiesGraph - 1)\n                                .push({ subject, predicate, object, isEmbedded });\n                        }\n                    }\n                }\n                else {\n                    // Emit if no @graph was applicable\n                    const graph = await util.getGraphContainerValue(keys, depthProperties);\n                    util.emitQuadChecked(depth, subject, predicate, object, graph, reverse, isEmbedded);\n                }\n            }\n        }\n        else {\n            // Buffer until our @id becomes known, or we go up the stack\n            if (reverse) {\n                util.validateReverseSubject(object);\n            }\n            // Either push to the annotations or the actual value buffer\n            if (isAnnotation) {\n                // Only add to buffer if rdfstar is enabled\n                if (parsingContext.rdfstar) {\n                    // Error if an @id was defined\n                    if (parsingContext.idStack[depth]) {\n                        parsingContext.emitError(new jsonld_context_parser_1.ErrorCoded(`Found an illegal @id inside an annotation: ${parsingContext.idStack[depth][0].value}`, jsonld_context_parser_1.ERROR_CODES.INVALID_ANNOTATION));\n                    }\n                    // Error if we're in an embedded node\n                    for (let i = 0; i < depth; i++) {\n                        if (await util.unaliasKeyword(keys[i], keys, i) === '@id') {\n                            parsingContext.emitError(new jsonld_context_parser_1.ErrorCoded(`Found an illegal annotation inside an embedded node`, jsonld_context_parser_1.ERROR_CODES.INVALID_ANNOTATION));\n                        }\n                    }\n                    // Store new annotation in the buffer\n                    const annotationsBuffer = parsingContext.getAnnotationsBufferSafe(depthProperties);\n                    const newAnnotation = { predicate, object, reverse, nestedAnnotations: [], depth: depthProperties };\n                    annotationsBuffer.push(newAnnotation);\n                    // Check in the buffer if any annotations were defined at a deeper depth,\n                    // if so, they are considered nested annotations.\n                    for (let i = annotationsBuffer.length - 2; i >= 0; i--) {\n                        // We iterate in reverse order, to enable easy item removal from the back.\n                        const existingAnnotation = annotationsBuffer[i];\n                        if (existingAnnotation.depth > depthProperties) {\n                            newAnnotation.nestedAnnotations.push(existingAnnotation);\n                            annotationsBuffer.splice(i, 1);\n                        }\n                    }\n                }\n            }\n            else {\n                parsingContext.getUnidentifiedValueBufferSafe(depthProperties).push({ predicate, object, reverse, isEmbedded });\n            }\n        }\n    }\n    isPropertyHandler() {\n        return true;\n    }\n    isStackProcessor() {\n        return true;\n    }\n    async validate(parsingContext, util, keys, depth, inProperty) {\n        const key = keys[depth];\n        if (key) {\n            const context = await parsingContext.getContext(keys);\n            if (!parsingContext.jsonLiteralStack[depth] && await util.predicateToTerm(context, keys[depth])) {\n                // If this valid predicate is of type @json, mark it so in the stack so that no deeper handling of nodes occurs.\n                if (Util_1.Util.getContextValueType(context, key) === '@json') {\n                    parsingContext.jsonLiteralStack[depth + 1] = true;\n                }\n                return true;\n            }\n        }\n        return false;\n    }\n    async test(parsingContext, util, key, keys, depth) {\n        return keys[depth];\n    }\n    async handle(parsingContext, util, key, keys, value, depth, testResult) {\n        const keyOriginal = keys[depth];\n        const context = await parsingContext.getContext(keys);\n        const predicate = await util.predicateToTerm(context, key);\n        if (predicate) {\n            const objects = await util.valueToTerm(context, key, value, depth, keys);\n            if (objects.length) {\n                for (let object of objects) {\n                    // Based on parent key, check if reverse, embedded, and annotation.\n                    let parentKey = await util.unaliasKeywordParent(keys, depth);\n                    const reverse = Util_1.Util.isPropertyReverse(context, keyOriginal, parentKey);\n                    let parentDepthOffset = 0;\n                    while (parentKey === '@reverse' || typeof parentKey === 'number') {\n                        // Check parent of parent when checking while we're in an array or in @reverse\n                        if (typeof parentKey === 'number') {\n                            parentDepthOffset++;\n                        }\n                        else {\n                            depth--;\n                        }\n                        parentKey = await util.unaliasKeywordParent(keys, depth - parentDepthOffset);\n                    }\n                    const isEmbedded = Util_1.Util.isPropertyInEmbeddedNode(parentKey);\n                    util.validateReverseInEmbeddedNode(key, reverse, isEmbedded);\n                    const isAnnotation = Util_1.Util.isPropertyInAnnotationObject(parentKey);\n                    if (value) {\n                        // Special case if our term was defined as an @list, but does not occur in an array,\n                        // In that case we just emit it as an RDF list with a single element.\n                        const listValueContainer = '@list' in Util_1.Util.getContextValueContainer(context, key);\n                        if (listValueContainer || value['@list']) {\n                            if (((listValueContainer && !Array.isArray(value) && !value['@list'])\n                                || (value['@list'] && !Array.isArray(value['@list'])))\n                                && object !== util.rdfNil) {\n                                const listPointer = util.dataFactory.blankNode();\n                                parsingContext.emitQuad(depth, util.dataFactory.quad(listPointer, util.rdfRest, util.rdfNil, util.getDefaultGraph()));\n                                parsingContext.emitQuad(depth, util.dataFactory.quad(listPointer, util.rdfFirst, object, util.getDefaultGraph()));\n                                object = listPointer;\n                            }\n                            // Lists are not allowed in @reverse'd properties\n                            if (reverse && !parsingContext.allowSubjectList) {\n                                throw new jsonld_context_parser_1.ErrorCoded(`Found illegal list value in subject position at ${key}`, jsonld_context_parser_1.ERROR_CODES.INVALID_REVERSE_PROPERTY_VALUE);\n                            }\n                        }\n                    }\n                    await EntryHandlerPredicate.handlePredicateObject(parsingContext, util, keys, depth, predicate, object, reverse, isEmbedded, isAnnotation);\n                }\n            }\n        }\n    }\n}\nexports.EntryHandlerPredicate = EntryHandlerPredicate;\n//# sourceMappingURL=EntryHandlerPredicate.js.map","\"use strict\";\n// tslint:disable:max-line-length\nObject.defineProperty(exports, \"__esModule\", { value: true });\n//# sourceMappingURL=JsonLdContext.js.map","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.EntryHandlerKeywordId = void 0;\nconst jsonld_context_parser_1 = require(\"jsonld-context-parser\");\nconst EntryHandlerKeyword_1 = require(\"./EntryHandlerKeyword\");\n/**\n * Handles @id entries.\n */\nclass EntryHandlerKeywordId extends EntryHandlerKeyword_1.EntryHandlerKeyword {\n    constructor() {\n        super('@id');\n    }\n    isStackProcessor() {\n        return false;\n    }\n    async handle(parsingContext, util, key, keys, value, depth) {\n        if (typeof value !== 'string') {\n            // JSON-LD-star allows @id object values\n            if (parsingContext.rdfstar && typeof value === 'object') {\n                const valueKeys = Object.keys(value);\n                if (valueKeys.length === 1 && valueKeys[0] === '@id') {\n                    parsingContext.emitError(new jsonld_context_parser_1.ErrorCoded(`Invalid embedded node without property with @id ${value['@id']}`, jsonld_context_parser_1.ERROR_CODES.INVALID_EMBEDDED_NODE));\n                }\n            }\n            else {\n                parsingContext.emitError(new jsonld_context_parser_1.ErrorCoded(`Found illegal @id '${value}'`, jsonld_context_parser_1.ERROR_CODES.INVALID_ID_VALUE));\n            }\n            return;\n        }\n        // Determine the canonical place for this id.\n        // For example, @nest parents should be ignored.\n        const depthProperties = await util.getPropertiesDepth(keys, depth);\n        // Error if an @id for this node already existed.\n        if (parsingContext.idStack[depthProperties] !== undefined) {\n            if (parsingContext.idStack[depthProperties][0].listHead) {\n                // Error if an @list was already defined for this node\n                parsingContext.emitError(new jsonld_context_parser_1.ErrorCoded(`Found illegal neighbouring entries next to @list for key: '${keys[depth - 1]}'`, jsonld_context_parser_1.ERROR_CODES.INVALID_SET_OR_LIST_OBJECT));\n            }\n            else {\n                // Otherwise, the previous id was just because of an @id entry.\n                parsingContext.emitError(new jsonld_context_parser_1.ErrorCoded(`Found duplicate @ids '${parsingContext\n                    .idStack[depthProperties][0].value}' and '${value}'`, jsonld_context_parser_1.ERROR_CODES.COLLIDING_KEYWORDS));\n            }\n        }\n        // Error if an annotation was defined\n        if (parsingContext.rdfstar && parsingContext.annotationsBuffer[depth]) {\n            for (const annotation of parsingContext.annotationsBuffer[depth]) {\n                if (annotation.depth === depth) {\n                    parsingContext.emitError(new jsonld_context_parser_1.ErrorCoded(`Found an illegal @id inside an annotation: ${value}`, jsonld_context_parser_1.ERROR_CODES.INVALID_ANNOTATION));\n                }\n            }\n        }\n        // Save our @id on the stack\n        parsingContext.idStack[depthProperties] = util.nullableTermToArray(await util.resourceToTerm(await parsingContext.getContext(keys), value));\n    }\n}\nexports.EntryHandlerKeywordId = EntryHandlerKeywordId;\n//# sourceMappingURL=EntryHandlerKeywordId.js.map","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.ContainerHandlerLanguage = void 0;\nconst jsonld_context_parser_1 = require(\"jsonld-context-parser\");\n/**\n * Container handler for @language.\n *\n * It assumes that the current key is the language of the current value.\n * This will add this value to the parent node.\n */\nclass ContainerHandlerLanguage {\n    canCombineWithGraph() {\n        return false;\n    }\n    async handle(containers, parsingContext, util, keys, value, depth) {\n        const language = await util.getContainerKey(keys[depth], keys, depth);\n        if (Array.isArray(value)) {\n            // No type-checking needed, will be handled on each value when this handler is called recursively.\n            value = value.map((subValue) => ({ '@value': subValue, '@language': language }));\n        }\n        else {\n            if (typeof value !== 'string') {\n                throw new jsonld_context_parser_1.ErrorCoded(`Got invalid language map value, got '${JSON.stringify(value)}', but expected string`, jsonld_context_parser_1.ERROR_CODES.INVALID_LANGUAGE_MAP_VALUE);\n            }\n            value = { '@value': value, '@language': language };\n        }\n        await parsingContext.newOnValueJob(keys.slice(0, keys.length - 1), value, depth - 1, true);\n        parsingContext.emittedStack[depth] = false; // We have emitted a level higher\n    }\n}\nexports.ContainerHandlerLanguage = ContainerHandlerLanguage;\n//# sourceMappingURL=ContainerHandlerLanguage.js.map","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.EntryHandlerKeywordValue = void 0;\nconst EntryHandlerKeyword_1 = require(\"./EntryHandlerKeyword\");\n/**\n * Handles @value entries.\n */\nclass EntryHandlerKeywordValue extends EntryHandlerKeyword_1.EntryHandlerKeyword {\n    constructor() {\n        super('@value');\n    }\n    async validate(parsingContext, util, keys, depth, inProperty) {\n        // If this is @value, mark it so in the stack so that no deeper handling of nodes occurs.\n        const key = keys[depth];\n        if (key && !parsingContext.literalStack[depth] && await this.test(parsingContext, util, key, keys, depth)) {\n            parsingContext.literalStack[depth] = true;\n        }\n        return super.validate(parsingContext, util, keys, depth, inProperty);\n    }\n    async test(parsingContext, util, key, keys, depth) {\n        return await util.unaliasKeyword(keys[depth], keys.slice(0, keys.length - 1), depth - 1, true) === '@value';\n    }\n    async handle(parsingContext, util, key, keys, value, depth) {\n        // If the value is valid, indicate that we are processing a literal.\n        // The actual value will be determined at the parent level when the @value is part of an object,\n        // because we may want to take into account additional entries such as @language.\n        // See {@link Util.valueToTerm}\n        // Indicate that we are processing a literal, and that no later predicates should be parsed at this depth.\n        parsingContext.literalStack[depth] = true;\n        // Void any buffers that we may have accumulated up until now\n        delete parsingContext.unidentifiedValuesBuffer[depth];\n        delete parsingContext.unidentifiedGraphsBuffer[depth];\n        // Indicate that we have not emitted at this depth\n        parsingContext.emittedStack[depth] = false;\n    }\n}\nexports.EntryHandlerKeywordValue = EntryHandlerKeywordValue;\n//# sourceMappingURL=EntryHandlerKeywordValue.js.map","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.ERROR_CODES = exports.ErrorCoded = void 0;\n/**\n * An error that has a certain error code.\n *\n * The error code can be any string.\n * All standardized error codes are listed in {@link ERROR_CODES}.\n */\nclass ErrorCoded extends Error {\n    /* istanbul ignore next */\n    constructor(message, code) {\n        super(message);\n        this.code = code;\n    }\n}\nexports.ErrorCoded = ErrorCoded;\n/**\n * All standardized JSON-LD error codes.\n * @see https://w3c.github.io/json-ld-api/#dom-jsonlderrorcode\n */\n// tslint:disable:object-literal-sort-keys\nvar ERROR_CODES;\n(function (ERROR_CODES) {\n    ERROR_CODES[\"COLLIDING_KEYWORDS\"] = \"colliding keywords\";\n    ERROR_CODES[\"CONFLICTING_INDEXES\"] = \"conflicting indexes\";\n    ERROR_CODES[\"CYCLIC_IRI_MAPPING\"] = \"cyclic IRI mapping\";\n    ERROR_CODES[\"INVALID_ID_VALUE\"] = \"invalid @id value\";\n    ERROR_CODES[\"INVALID_INDEX_VALUE\"] = \"invalid @index value\";\n    ERROR_CODES[\"INVALID_NEST_VALUE\"] = \"invalid @nest value\";\n    ERROR_CODES[\"INVALID_PREFIX_VALUE\"] = \"invalid @prefix value\";\n    ERROR_CODES[\"INVALID_PROPAGATE_VALUE\"] = \"invalid @propagate value\";\n    ERROR_CODES[\"INVALID_REVERSE_VALUE\"] = \"invalid @reverse value\";\n    ERROR_CODES[\"INVALID_IMPORT_VALUE\"] = \"invalid @import value\";\n    ERROR_CODES[\"INVALID_VERSION_VALUE\"] = \"invalid @version value\";\n    ERROR_CODES[\"INVALID_BASE_IRI\"] = \"invalid base IRI\";\n    ERROR_CODES[\"INVALID_CONTAINER_MAPPING\"] = \"invalid container mapping\";\n    ERROR_CODES[\"INVALID_CONTEXT_ENTRY\"] = \"invalid context entry\";\n    ERROR_CODES[\"INVALID_CONTEXT_NULLIFICATION\"] = \"invalid context nullification\";\n    ERROR_CODES[\"INVALID_DEFAULT_LANGUAGE\"] = \"invalid default language\";\n    ERROR_CODES[\"INVALID_INCLUDED_VALUE\"] = \"invalid @included value\";\n    ERROR_CODES[\"INVALID_IRI_MAPPING\"] = \"invalid IRI mapping\";\n    ERROR_CODES[\"INVALID_JSON_LITERAL\"] = \"invalid JSON literal\";\n    ERROR_CODES[\"INVALID_KEYWORD_ALIAS\"] = \"invalid keyword alias\";\n    ERROR_CODES[\"INVALID_LANGUAGE_MAP_VALUE\"] = \"invalid language map value\";\n    ERROR_CODES[\"INVALID_LANGUAGE_MAPPING\"] = \"invalid language mapping\";\n    ERROR_CODES[\"INVALID_LANGUAGE_TAGGED_STRING\"] = \"invalid language-tagged string\";\n    ERROR_CODES[\"INVALID_LANGUAGE_TAGGED_VALUE\"] = \"invalid language-tagged value\";\n    ERROR_CODES[\"INVALID_LOCAL_CONTEXT\"] = \"invalid local context\";\n    ERROR_CODES[\"INVALID_REMOTE_CONTEXT\"] = \"invalid remote context\";\n    ERROR_CODES[\"INVALID_REVERSE_PROPERTY\"] = \"invalid reverse property\";\n    ERROR_CODES[\"INVALID_REVERSE_PROPERTY_MAP\"] = \"invalid reverse property map\";\n    ERROR_CODES[\"INVALID_REVERSE_PROPERTY_VALUE\"] = \"invalid reverse property value\";\n    ERROR_CODES[\"INVALID_SCOPED_CONTEXT\"] = \"invalid scoped context\";\n    ERROR_CODES[\"INVALID_SCRIPT_ELEMENT\"] = \"invalid script element\";\n    ERROR_CODES[\"INVALID_SET_OR_LIST_OBJECT\"] = \"invalid set or list object\";\n    ERROR_CODES[\"INVALID_TERM_DEFINITION\"] = \"invalid term definition\";\n    ERROR_CODES[\"INVALID_TYPE_MAPPING\"] = \"invalid type mapping\";\n    ERROR_CODES[\"INVALID_TYPE_VALUE\"] = \"invalid type value\";\n    ERROR_CODES[\"INVALID_TYPED_VALUE\"] = \"invalid typed value\";\n    ERROR_CODES[\"INVALID_VALUE_OBJECT\"] = \"invalid value object\";\n    ERROR_CODES[\"INVALID_VALUE_OBJECT_VALUE\"] = \"invalid value object value\";\n    ERROR_CODES[\"INVALID_VOCAB_MAPPING\"] = \"invalid vocab mapping\";\n    ERROR_CODES[\"IRI_CONFUSED_WITH_PREFIX\"] = \"IRI confused with prefix\";\n    ERROR_CODES[\"KEYWORD_REDEFINITION\"] = \"keyword redefinition\";\n    ERROR_CODES[\"LOADING_DOCUMENT_FAILED\"] = \"loading document failed\";\n    ERROR_CODES[\"LOADING_REMOTE_CONTEXT_FAILED\"] = \"loading remote context failed\";\n    ERROR_CODES[\"MULTIPLE_CONTEXT_LINK_HEADERS\"] = \"multiple context link headers\";\n    ERROR_CODES[\"PROCESSING_MODE_CONFLICT\"] = \"processing mode conflict\";\n    ERROR_CODES[\"PROTECTED_TERM_REDEFINITION\"] = \"protected term redefinition\";\n    ERROR_CODES[\"CONTEXT_OVERFLOW\"] = \"context overflow\";\n    ERROR_CODES[\"INVALID_BASE_DIRECTION\"] = \"invalid base direction\";\n    ERROR_CODES[\"RECURSIVE_CONTEXT_INCLUSION\"] = \"recursive context inclusion\";\n    ERROR_CODES[\"INVALID_STREAMING_KEY_ORDER\"] = \"invalid streaming key order\";\n    /**\n     * JSON-LD-star\n     */\n    ERROR_CODES[\"INVALID_EMBEDDED_NODE\"] = \"invalid embedded node\";\n    ERROR_CODES[\"INVALID_ANNOTATION\"] = \"invalid annotation\";\n})(ERROR_CODES = exports.ERROR_CODES || (exports.ERROR_CODES = {}));\n//# sourceMappingURL=ErrorCoded.js.map","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.ContainerHandlerType = void 0;\nconst EntryHandlerPredicate_1 = require(\"../entryhandler/EntryHandlerPredicate\");\nconst Util_1 = require(\"../Util\");\n/**\n * Container handler for @type.\n *\n * This will add this entry to the parent node, and use the current key as an rdf:type value.\n */\nclass ContainerHandlerType {\n    canCombineWithGraph() {\n        return false;\n    }\n    async handle(containers, parsingContext, util, keys, value, depth) {\n        if (!Array.isArray(value)) {\n            if (typeof value === 'string') {\n                // Determine the @type of the container\n                const context = await parsingContext.getContext(keys);\n                const containerTypeType = Util_1.Util.getContextValueType(context, keys[depth - 1]);\n                // String values refer to node references\n                const id = containerTypeType === '@vocab'\n                    ? await util.createVocabOrBaseTerm(context, value)\n                    : await util.resourceToTerm(context, value);\n                if (id) {\n                    // Handle the value of this node as @id, which will also cause the predicate from above to be emitted.\n                    const subValue = { '@id': id.termType === 'NamedNode' ? id.value : value };\n                    await parsingContext.newOnValueJob(keys.slice(0, keys.length - 1), subValue, depth - 1, true);\n                    // Set the id in the stack so it can be used for the rdf:type handling later on\n                    parsingContext.idStack[depth + 1] = [id];\n                }\n            }\n            else {\n                // Other values are handled by handling them as a proper job\n                // Check needed for cases where entries don't have an explicit @id\n                const entryHasIdentifier = !!parsingContext.idStack[depth + 1];\n                // Handle the value of this node, which will also cause the predicate from above to be emitted.\n                if (!entryHasIdentifier) {\n                    delete parsingContext.idStack[depth]; // Force new (blank node) identifier\n                }\n                await parsingContext.newOnValueJob(keys.slice(0, keys.length - 1), value, depth - 1, true);\n                if (!entryHasIdentifier) {\n                    parsingContext.idStack[depth + 1] = parsingContext.idStack[depth]; // Copy the id to the child node, for @type\n                }\n            }\n            // Identify the type to emit.\n            const keyOriginal = await util.getContainerKey(keys[depth], keys, depth);\n            const type = keyOriginal !== null\n                ? util.createVocabOrBaseTerm(await parsingContext.getContext(keys), keyOriginal)\n                : null;\n            if (type) {\n                // Push the type to the stack using the rdf:type predicate\n                await EntryHandlerPredicate_1.EntryHandlerPredicate.handlePredicateObject(parsingContext, util, keys, depth + 1, util.rdfType, type, false, false, false);\n            }\n            // Flush any pending flush buffers\n            await parsingContext.handlePendingContainerFlushBuffers();\n        }\n        parsingContext.emittedStack[depth] = false; // Don't emit the predicate owning this container.\n    }\n}\nexports.ContainerHandlerType = ContainerHandlerType;\n//# sourceMappingURL=ContainerHandlerType.js.map","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.EntryHandlerKeywordAnnotation = void 0;\nconst EntryHandlerKeyword_1 = require(\"./EntryHandlerKeyword\");\nconst jsonld_context_parser_1 = require(\"jsonld-context-parser\");\n/**\n * Handles @annotation entries.\n */\nclass EntryHandlerKeywordAnnotation extends EntryHandlerKeyword_1.EntryHandlerKeyword {\n    constructor() {\n        super('@annotation');\n    }\n    async handle(parsingContext, util, key, keys, value, depth) {\n        // Validate value\n        if (typeof value === 'string' || (typeof value === 'object' && value['@value'])) {\n            parsingContext.emitError(new jsonld_context_parser_1.ErrorCoded(`Found illegal annotation value: ${JSON.stringify(value)}`, jsonld_context_parser_1.ERROR_CODES.INVALID_ANNOTATION));\n        }\n        // Rest of the processing is done as regular nodes\n    }\n}\nexports.EntryHandlerKeywordAnnotation = EntryHandlerKeywordAnnotation;\n//# sourceMappingURL=EntryHandlerKeywordAnnotation.js.map","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.EntryHandlerKeywordGraph = void 0;\nconst EntryHandlerKeyword_1 = require(\"./EntryHandlerKeyword\");\n/**\n * Handles @graph entries.\n */\nclass EntryHandlerKeywordGraph extends EntryHandlerKeyword_1.EntryHandlerKeyword {\n    constructor() {\n        super('@graph');\n    }\n    async handle(parsingContext, util, key, keys, value, depth) {\n        // The current identifier identifies a graph for the deeper level.\n        parsingContext.graphStack[depth + 1] = true;\n    }\n}\nexports.EntryHandlerKeywordGraph = EntryHandlerKeywordGraph;\n//# sourceMappingURL=EntryHandlerKeywordGraph.js.map","class Sink {\n  constructor (Impl, options) {\n    this.Impl = Impl\n    this.options = options\n  }\n\n  import (input, options) {\n    const output = new this.Impl(input, { ...this.options, ...options })\n\n    input.on('end', () => {\n      if (!output.readable) {\n        output.emit('end')\n      }\n    })\n\n    input.on('error', err => {\n      output.emit('error', err)\n    })\n\n    return output\n  }\n}\n\nexport default Sink\n","import rdf from '@rdfjs/data-model'\nimport toReadable from 'duplex-to/readable.js'\nimport { JsonLdParser } from 'jsonld-streaming-parser'\nimport { Transform } from 'readable-stream'\n\nconst relativeIriProtocol = 'null:'\n\nfunction termCleanup (factory) {\n  return term => {\n    if (term.termType !== 'NamedNode') {\n      return null\n    }\n\n    if (!term.value.startsWith(relativeIriProtocol)) {\n      return null\n    }\n\n    // remove dummy protocol workaround for relative IRIs\n    return factory.namedNode(term.value.slice(relativeIriProtocol.length))\n  }\n}\n\nfunction quadCleanup (factory) {\n  const cleanup = termCleanup(factory)\n\n  return quad => {\n    const subject = cleanup(quad.subject)\n    const predicate = cleanup(quad.predicate)\n    const object = cleanup(quad.object)\n    const graph = cleanup(quad.graph)\n\n    if (subject || predicate || object || graph) {\n      return factory.quad(\n        subject || quad.subject,\n        predicate || quad.predicate,\n        object || quad.object,\n        graph || quad.graph\n      )\n    }\n\n    return quad\n  }\n}\n\nclass ParserStream {\n  constructor (input, { baseIRI = relativeIriProtocol, context = null, documentLoader, factory = rdf } = {}) {\n    const parser = new JsonLdParser({\n      baseIRI,\n      context,\n      dataFactory: factory,\n      documentLoader,\n      streamingProfile: false\n    })\n\n    input.pipe(parser)\n\n    const cleanup = quadCleanup(factory)\n\n    const transform = new Transform({\n      objectMode: true,\n      transform: (quad, encoding, callback) => {\n        callback(null, cleanup(quad))\n      }\n    })\n\n    parser.on('context', context => {\n      Object.entries(context).forEach(([prefix, iri]) => {\n        transform.emit('prefix', prefix, factory.namedNode(iri))\n      })\n    })\n    parser.on('error', err => transform.destroy(err))\n    parser.pipe(transform)\n\n    return toReadable(transform)\n  }\n}\n\nexport default ParserStream\n","import Sink from '@rdfjs/sink'\nimport ParserStream from './lib/ParserStream.js'\n\nclass Parser extends Sink {\n  constructor (options) {\n    super(ParserStream, options)\n  }\n}\n\nexport default Parser\n"],"names":["COMPATIBLE_ENCODING_PATTERN","WS_TRIM_PATTERN","WS_CHAR_PATTERN","WS_FOLD_PATTERN","DELIMITER_PATTERN","WS_DELIMITER_PATTERN","TOKEN_PATTERN","STATE","IDLE","URI","ATTR","trim","value","replace","hasWhitespace","test","skipWhitespace","offset","needsQuotes","shallowCompareObjects","object1","object2","Object","keys","length","every","key","Link","constructor","this","refs","parse","rel","links","type","toLowerCase","i","push","get","attr","set","link","setUnique","some","ref","has","slice","state","Error","expandRelations","end","indexOf","uri","attrValue","isSingleOccurenceAttr","parseExtendedValue","Array","isArray","toString","reduce","formatAttribute","join","isCompatibleEncoding","isTokenAttr","escapeQuotes","rels","split","map","assign","parts","exec","language","encoding","decodeURIComponent","formatExtendedAttribute","data","toUpperCase","encodedValue","Buffer","isBuffer","encodeURIComponent","item","module","exports","defineProperty","EntryHandlerArrayValue","Util_1","jsonld_context_parser_1","isPropertyHandler","isStackProcessor","validate","parsingContext","util","depth","inProperty","handle","parentKey","unaliasKeywordParent","listRootKey","listRootDepth","keyOption","values","valueToTerm","getContext","object","handleListElement","newOnValueJob","undefined","unaliasKeyword","parentContext","Util","getContextValueContainer","emittedStack","shiftStack","contextTree","removeContext","valueOriginal","listRootKeys","listPointer","listPointerStack","unaliasKeywords","newLinkTerm","dataFactory","blankNode","emitQuad","quad","rdfRest","getDefaultGraph","linkTerm","listId","rdfFirst","rdfNil","rdfstar","annotationsBuffer","emitError","ErrorCoded","ERROR_CODES","INVALID_ANNOTATION","ContextTree","subTrees","head","tail","subTree","subContext","then","context","setContext","path","ContainerHandlerIndex","EntryHandlerPredicate_1","canCombineWithGraph","containers","graphContainer","indexKey","indexPropertyRaw","getContextValueIndex","isPotentialKeyword","INVALID_TERM_DEFINITION","getContextValueType","INVALID_VALUE_OBJECT","id","resourceToTerm","idStack","indexProperty","createVocabOrBaseTerm","indexValues","getContainerKey","graphId","getGraphContainerValue","indexValue","EntryHandlerPredicate","handlePredicateObject","depthOffset","handlePendingContainerFlushBuffers","EntryHandlerKeywordNest","EntryHandlerKeyword_1","EntryHandlerKeyword","super","INVALID_NEST_VALUE","EntryHandlerInvalidFallback","EntryHandlerKeywordContext","streamingProfile","processingStack","processingType","INVALID_STREAMING_KEY_ORDER","parseContext","getContextRaw","emitContext","validateContext","EntryHandlerContainer","ContainerHandlerIdentifier_1","ContainerHandlerIndex_1","ContainerHandlerLanguage_1","ContainerHandlerType_1","isSimpleGraphContainer","isComplexGraphContainer","getContainerGraphIndex","index","getContainerHandler","fallback","checkGraphContainer","containersSelf","getContextValue","containersParent","containerHandleName","CONTAINER_HANDLERS","isBufferableContainerHandler","handler","containerName","testResult","ContainerHandlerIdentifier","ContainerHandlerLanguage","ContainerHandlerType","EntryHandlerKeywordUnknownFallback","keywordType","VALID_KEYWORDS_TYPES","errorCode","strictValues","INVALID_INDEX_VALUE","INVALID_REVERSE_VALUE","keyUnaliased","maybeId","ids","term","equals","EntryHandlerKeywordType","keyOriginal","predicate","rdfType","reverse","isPropertyReverse","isEmbedded","isPropertyInEmbeddedNode","validateReverseInEmbeddedNode","isAnnotation","isPropertyInAnnotationObject","elements","element","INVALID_TYPE_VALUE","scopedContext","Promise","resolve","hasTypedScopedContext","sort","typeContext","c","streamingProfileAllowOutOfOrderPlainType","JsonLdContextNormalized","ContextParser","relative_to_absolute_iri_1","ErrorCoded_1","FetchDocumentLoader_1","JsonLdContextNormalized_1","options","documentLoader","FetchDocumentLoader","documentCache","skipValidation","expandContentTypeToBase","remoteContextsDepthLimit","redirectSchemaOrgHttps","validateLanguage","strictRange","JSON","stringify","REGEX_LANGUAGE_TAG","validateDirection","INVALID_BASE_DIRECTION","REGEX_DIRECTION_TAG","idifyReverseTerms","isValidKeyword","INVALID_IRI_MAPPING","expandPrefixedTerms","contextRaw","EXPAND_KEYS_BLACKLIST","isReservedInternalKeyword","keyValue","ALIAS_DOMAIN_BLACKLIST","KEYWORD_REDEFINITION","ALIAS_RANGE_BLACKLIST","getContextValueId","INVALID_KEYWORD_ALIAS","isPrefixValue","changed","expandTerm","canAddIdEntry","isValidIri","newId","expandedType","normalize","processingMode","normalizeLanguageTags","lowercase","containersToHash","newValue","containerValue","applyScopedProtected","expandOptions","isTermProtected","isSimpleTermDefinitionPrefix","validateKeywordRedefinitions","contextBefore","contextAfter","deepEqual","PROTECTED_TERM_REDEFINITION","valueType","substr","INVALID_VOCAB_MAPPING","INVALID_BASE_IRI","INVALID_DEFAULT_LANGUAGE","INVALID_VERSION_VALUE","INVALID_CONTEXT_ENTRY","INVALID_PROPAGATE_VALUE","getPrefix","CYCLIC_IRI_MAPPING","isValidIriWeak","isCompactIri","objectKey","objectValue","INVALID_TYPE_MAPPING","INVALID_REVERSE_PROPERTY","CONTAINERS_1_0","INVALID_CONTAINER_MAPPING","CONTAINERS","INVALID_LANGUAGE_MAPPING","INVALID_PREFIX_VALUE","applyBaseEntry","inheritFromParent","baseIRI","external","normalizeContextIri","contextIri","_a","startsWith","parseInnerContexts","ignoreScopedContexts","ignoreProtection","ignoreRemoteScopedContexts","e","message","INVALID_SCOPED_CONTEXT","minimalProcessing","internalOptions","DEFAULT_PROCESSING_MODE","remoteContexts","CONTEXT_OVERFLOW","hasProtectedTerms","INVALID_CONTEXT_NULLIFICATION","overriddenLoad","getOverriddenLoad","parsedStringContext","load","contextIris","contexts","all","reducedContexts","accContextPromise","contextEntry","accContext","importContext","INVALID_IMPORT_VALUE","loadImportContext","defaultExpandOptions","newContext","overlappingKeys","newContextWrapped","INVALID_LOCAL_CONTEXT","url","cached","document","LOADING_REMOTE_CONTEXT_FAILED","INVALID_REMOTE_CONTEXT","RECURSIVE_CONTEXT_INCLUSION","importContextIri","serialize","toJSON","t","cv","ci","comma","EntryHandlerKeywordIncluded","INVALID_INCLUDED_VALUE","valueUnliased","keyword","JsonLdParser","Parser","readable_stream_1","EntryHandlerArrayValue_1","EntryHandlerContainer_1","EntryHandlerInvalidFallback_1","EntryHandlerKeywordContext_1","EntryHandlerKeywordGraph_1","EntryHandlerKeywordId_1","EntryHandlerKeywordIncluded_1","EntryHandlerKeywordNest_1","EntryHandlerKeywordType_1","EntryHandlerKeywordUnknownFallback_1","EntryHandlerKeywordValue_1","ParsingContext_1","http_link_header_1","EntryHandlerKeywordAnnotation_1","Transform","readableObjectMode","ParsingContext","parser","jsonParser","contextJobs","typeJobs","contextAwaitingJobs","lastDepth","lastKeys","lastOnValueJob","attachJsonParserListeners","on","mode","emit","fromHttpResponse","mediaType","headers","wellKnownMediaTypes","includes","endsWith","LOADING_DOCUMENT_FAILED","forEach","linkHeader","MULTIPLE_CONTEXT_LINK_HEADERS","ignoreMissingContextLinkHeader","contentType","match","import","stream","error","parsed","pipe","output","PassThrough","_transform","chunk","callback","write","lastDepthCheck","flushStacks","listHead","splice","pendingContainerFlushBuffers","flushBuffer","handleKey","INVALID_REVERSE_PROPERTY_MAP","validationStack","property","Math","max","validationResult","validateKey","valid","isLiteral","entryHandler","ENTRY_HANDLERS","validateValueIndexes","unaliasedKeywordCacheStack","graphStack","graphContainerTermStack","jsonLiteralStack","literalStack","subjects","subjectsWasDefined","valueBuffer","unidentifiedValuesBuffer","subject","depthOffsetGraph","getDepthOffsetGraph","graphs","graph","bufferedValue","emitQuadChecked","subGraphBuffer","getUnidentifiedGraphBufferSafe","graphBuffer","unidentifiedGraphsBuffer","termType","topLevelProperties","annotationsBufferParent","getAnnotationsBufferSafe","annotation","onValue","stack","fill","v","isParsingContextInner","valueJobCb","jobs","job","executeBufferedJobs","onError","applicableTypeJobs","applicableTypeJobIds","typeJob","isPrefixArray","sortedTypeJobs","job1","job2","sortedApplicableTypeJobIds","jobId","EntryHandlerKeywordId","EntryHandlerKeywordGraph","EntryHandlerKeywordValue","EntryHandlerKeywordAnnotation","separatorPos","charAt","prefix","contextValue","allowPrefixNonGenDelims","isPrefixIriEndingWithGenDelim","KEYWORD_REGEX","prefixIri","ENDS_WITH_GEN_DELIM","iri","Boolean","IRI_REGEX","IRI_REGEX_WEAK","VALID_KEYWORDS","objKeys1","objKeys2","value1","value2","__createBinding","create","o","m","k","k2","desc","getOwnPropertyDescriptor","__esModule","writable","configurable","enumerable","__exportStar","p","prototype","hasOwnProperty","call","blackList","Set","readable","duplex","Proxy","target","Reflect","arguments","result","bind","C","LEFT_BRACE","RIGHT_BRACE","LEFT_BRACKET","RIGHT_BRACKET","COLON","COMMA","TRUE","FALSE","NULL","STRING","NUMBER","START","STOP","TRUE1","TRUE2","TRUE3","FALSE1","FALSE2","FALSE3","FALSE4","NULL1","NULL2","NULL3","NUMBER1","NUMBER3","STRING1","STRING2","STRING3","STRING4","STRING5","STRING6","VALUE","KEY","OBJECT","ARRAY","BACK_SLASH","charCodeAt","FORWARD_SLASH","BACKSPACE","FORM_FEED","NEWLINE","CARRIAGE_RETURN","TAB","STRING_BUFFER_SIZE","alloc","size","tState","string","stringBuffer","stringBufferOffset","unicode","highSurrogate","bytes_remaining","bytes_in_sequence","temp_buffs","toknam","code","l","proto","err","charError","buffer","String","fromCharCode","appendStringChar","char","appendStringBuf","buf","start","copy","n","onToken","j","byteLength","intVal","parseInt","numberReviver","token","parseError","pop","parent","text","Number","isNaN","expandVocab","validIriMapping","vocab","vocabRelative","base","potentialKeyword","contextPrefixValue","allowPrefixForcing","allowVocabRelativeToBase","compactIri","shortestPrefixing","suffix","fetcher","response","fetch","Headers","accept","ok","colonPos","json","alternateUrl","statusText","status","ContextTree_1","JsonLdParser_1","contextParser","skipContextValidation","produceGeneralizedRdf","allowSubjectList","defaultGraph","rdfDirection","rdfstarReverseInEmbedded","activeProcessingMode","parseFloat","rootContext","activeVersion","PROCESSING_MODE_CONFLICT","keysOriginal","contextData","getContextPropagationAware","contextKeyEntry","propagate","originalDepth","hasApplicablePropertyScopedContext","lastKey","lastKeyValue","pendingFlushBuffer","getUnidentifiedValueBufferSafe","getExpandOptions","EXPAND_OPTIONS","deeperIdStack","rdf_data_factory_1","canonicalizeJson","DataFactory","namedNode","RDF","rdfJson","contextKey","entry","getContextValueLanguage","getContextValueDirection","isContextValueReverse","needle","haystack","indexHashes","existingIndexValue","CONFLICTING_INDEXES","literal","valueToJsonString","getContextSelfOrPropertyScoped","val","valueLanguage","valueDirection","valueIndex","subValue","INVALID_VALUE_OBJECT_VALUE","INVALID_LANGUAGE_TAGGED_VALUE","INVALID_LANGUAGE_TAGGED_STRING","nullableTermToArray","createLanguageDirectionLiteral","INVALID_TYPED_VALUE","typeTerm","INVALID_SET_OR_LIST_OBJECT","listValue","graphContainerEntries","valueId","valueTerm","INVALID_ID_VALUE","stringValueToTerm","XSD_BOOLEAN","XSD_INTEGER","XSD_DOUBLE","predicateToTerm","expanded","intToString","datatype","isFinite","isInteger","toExponential","defaultDatatype","contextType","contextLanguage","contextDirection","direction","valueNode","disableCache","cachedUnaliasedKeyword","unliased","hash","newHash","validateReverseSubject","INVALID_REVERSE_PROPERTY_VALUE","depthContainer","graphContainerIndex","getPropertiesDepth","lastValidDepth","INVALID_EMBEDDED_NODE","emitAnnotation","annotationQuad","nestedAnnotation","nestedAnnotations","XSD","depthProperties","depthPropertiesGraph","atGraph","newAnnotation","existingAnnotation","objects","parentDepthOffset","listValueContainer","valueKeys","COLLIDING_KEYWORDS","INVALID_LANGUAGE_MAP_VALUE","containerTypeType","entryHasIdentifier","Sink","Impl","input","relativeIriProtocol","termCleanup","factory","quadCleanup","cleanup","ParserStream","transform","objectMode","entries","destroy"],"ignoreList":[],"sourceRoot":""}